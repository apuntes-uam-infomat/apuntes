% -*- root: ../GeometriaDiferencial.tex -*-

\section{Formas diferenciales}

La teoría de este tema se encuentra en el capítulo \ref{chapFormasDiferenciales}. Ejercicios recomendados correspondientes a \cite[Capítulo 1]{doCarmo94}.

\begin{problem}[4] Sea ω una $k$-forma en $\real^n$, donde $k$ es impar. Demuestra que $ω \y ω = 0$.
\label{T1_E4}
\solution

\doneby{Pedro}

\approvedby{Dejuan}

Puesto que ω es una k-forma tenemos que

\[ω = \sum a_i \dif x_{i_1}...\dif x_{i_k} \text{ con k impar}\]

Al calcular el producto exterior de esta forma consigo misma vamos a obtener una suma donde cada sumando aparece dos veces si reordenamos los diferenciables.

\paragraph{Si $2k > n$:\\}
Para empezar, es posible que estos sumandos sean 0 directamente, cosa que ocurre si estamos en un espacio de dimensión menor que 2k y en este caso no habría nada más que hacer. Esto ocurre si multiplicamos dos 2-formas en $\real^3$ puesto que cada sumando del resultado tendrá un producto de 4 diferenciales escogidos de un conjunto de 3 posibles. Por el principio del palomar es claro que habremos tomado al menos uno repetido, por lo que obtendremos un 0 directamente ($dx ∧ dx = 0$).

\paragraph{Si $2k≤n$:\\}
Por tanto sólo nos queda ver el caso en que estos sumanos no se hagan 0. Entonces nos quedaría, en alguna parte del resultado final, la suma:
\[a_i \dif x_{i_1}...\dif x_{i_k} \cdot a_j \dif x_{j_1}...\dif x_{j_k} + a_j \dif x_{j_1}...\dif x_{j_k} \cdot a_i \dif x_{i_1}...\dif x_{i_k}\]

Para poder sumar correctamente debemos escribir en ambos sumandos los diferenciales en el mismo orden. Para ello tomamos el segundo sumando y desplazamos el primer diferencial hasta el final. Esto nos supone un número par de intercambios para llevarlo al final de los $\dif x_j$ más un número impar de intercambios para llevarlo hasta el final de los $\dif x_i$.\footnote{Poneos un ejemplo de 3 diferenciales o de 4 (para el primer caos y el segundo respectivamente) y veis que tengo razón}.

Con esto podemos ver que mover la primera diferencial del segundo sumando hasta el final implica cambiar de signo este sumando, pues hacemos un número impar de intercambios. Puesto que esta operación la tenemos que hacer $k$ veces siendo $k$ un número impar, es claro que nos quedará el segundo sumando de signo negativo.

Por tanto la suma escrita anteriormente será 0 y al multiplicar una forma por sí misma no habrá ningún termino libre (que no esté emparejado con otro formando una suma con la indicada) por lo que es claro que queda 0.

Si queremos escribirlo más formalmente:

\begin{align*}
φ ∧ φ &= \sum_{I,J} a_I · a_J \; \dif x_I ∧ \dif x_J = \\
& \sum_{i_1,...,i_k} \sum_{j_i,...,j_k} a_{i_1,...,i_k} · a_{j_1,...,j_k} \; \dif x_{i_1} ∧ ... ∧ \dif x_{i_k} ∧ \dif x_{j_1} ∧ ... ∧ \dif x_{j_k} \overset{*}{=} \\
\sum_{i_1,...,i_k}& \sum_{j_i<i_1,...,j_k<i_k} (a_{i_1,...,i_k}a_{j_1,...,j_k} + (-1)^k a_{j_1,...,j_k}a_{i_1,...,i_k}) \dif x_{i_1} ∧ ... ∧ \dif x_{i_k} ∧ \dif x_{j_1} ∧ ... ∧ \dif x_{j_k} =\\
& \sum_{I,J<I} (a_Ia_J + (-1)^ka_Ja_I) \dif x_I∧\dif x_J  \overset{k \text{ impar}}{=}0
 \end{align*}

\textbf{*}: Por la explicación de Pedro.

\end{problem}

\begin{problem}[5] Sean $φ,ψ,θ$ las siguientes formas diferenciales en $ℝ^3$:
\begin{align*}
φ &= x \dif x - y \dif y \\
ψ &= z \dif x \y \dif y + x \dif y \y \dif z \\
θ &= z \dif y
\end{align*}

Calcula:
\ppart $φ\y ψ$.
\ppart $θ\y φ \y ψ$.
\ppart $\dif φ$.
\ppart $\dif ψ$.
\ppart $\dif θ$.

\solution

\doneby{Pedro}

\approvedby{Dejuan}

\spart
\[φ\y ψ=xz \dif x \y \dif x \y \dif y + x^2 \dif x \y \dif x  y \y \dif z-yz\dif y \y \dif x \y \dif y-yx \dif y \y \dif y \y \dif z = x^2 \dif x \y \dif y \y \dif z\]

\spart
\[θ\y φ \y ψ= 0\]

Es fácil de ver apoyándonos en el apartado a) y en la propiedad asociativa del producto exterior. La otra forma de verlo es pensando que el resultado será una $1+2+1 = 4$-forma en $\real^3$ que tiene que tener algún $\dif (algo)$ repetido.

\spart
\[\dif φ=\dif x \y \dif x + 0\cdot \dif y \y \dif x+0\cdot \dif z \y \dif x = 0\]

\spart
\[\dif ψ=\dif z \y \dif x \y \dif y + \dif x \y \dif y \y \dif z = 2 \cdot \dif x \y \dif y \y \dif z \]

\spart
\[\dif θ= \dif z \y \dif y = - \dif y ∧ \dif z\]

\end{problem}

\begin{problem}[6] Sea $\appl{f}{U⊂ℝ^m}{ℝ^n}$ una aplicación diferenciable. Supongamos que $m < n$ y sea ω una $k$-forma en $ℝ^n$, con $k > m$. Demuestra que $f^*ω = 0$.
\solution

\doneby{Pedro}

Primero vamos a pensar en qué es lo que tendríamos que hacer para calcular este pull back.

Dada la función $f$ podemos escribir cada coordenada de $\real^n$ como combinación de funciones de las variables de $\real^m$.

Podemos escribir
\[ω = \sum a_i(x_1,...x_n) \dif x_{i_1}.... \dif x_{i_k}\]

Al aplicar el pull back sustituimos cada $a_i(x_1,...x_n)$ por $a_i(Im (f)_1,...Im(f)_n)$, con lo que obtendremos otros coeficientes, cosa que nos da igual para este ejercicio.

El detalle importante es lo que vamos a hacer con los diferenciales. Vamos a sustituir cada uno de ellos por $\dif Im(f)_i$ considerando esta imagen como una 0-forma a la hora de derivar.

Finalmente, cuando escribamos el producto de todos los $\dif x_i$ posiblemente nos quedará un producto de formas que dará lugar a un sumatorio. El detalle a recalcar es que cada producto implicará multiplicar $k$ diferenciales escogidas entre un conjunto de $m<k$ posibles diferenciales.

De nuevo aplicamos el principio del palomar y vemos que en todos estos productos estaremos cogiendo alguna diferencial varias veces con lo que nos quedará una suma de 0.

Finalmente $a_i \cdot 0 = 0$.

\doneby{Dejuan}

El pull back (por definición) nos lleva $k$-formas de un sitio a $k$-formas en otro. En este caso nos llevará una $k$-forma a $\real^m$ con $k>m$. Entonces, por el principio del Palomar tiene que haber algún $\dif (algo)$ repetido

\end{problem}

\begin{problem}[7] Sea $ω$ la 2-forma en $ℝ^{2n}$ dada por \[ ω = \dif x_1 \y \dif x_2 + \dif x_3 \y \dif x_4 + \dotsb + \dif x_{2n-1} \y \dif x_{2n} \]

Calcula el producto exterior de $n$ copias de ω (esto es, $ω \underbracket{\y \dotsb \y}_{n} ω$).
\solution

\doneby{Dejuan}

\approvedby{Pedro}

Antes de nada podemos ver que ese producto nos dará una suma de 2n-formas que tendremos que calcular.

Todas las 2n-formas que se obtengan al multiplicar uno de los sumandos de ω por sí mismo será 0. Por tanto sólo sobrevivirán aquellos sumanos que combinen todos los posibles alores de $\dif x_i$.\footnote{Si no combina todos los valores posibles pero tiene 2n elementos, por necesidad está repitiendo algún elemento, por lo que quedará 0}.

Nos quedarán $n!$ factores, cada uno con una ordenación diferente de los pares $\dif x_i \y \dif x_{i+1}$ de ω. Como cualquier reordenación que tengamos que hacer implicará mover directamente dos diferenciales, implicará un número par de cambios $2\cdot k$ por lo que se mantendrá el signo.


Vamos a estudiar el caso $n=2$ para verlo más claro.

Tenemos \[ω=\dif x_1 ∧ \dif x_2 + \dif x_3 ∧ \dif x_4 \]

y al multiplicar esta forma consigo misma obtenemos:
\[ ω∧ω = \dif x_1 ∧ \dif x_2 ∧ \dif x_3 ∧ \dif x_4 + \dif x_3 ∧ \dif x_4 \y \dif x_1 ∧ \dif x_2 = 2 \dif x_1 ∧ \dif x_2 ∧ \dif x_3 ∧ \dif x_4\]

El resultado final será:

\[
ω \underbracket{\y \dotsb \y}_{n} ω = n! \dif x_1 ∧ ... ∧ \dif x_{2n}
\]


\end{problem}

\begin{problem}[8] Sea $\appl{f}{ℝ^n}{ℝ^n}$ la aplicación diferenciable dada por $f(x_1, \dotsc, x_n) = (y_1, \dotsc, y_n)$, y sea $ω = \dif y_1 \y \dotsb \y \dif y_n$. Demuestra que \[ f^* ω = \det (\dif f) · \dif x_1 \y \dotsb \y \dif x_n \]
\solution

\doneby{Dejuan}

Recordamos\footnote{consultando los magníficos apuntes de Análisis Matemático en donde viene muy bien el pull-back con ejemplos} que $f^* (ω∧φ) = f^*(ω) ∧ f^*(φ)$.

Sabemos además\footnote{Reconsultando Análisis Matemático o el doCarmo} que $f^*(\dif y_1) = \dif x_1 (y_1,...,y_n) = \displaystyle\sum \dpa{}{x_i}f_1 \dif x_i$.

Juntando estos 2 conocimientos, escribimos:

\[
f^*(ω) = f^*(\dif y_1) ∧ ... ∧ f^*(\dif y_n) = \left(\sum_i \dpa{f_1}{x_i}\dif x_i\right) ∧ ... ∧ \left( \sum_i \dpa{f_n}{x_i} dx_i\right)
\]

Ahora sólo es cuestión de reorganizar los términos para intentar escribirlo como determinante.


Vamos a demostrarlo por inducción.

El caso base es $n=2$:
\begin{align*}
f^*(y_1 ∧ y_2) &= f^*(y_1) ∧ f^*(y_2) = \left(\dpa{f_1}{x_1}\dif x_1 + \dpa{f_1}{x_2} \dif x_2 \right)∧  \left(\dpa{f_2}{x_1}\dif x_1 + \dpa{f_2}{x_2} \dif x_2 \right) = \\
&= \left(\dpa{f_1}{x_2} · \dpa{f_1}{x_1} \dif x_1 ∧ \dif x_2\right) + \left(\dpa{f_1}{x_2} · \dpa{f_2}{x_1} \dif x_2 ∧ \dif x_1\right) = \\
&= \left(\dpa{f_2}{x_2} · \dpa{f_1}{x_1} - \dpa{f_1}{x_2} · \dpa{f_2}{x_1}\right) \dif x_1 ∧ \dif x_2 = \\
&=\det(\dif f_n) \dif x_1 ∧ \dif x_2
\end{align*}

Ahora, suponiendo cierto que
\[
\left(\sum_i^n \dpa{f_1}{x_i}\dif x_i\right) ∧ ... ∧ \left( \sum_i^n \dpa{f_n}{x_i} dx_i\right) = \det(df_n) \dif x_1 ∧ ... ∧ \dif x_n
\]
vamos a ver que

\[
\left(\sum_i^{n+1} \dpa{f_1}{x_i}\dif x_i\right) ∧ ... ∧ \left( \sum_i^{n+1} \dpa{f_{n+1}}{x_i} dx_i\right) = \det(df_n) \dif x_1 ∧ ... ∧ \dif x_n
\]

Para ello, el primer sumando lo extendemos y aplicamos la propiedad distributiva y utilizando que $\dif x∧\dif x = 0$\footnote{es por esto por lo que los sumatorios comienzan en 2}, es decir:

\begin{align*}
&\dpa{f_1}{x_1} \dif x_1 ∧ \underbrace{\left [ \left( \sum_{i=2}^{n+1} \dpa{f_2}{x_i} \dif x_i \right) ∧ ... ∧ \left( \sum_{i=2}^{n+1} \dpa{f_{n+1}}{x_i} \dif x_i \right)\right]}_{\det (d(f_2,..,f_{n+1}))}  + \dpa{f_2}{x_2}\dif x_2 ∧ (...) + ... =\\
&\sum_{i=1}^{n+1} \dpa{f_1}{x_i} \dif x_i · \left[\det\left(d(f_1,...,f_{i-1},f_{i+1},...,f_n)\right) \dif x_1 ∧ ... ∧ \dif x_{i-1} ∧ \dif x_{i+1} ∧ ... ∧ \dif x_n\right] \overset{*}{=}\\
&\det(\dif (f_{n+1})) \dif x_1 ∧ \dif x_{n+1}
\end{align*}

\textbf{*:} Por cómo se calculan los determinantes utilizando menores, es decir:

\begin{align*}
\begin{vmatrix} a & b & c & d\\e & f & g & h\\i & j & k & l\\m & n & o & p \end{vmatrix} = a\begin{vmatrix} f & g & h\\j & k & l\\n & o & p \end{vmatrix} -b\begin{vmatrix} e & g & h\\i & k & l\\m & o & p \end{vmatrix}+c\begin{vmatrix} e & f & h\\i & j & l\\m & n & p \end{vmatrix}-d\begin{vmatrix} e & f & g\\i & j & k\\m & n & o \end{vmatrix}
\end{align*}

Y los signos negativos aparecen al desplazar el $\dif x_i$ a su posición correspondiente, teniendo que realizar $i$ cambios.

% % % Sólo tenemos que ver que ese algo largo sea el determinante. Para ello, nos ayudamos de escribir la cuenta que tenemos sin sumatorios, donde $a_{ij} =\displaystyle \dpa{f_i}{x_j}$
% % %
% % % \begin{align*}
% % % &(a_{11}\dif x_1 + a_{12} \dif x_2 +  \cdots + a_{1n}\dif x_n) \;∧ \\
% % % &(a_{21}\dif x_1 + a_{22} \dif x_2 +  \cdots + a_{2n}\dif x_n) \;∧ \\
% % % & \quad \vdots\\
% % % &(a_{n1}\dif x_1 + a_{22} \dif x_2 +  \cdots + a_{nn}\dif x_n)\\
% % % \end{align*}
% % %
% % % Por otro lado, en \href{http://en.wikipedia.org/wiki/Determinant}{Wikipedia} encontramos una fórmula de desarrollo de determinantes de matrices $n$-dimensionales (la fórmula de Leibniz)
% % %
% % % \[
% % % \det(A) = \sum_{\sigma \in S_n} \text{sgn}(\sigma) \prod_{i=1}^n a_{i,\sigma_i}
% % % \]
% % % donde $S_n$ es nuestro queridísimo grupo simétrico\footnote{el conjunto de todas las permutaciones de listas de n elementos} que veíamos en Galois. Esta fórmula sale de la generalización de lo que ya conocemos:
% % % \begin{equation*}
% % % \begin{vmatrix} a & b & c & d\\e & f & g & h\\i & j & k & l\\m & n & o & p \end{vmatrix} = a\begin{vmatrix} f & g & h\\j & k & l\\n & o & p \end{vmatrix} -b\begin{vmatrix} e & g & h\\i & k & l\\m & o & p \end{vmatrix}+c\begin{vmatrix} e & f & h\\i & j & l\\m & n & p \end{vmatrix}-d\begin{vmatrix} e & f & g\\i & j & k\\m & n & o \end{vmatrix}
% % % \end{equation*}
% % %
% % %
% % % El siguiente paso que se me ocurre dar es demostrarlo por inducción.


\end{problem}

\begin{problem}[18] Una función $\appl{g}{ℝ^3}{ℝ}$ es homogénea de grado $k$ si \[ g(tx,ty,tz) = t^k g(x,y,z)\] para $t > 0$ y $(x,y,z) ∈ ℝ^3$. Demuestra que

\ppart Si $g$ es diferenciable y homogénea de grado $k$, entonces \[ x \dpa{g}{x} + y \dpa{g}{y} + z \dpa{g}{z} = k g\]

Esta es la relación de Euler.

\textit{Sugerencia}: deriva $g(tx,ty,tz) = t^k g(x,y,z)$ con respecto a $t$ y supón $t = 1$.

\ppart Si la forma diferencial \[ ω = a \dif x + b \dif y + c \dif z \] es tal que $a,b,c$ son funciones homogéneas de grado $k$ y se tiene que $\dif ω = 0$, entonces $ω = \dif f$ con \[ f = \frac{xa + yb + zc}{k+1}\]

\textit{Sugerencia}: $\dif ω = 0$ implica que \[ \dpa{b}{x} = \dpa{a}{y},\quad \dpa{c}{x} = \dpa{a}{z},\quad \dpa{b}{z} = \dpa{c}{y} \] y aplica la relación de Euler del anterior apartado.

\ppart Si la forma diferencial \[ σ = a \dif y \y \dif z + b \dif z \y \dif x + c \dif x \y \dif y \] es tal que $a,b,c$ son homogéneas de grado $k$ y $\dif σ = 0$, entonces $σ = \dif γ$ donde \[ γ = \frac{(zb-yc) \dif x + (xc-za) \dif y + (ya-xb) \dif z}{k+2} \]
\solution

\doneby{Pedro}

\spart

Atendiendo a la sugerencia proporcionada derivamos $g(tx,ty,tz)=t^k g(x,y,z)$ respecto de $t$ a ambos lados de la igualdad obteniendo:
\[x\frac{\partial g}{\partial x}+y\frac{\partial g}{\partial y}+z\frac{\partial g}{\partial z} = k t^{k-1}g(x,y,z)\]

Si tomamos $t=1$ ya tenemos el resultado buscado.

\spart

Vamos a calcular la diferencia de la función $f$ dada y a ver si coincide cono ω bajo la suposición $\dif w = 0$.

\[\dif f = \dif \frac{xa(x,y,z)+yb(x,y,z)+zc(x,y,z)}{k+1}=\]
\[=\frac{(a(x,y,z)+xa_x(x,y,z)+yb_x(x,y,z)+zc_x(x,y,z))\dif x}{k+1}+\]
\[+\frac{(b(x,y,z)+yb_y(x,y,z)+xa_y(x,y,z)+zc_y(x,y,z)) \dif y}{k+1}+\]
\[+\frac{(c(x,y,z)+zc_z(x,y,z)+yb_z(x,y,z)+xa_z(x,y,z)) \dif z}{k+1}\]

Hasta aquí simplemente hemos derivado. Basándonos en la información que nos da la sugerencia sobre lo que se puede deducir de que $\dif ω = 0$, las relaciones entre las derivadas parciales, podemos escribir:

\[\dif f = \dif \frac{xa(x,y,z)+yb(x,y,z)+zc(x,y,z)}{k+1}=\]
\[=\frac{(a(x,y,z)+xa_x(x,y,z)+ya_y(x,y,z)+za_z(x,y,z))\dif x}{k+1}+\]
\[+\frac{(b(x,y,z)+yb_y(x,y,z)+xb_x(x,y,z)+zb_z(x,y,z)) \dif y}{k+1}+\]
\[+\frac{(c(x,y,z)+zc_z(x,y,z)+yc_y(x,y,z)+xc_x(x,y,z)) \dif z}{k+1}\]

Basándonos ahora en la propiedad que hemos probado en el apartado anterior, tenemos:

\[\dif f = \dif \frac{xa(x,y,z)+yb(x,y,z)+zc(x,y,z)}{k+1}=\]
\[=\frac{(a(x,y,z)+ka(x,y,z))\dif x}{k+1}+\frac{(b(x,y,z)+kb(x,y,z)) \dif y}{k+1}+\frac{(c(x,y,z)+kc(x,y,z)) \dif z}{k+1}=\]
\[= a(x,y,z)\dif x + b(x,y,z) \dif y + c(x,y,z) \dif z = ω\]

\spart

Puesto que $\dif σ=0$ tenemos:
\[a_x(x,y,z)+b_y(x,y,z)+c_z(x,y,z) = 0\]

De forma similar a lo que hicimos en el apartado anterior vamos a derivar γ, aunque esta vez no vamos a escribir todos los pasos de forma tan exhaustiva.

\[\dif γ = \frac{(zb_y-c-yc_y-c-xc_x+za_x)\dif y \y \dif x + (b+zb_z-yc_z-ya_x+b+xb_x) \dif z \y \dif x}{k+2}+\]
\[+\frac{(a+ya_y-xb_y-xc_z+a+za_z)\dif y \y \dif z}{k+2}=\]
utilizando $a_x+b_y+c_z=0$:
\[\dif γ = \frac{(-c-yc_y-c-xc_x-zc_z)\dif y \y \dif x + (b+zb_z-yb_y+b+xb_x) \dif z \y \dif x}{k+2}+\]
\[+\frac{(a+ya_y+xa_y+a+za_z)\dif y \y \dif z}{k+2}=\]
y basándonos ahora otra vez más en el primer apartado tenemos:
\[\dif γ = c \dif x \y \dif y + b \dif z \y \dif x + a \dif y \y \dif z = σ\]


\end{problem}

\section{Integrales de línea}

La teoría correspondiente a estos ejercicios se encuentra en la sección \ref{secIntegralesLinea}. Ejercicios de \cite[Capítulo 2]{doCarmo94}.

\begin{problem}[1] Demuestra que la forma $ω =  2xy^3\dif x + 3 x^2 y^2 \dif y$ es cerrada y calcula $\int_c ω$, donde $c$ es el arco de la parábola $y = x^2$ desde $(0,0)$ hasta $(x,y)$.
\solution

\doneby{Pedro}

Una forma diferencial será cerrada si su derivada es 0. Por tanto para demostrar que ω es cerrada basta con ver que $\dif ω = 0$.

\[\dif ω = 2x3y^2 \dif y \y \dif x +6x y^2 \dif x \y \dif y = 0\]

Podemos ver que ω es una forma exacta, pues $f=x^2y^3$ es una 0-forma tal que $\dif f = ω$.

El arco de parábola dado podemos verlo como una función $\appl{c}{\real}{\real^2}$ tal que $c(t)=(t,t^2)$.

Por tanto podemos calcular la integral como:
\[\int_c ω = \int_c \dif f = \int_0^{x} c^*(\dif f) = f(c(x))-f(c(0))=x^8-0 = x^8 \]

\end{problem}

\begin{problem}[2]\label{ejIntegralesLinea2}
\ppart Demuestra que si $ω$ es una $1$-forma diferenciable definida en $U ⊂ ℝ^n$, $\appl{c}{[a,b]}{U}$ es una curva diferenciable y $\abs{ω(c(t))} ≤ M$ para todo $t ∈ [a,b]$, entonces \[ \abs{\int_c ω} ≤ ML \] donde $L$ es la longitud de $c$.

\ppart Sea $ω$ una 1-forma cerrada en $ℝ^2 \setminus \set{0}$. Suponemos que $ω$ está acotada (esto es, sus coeficientes están acotados) en un disco de centro el origen. Demuestra que $ω$ es exacta en $ℝ^2 \setminus \set{0}$.

\ppart Demuestra que el resultado del apartado anterior es cierto si sólo suponemos que $\dif  ω = 0$ y que \[ \lim_{x^2+y^2  \to 0} ω\sqrt{x^2+y^2} = 0 \]
\solution

\doneby{Pedro}

\spart

\[\left| \int_c ω\right| \leq \int_c | ω | =\int_a^b c^*(ω) = \int_a^b ω(c(t))dt \leq \int_a^b M dt = ML\]

\spart

Sea $c$ la curva que define el disco en el que nuestra 1-forma, ω, está acotada, si recorremos muy rápido esta curva tenemos que:

\[\int_c ω \leq \int_c |w| =\int_0^ε ω(c(t)) \leq ML = Mε\]
puesto que esto es cierto para cualquier ε que tomemos, por muy pequeño que sea, necesariamente $\int_c ω = 0$ para la curva dada.

He encontrado un \href{http://fejer.ucol.mx/cursos2/wp-content/uploads/2007/05/cap9.pdf}{resultado (final de la página 13)} en internet que dice que si dos curvas son homotópicas y ω una curva cerrada, se tiene que
\[\int_{c_1} ω = \int_{c_2} ω\]

Puesto que estamos trabajando con curvas cerradas en torno al origen, por lo que vimos en topología, sabemos que todas son homotópicas (es muy sencillo encontrar una contracción que nos llevase de una a otra).

Basándonos ahora en las proposiciones de la página 18 del capítulo 2 del Do Carmo, tenemos que:
\[\int_c ω = 0 \forall c \text{ closed} \implies \ ω is exact\]
con lo que ya lo tenemos.

\spart

Si tomamos la función $\appl{f}{(x,y)}{(r, \theta)}$, que realiza el cambio de variables a polares siendo $r$ constante, y $c$ es un círculo centrado en el origen, tenemos:
\[\int_c ω = \int_0^{2π} w r\]

Sabemos que para cualquier curva que tomemos esta integral tendrá el mismo valor y a medida que tomemos curvas más pequeñas tendremos que
\[\lim_{r \to 0} w r = 0\]
por lo que
\[\int_c ω = 0\]
ya que si puedo acercarme tanto como quiera al 0, la integral debe ser 0.

A partir de aquí, el mismo razonamiento del apartado anterior nos lleva a que ω es exacta en $\real^2 \setminus \{(0,0)\}$

\end{problem}

\begin{problem}[3] Consideramos la forma \[ ω = \frac{e^x}{x^2+y^2}\left((x\cos y + y \sin y) \dif y + (x \sin y - y \cos y) \dif x \right)\] definida en $ℝ^2 \setminus \set {0}$.

\ppart Demuestra que $ω$ se puede escribir como \[ ω = e^x \cos y · ω_0 + e^x \sin y · \dif \log r\] donde $ω_0$ es el elemento de ángulo\footnote{Entiendo que esto quiere decir $\dif θ$ tomando coordenadas polares.} en $0$ y $r = \sqrt{x^2+y^2}$. Comprueba calculándolo que $\dif ω = 0$.

\ppart Demuestra que $ω - ω_0$ cumple la condición del ejercicio \ref{ejIntegralesLinea2}, apartado \textbf{c)}, y que por lo tanto es exacta.

\ppart Calcula $\int_c ω$ donde $c$ es una curva cerrada simple\footnote{Sin autointersecciones.} en $ℝ^2 \setminus \set{0}$.

\solution

\doneby{Pedro}

\spart

Atendiendo al ejemplo 1 del capítulo 2 del Do Carmo tenemos que el elemento de ángulo respecto del origen se define como:
\[ω_0=-\frac{y}{x^2+y^2}\dif x + \frac{x}{x^2+y^2} \dif y\]

Por tanto, la forma que nos dan en este apartado es:
\[ω = \frac{e^x}{x^2+y^2}(-y\cos y \dif x + x \cos y \dif y)+e^x \sin y \dif \log r\]

Ya empieza a parecerse a lo que queremos llegar. Ahora tenemos que ver cómo jugar con esa diferencial de logaritmo.

La idea intuitiva es escribir $r$ en función de $x$ e $y$ y derivar su logaritmo. Vamos a ello:
\[\dif \log r = \dif \log\left(\sqrt{x^2+ y ^2}\right) = \frac{x}{x^2+y^2}\dif x + \frac{y}{x^2+y^2} \footnote{Lo he escrito muy rápido pero la cuenta sale. Trust me}\]

Combinando esto con la fórmula que teníamos de ω llegamos a:
\[ω = \frac{e^x}{x^2+y^2}(-y\cos y \dif x + x \cos y \dif y)+\frac{e^x}{x^2+y^2}(x \sin y \dif x + y \sin y \dif y)=\]
\[=\frac{e^x}{x^2+y^2}\left((x\cos y + y \sin y) \dif y + (x \sin y - y \cos y) \dif x \right)\]


\spart

Tenemos que
\[ω-ω_0=\frac{e^x}{x^2+y^2}\left((x\cos y + y \sin y + x) \dif y + (x \sin y - y \cos y - y) \dif x \right)\]

Es sencillo ver que
\[\dif ( ω-ω_0)=\left(\frac{e^x(x²+y²)-e^x2x}{(x^2+y^2)^2}\left(x\cos y + y \sin y + x \right) + \frac{e^x}{x^2+y^2}(\cos y + 1)\right) \dif x \y \dif y+\]
\[+\left(\frac{-e^x2y}{(x^2+y^2)^2}\left(x \sin y - y \cos y - y \right) + \frac{e^x}{x^2+y^2}(x\cos y +y \sin y -1)\right) \dif y \y \dif x\]

A ojo de buen cubero y sabiendo que si no sale no se puede hacer el ejercicio (y eso no es propio de Do Carmo), vemos que este choricete acaba dando 0 a base de simplificar cosas.

Ahora nos queda ver la otra propiedad del apartado $c$:

\[ \lim_{x^2+y^2  \to 0} ω\sqrt{x^2+y^2} =\lim_{x^2+y^2  \to 0} \frac{e^x}{\sqrt{x^2+y^2}}\left((x\cos y + y \sin y + x) \dif y + (x \sin y - y \cos y - y) \dif x \right)\]

Para calcular este límite hacemos el cambio de coordenadas a polares de modo que nos quedará un límite en una única variable, el radio, que tiende a 0.

\textcolor{blue}{Estas cuentas parecen la entrada al infierno así que se dejan como ejercicio para el lector desconfiado. Básicamente es ponerse, ver que se simplifican cosas, y hacer el límite.}

\end{problem}

\begin{problem}[4] Sea $ω$ una 1-forma definida en un abierto $U ⊂ ℝ^n$. Suponemos que para cada curva $c$ cerrada y diferenciable en $U$, $\int_c ω$ es un número racional. Demuestra que $ω$ es cerrada.
\solution

\doneby{Pedro}

Para demostrar que ω es cerrada tenemos que ver que $\dif ω = 0$.

En internet ya se han peleado con esta pregunta \href{http://math.stackexchange.com/questions/111658/differential-form-is-closed-if-the-integral-over-a-curve-is-rational-number}{aquí}.

La idea es que cuando una curva cerrada es deformada continuamente mediante un parámetro su integral también se deforma continuamente. Es decir, que si integro sobre dos curvas cerradas muy similares (reduciendo el radio ε de una a la otra) debo obtener valores muy cercanos.

Ahora bien, la hipótesis nos dice que estas integrales serán siempre valores racionales, pero si una vez toma el valor $a$ y luego el valor $b$, el teorema de los valores intermedios nos dice que también deberá tomar todos los valores intermedios. Oh wait, en medio habrá irracionales que sabemos que no se alcanzan.

La unica forma de que esto no suponga una contradicción y un horror matemático es que la integral sea 0 para toda curva cerrada $c$.

Volviendo a la proposición 1 del tema 2 del Do Carmo, tenemos que ω es exacta y si es exacta es cerrada.

\[ω \text{ exacta } \implies ω = \dif f \implies \dif ω \dif \dif f = 0\]


\end{problem}

\begin{problem}[7] Consideramos la forma \[ ω = \frac{2(x^2 - y^2 - 1) \dif y - 4xy\dif x}{(x^2 + y^2 -1)^2 + 4y^2} \] definida en $ℝ^2 \setminus \set{p_1, p_2}$ con $p_1 = (1,0)$ y $p_2 = (-1, 0)$. Sean $D_1, D_2$ discos centrados en $p_1$ y $p_2$ respectivamente y lo suficientemente pequeños como para que se cumpla que $p_2 \notin D_1$ y $p_1 \notin D_2$.

\ppart Demuestra las siguientes igualdades: \[ \frac{1}{2π}\int_{∂D_1} ω = 1\qquad \frac{1}{2π}\int_{∂D_2} ω = -1 \] donde $∂D_1, ∂D_2$ están orientados en el sentido contrario de las agujas del reloj.

\textit{Sugerencia}: considera $F = (f,g) = (x^2 + y^2 - 1, 2y)$ y observa que \[ ω = \frac{f \dif g - g \dif f}{f^2 + g^2} \]

Fíjate en que $p_1$ y $p_2$ son los únicos de ceros de $F$, donde $p_1$ es un cero positivo y $p_2$ es un cero negativo.

\ppart Concluye por homotopía que la integral de $ω$ sobre la curva $C$ de la figura \ref{figDoCarmo2-3}, con la orientación indicada, es $4π$.
\solution

\begin{figure}[hbtp]
\centering
\inputtikz{doCarmoFig2-3}
\caption{Curva $C$ alrededor de $p_1$ y $p_2$.}
\label{figDoCarmo2-3}
\end{figure}

\doneby{Pedro}

\spart

Aquí hace falta algo de teoría que aparece en el Do Carmo pero que creo que no hemos explicado en clase (jaja, como si hubiésemos explicado algo, quiero decir que no lo hemos ni mencionado). No obstante, lo que viene a continuación tiene cierta similitud con algo que hemos visto en Variable Compleja.

En la página 24 del Do Carmo se explica que siendo $F(x,y)=(f(x,y),g(x,y))$ y siendo $D$ un disco cerrado tal que su frontera no tiene ceros de $F$, si consideramos la forma diferencial
\[ω = \frac{f \dif g - g \dif f}{f^2 + g^2}\]
definida en todo punto tal que $f^2+g^2 \neq 0$ definimos el \concept{{Í}ndice} de $F$ en $D$ como el entero:
\[\frac{1}{2π}\int_{\partial D} ω = n(F;D)\]

Sea
\[ω_0=\frac{u \dif v - v \dif u}{u^2 + v^2}\]
el \concept{elemento de ángulo en el plano relativo al origen}, si tomamos $f(x,y)=u$ y $g(x,y)=v$ tendremos que
\[ω = F^*ω_0\]
por lo que podremos escribir:

\[n(F;D)=\frac{1}{2π}\int_{\partial D} ω = \frac{1}{2π}\int_{\partial D} F^* ω_0 = \frac{1}{2π}\int_{F \circ \partial D}ω_0\]

El teorema 3 del capítulo 2 del Do Carmo nos dice cómo calcular este índice sin tener que realizar las integrales.
\[n(F;D)=P-N\]
donde $P$ es el número de ceros positivos en el disco y $N$ el número de ceros negativos en el disco.

Usando la sugerencia del enunciado, es trivial ver que
\[n(F;D_1)=1 \ \; \ n(F;D_2)=-1\]

\spart

La integral de la curva dada se puede calcular como suma de dos integrales, una en la parte positiva de las $x$ y otra para la parte negativa.

La homotopía nos dice que dos curvas homotópicas integradas sobre una misma forma tienen el mismo valor.
Además, tenemos que
\[\frac{1}{2π}\int_{∂D_1} ω = 1 \implies \int_{∂D_1} ω = 2π\]
\[\frac{1}{2π}\int_{∂D_2} ω = 1 \implies \int_{∂D_2} ω = 2π\]
Por tanto podemos escribir:
\[\int_C ω = \int_{C_P} ω + \int_{C_N}ω = \int_{\partial D_1} ω + \int_{\partial D_2} ω = 2π+2π = 4π\]

\end{problem}

\begin{problem}[10] Sea $ω$ una $1$-forma diferenciable definida en $U ⊂ ℝ^2$. Un factor integrante local en $p$ para ω es una función $\appl{g}{V}{ℝ}$ deifnida en un entorno $V⊂U$ de $p$ tal que la forma $gω$ es exacta en $V$, esto es, existe una función $\appl{f}{V}{ℝ}$ con $gω = \dif f$.

\ppart Demuestra que si $ω (p) ≠ 0$ existe un factor local integrante en $p$.

\textit{Sugerencia}: la condición $ω(v) = 0$ determina un campo vectorial $v$ en un entorno de $p$ que no es nulo. Por el teorema fundamental de las ecuaciones diferenciales, existe un entorno $V$ de $p$ y una función $\appl{f}{V}{ℝ}$ (la primera integral de $f$) tal que $f$ es constante sobre las trayectorias de $v$. Entonces \[ \dif f(v) = 0 = ω(v) \]

De ahí se sigue que $\dif f = gω$.

\ppart Demuestra que si $\appl{g}{V}{ℝ}$ es un factor integrante local en $p ∈ V$ (esto es, $\dif f = gω$ para algúna función $f$) y $\appl{θ}{ℝ}{ℝ}$ es cualquier función diferenciable, entonces $\appl{\tilde{g}}{V}{ℝ}$ definida por $\tilde{g}(p) = \dif θ(f(p)) · g(p)$ es también un factor integrante.

\textit{Sugerencia}: usando la notación de la sugerencia del apartado anterior, $θ(f)$ sigue siendo constante a lo largo de las trayectorias de $v$. Entonces $\dif (θ(f)) = \tilde{g}ω$ o $\dif θ · gω = \tilde{g}ω$ donde $\tilde{g}$ es un nuevo factor integrante. Dado que $ω ≠ 0$, entonces $\dif θ · g = \tilde{g}$.
\solution
\end{problem}

\section{Variedades diferenciables}

La teoría de estos ejercicios corresponde al capítulo \ref{chapVariedades}. Los ejercicios se encuentran en \cite[Capítulo 3]{doCarmo94}.

\begin{problem}[1]
Demuestra que el plano proyectivo es una variedad diferenciable.
\solution
\textcolor{blue}{Este ejercicio está prácticamente resuelto en teoría (\ref{defPlanoProj}) pero lo repetimos aquí con más detalle.}

Recordamos que, por definición, un conjunto $X$ es una variedad diferenciable (\ref{defVariedadDiferenciable}) si cumple:
\begin{enumerate}
\item $X$ es un espacio topológico con topología conexa y Hausdorff.
\item $U_i ⊂ X$ es una familia numerable de abiertos con aplicaciones $\appl{Φ_i}{U_i}{ℝ^n}$, homomorfismos sobre sus imágenes. El par $(U_i, Φ_i)$ es una carta coordenada.
\item Para todo par de de cartas coordenadas $U_i, U_j$ de la estructura diferencial\footnote{Una variedad queda unívocamente definida por un atlas maximal. Un atlas maximal es un atlas que contiene a todos los atlas que son compatibles con él. Dos atlas son compatibles si son equivalentes} y sus correspondientes homomorfismos $Φ_i, Φ_j$, la función $ \inv{Φ_i} ○ Φ_j $ es difeomorfismo en el entorno en el que está definida (en $U_i ∩ U_j$).
\end{enumerate}

Por otro lado tenemos el plano proyectivo definido como:
\[ \projp^2 ≝ \quot{ℝ^3 \setminus \set{0}}{\sim} \]
donde $\sim$ es una relación de equivalencia definida de la siguiente forma: dados $e, e' ∈ ℝ^3$, están relacionados $e \sim e'$ si y sólo si $∃λ ≠ 0$ tal que $λe = e'$.

Primero hay que dotar de una topología a este espacio. Para ello vamos a definir unos conjuntos:

\[U_i = \{(x_1,x_2,x_3) : x_i ≠ 0\}\]

Esta construcción permite decir que $\projp^2(ℝ) = \displaystyle\bigcup_{i=1}^3 U_i$. En cada conjunto se puede construir el homomorfismo $\appl{Φ_i}{U_i}{ℝ^2}$ llevando $[x_0, x_1, x_2]$ a $\left[\frac{x_0}{x_i},\frac{x_1}{x_i},\frac{x_2}{x_i}\right]$. Dado que una de las coordenadas va a ser $1$ siempre, podemos quitarla y entonces será equivalente a $ℝ^2$.

Definimos la topología del plano proyectivo como:

\[ A⊂U_i, A∈\topl \dimplies Φ_i(A) ∈\topl_{ℝ^n}\]

es decir, un subconjunto de $U_i$ es abierto si y sólo si su imagen por $Φ_i$ es un abierto en $ℝ^n$ con la topología habitual. No es de este curso comprobar que esto realmente define una topología ni que esta topología sea la topología con más abiertos tal que la aplicación $\appl{π}{\real^3 \setminus \set{0}}{\projp^2}$ es continua\footnote{$π$ es la combinación apropiada de $Φ_i$ para que sea continua. Es como la proyección en el plano proyectivo utilizado todas las $Φ_i$}.

Esta topología es conexa y Hausdorff, y también compacta.

Al tener una topología conexa y Hausdorff, el plano proyectivo es una variedad topológica.

Tendríamos que comprobar la tercera propiedad de variedad diferenciable. Para ello vemos que el plano proyectivo tratado como variedad tiene tres cartas, dadas por $(U_i,Φ_i)$.

Si tomamos dos cartas $(U_i, Φ_i), \ (U_j, Φ_j)$ vemos que la intersección de los $U$ es:
\[W = U_i \cap U_j= \{(x_1,x_2,x_3): \ x_i \neq 0 \ x_j \neq 0\}\]

Veamos como se comporta la aplicación $ \inv{Φ_i} ○ Φ_j $  sobre $W$:
\[\inv{Φ_i} ○ Φ_j (W)= \inv{Φ_i} \left(\left\{ \left(\frac{x_1}{x_j}, \frac{x_2}{x_j},\frac{x_3}{x_j}\right)\right\}\right) = \left\{ \left(\frac{x_i \cdot x_1}{x_j}, \frac{x_i \cdot x_2}{x_j},\frac{x_i \cdot x_3}{x_j}\right)\right\} \] con $i,j \in \set{1,2,3}$.

Puesto que partimos de la premisa de que $x_i, x_j \neq 0$ tenemos que la función es claramente diferenciable\footnote{cada coordenada es un polinomio de varias variables con un posible denominador no nulo} y puede comprobarse fácilmente que es biyectiva.

La inversa de esta función sería $ Φ_i ○ \inv{Φ_j}$ que se comportaría de la siguiente forma:
\[Φ_i ○ \inv{Φ_j}\left( \{(y_1, y_2, y_3)\}\right) =Φ_i  \left( \{y_1x_j, y_2x_j, y_3x_j\}\right) = \left\{ \left(\frac{y_1x_j}{x_i}, \frac{y_2x_j}{x_i}, \frac{y_3x_j}{x_i} \right)\right\}\]

Esta función sólo estará definida en aquellos puntos en que $x_i\neq$ por lo que resulta ser también diferenciable y vuelve a ser sencilla la comprobación de que la función es biyectiva por lo que queda claro que es un difeomorfismo y por tanto \textbf{el plano proyectivo es una variedad diferencial}.

\end{problem}

\begin{problem}[3] Sea $\appl{γ}{M}{N}$ una aplicación diferenciable. Demuestra que la definición de la diferencial $\appl{\dif γ_p}{\tgs_p M}{\tgs_{γ(p)} N}$ de γ en $p$ no depende de la elección de la curva y que $\dif γ_p$ es una aplicación lineal.

\solution
\doneby{Pedro}

Por definición tenemos
\[dγ_p(v) \in \tgs_{α(p)} N = (γ\circ α)'(0)\]
siendo
\[\appl{α}{(-ε, ε)}{M} \text{ con } α(0)=p, α'(0)=v\]

Sabemos que
\[(γ\circ α)'(0) = α'(0)(γ'(α(0)) = v \cdot γ'(p)\]

sin importar la curva $α$ tomada siempre y cuando cumpla las condiciones pedidas.

Ahora es sencillo ver que es lineal pues tenemos que es una aplicación que, dado un vector $v$ nos lleva a ese mismo vector multiplicado por un valor constante por lo que es lineal de manera trivial.
\end{problem}

\begin{problem}[4]
Let $\appl{γ}{M}{N}$ be an inmersion and let $p$ be a point in $M$. Show that there exists a neighborhood $V \subset M$ of $p$ such that the restriction $γ|_V$ is an embedding (This means that every inmersion is locally an embedding).

\solution
\doneby{Pedro}

Para empezar recordemos lo que era una \textbf{inmersión}: Sean $M$ y $N$ variedades diferenciables. Se dice que una función diferenciable $\appl{F}{M}{N}$ es una \textbf{inmersión} en $p$ si la diferencial $\appl{F_{*p}}{\tgs_pM}{\tgs_{F(p)}N}$ entre los espacios tangentes es inyectiva. Si $F$ es una inmersión para todo punto $p\in M$ decimos que es una \textbf{inmersión}.

Recordemos también lo que era un \textbf{embedding}: Si una \textbf{inmersión} es un homeomorfismo sobre su imagen, con la topología inducida en esta por $N$, decimos que es un \textbf{embedding}

Puesto que toda función diferenciable es continua podemos tomar un entorno de $γ(p)$ y calcular su preimagen, que será un entorno de $p$. La restricción de γ a este entorno será inyectiva, por ser inyectiva γ en general y será sobreyectiva por construcción por lo que será biyectiva. Así podemos garantizar que tendrá inversa diferenciable y por tanto se trata de un homeomorfismo sobre su imagen lo que implica que γ es un \textbf{embedding}
\end{problem}

\begin{problem}[6]
Consider the cylinder $C=\{(x,y,z) \in \real^3 \tq x^2+y^2=1\}$ and indentify the point $(x,y,z)$ with $(-x,-y,-z)$. Show that the quotient space of $C$ by this equivalence relation can be given a differentiable structure. (infinite Möbius band)
\solution

\doneby{Pedro}

Primero mostramos un ejemplo encontrado por internet que resuelve un problema muy similar a este.

\begin{center}
\includegraphics[keepaspectratio=true,width=\linewidth]{img/ejemplo_6.png}
\end{center}

Para dotar a un conjunto de estructura diferencial basta con encontrar un atlas para el cual se cumpla la definición de estructura diferencial sobre el conjunto dado.

Tomamos 8 cartas de la siguiente forma:
\begin{enumerate}
\item
\[\appl{\phi_1}{\{(x,y,z) \tq x\in [0,1), y \in [0,1), z \geq 0\}}{\real^3}\]
siendo $\phi_1=Id$
\item
\[\appl{\phi_2}{\{(x,y,z) \tq x\in (-1,0], y \in [0,1), z \geq 0\}}{\real^3}\]
siendo $\phi_2([x,y,z])=(-x,y,z)$
\item
\[\appl{\phi_3}{\{(x,y,z) \tq x\in [0,1), y \in (-1,0], z \geq 0\}}{\real^3}\]
siendo $\phi_3([x,y,z])=(x,-y,z)$
\item
\[\appl{\phi_4}{\{(x,y,z) \tq x\in [0,1), y \in [0,1), z \leq 0\}}{\real^3}\]
siendo $\phi_4([x,y,z])=(x,y,-z)$
\item
\[\appl{\phi_5}{\{(x,y,z) \tq x\in (-1,0], y \in (-1,0], z \geq 0\}}{\real^3}\]
siendo $\phi_5([x,y,z])=(-x,-y,z)$
\item
\[\appl{\phi_6}{\{(x,y,z) \tq x\in (-1,0], y \in [0,1), z \leq 0\}}{\real^3}\]
siendo $\phi_6([x,y,z])=(-x,y,-z)$
\item
\[\appl{\phi_7}{\{(x,y,z) \tq x\in [0,1), y \in (-1,0], z \leq 0\}}{\real^3}\]
siendo $\phi_7([x,y,z])=(x,-y,-z)$
\item
\[\appl{\phi_8}{\{(x,y,z) \tq x\in (-1,0], y \in (-1,0], z \leq 0\}}{\real^3}\]
siendo $\phi_8([x,y,z])=(-x,-y,-z)$

\end{enumerate}

La combinación de una de estas funciones con la inversa de otra no implicará más que cambios de signo sobre las variables de tal forma que
\[\phi_i\circ \inv{\phi_j}(x,y,z)=(\pm x, \pm y, \pm z)\]

Buscamos que estas combinaciones sean difeomorfismos en el entorno en el que están definidas (la intersección de sus dominios) (\ref{defVariedadDiferenciable}) y queda claro que estas aplicaciones son $C^{\infty}$ y sus inversas, que son de la misma forma, también. Conviene observar que el jacobiano vale siempre $\pm 1$.

Por ejemplo, $Φ_7\circ Φ_8^{-1} (-x,-y,-z) = Φ_7([x,y,z]) = (x,-y,-z)$ en $U_7 ∩ U_8 = \{(x,y,z) \tq x=0, y∈(-1,0], z≤0\}$.
\end{problem}

\section{Integración en variedades}

La teoría de estos ejercicios de \cite[Capítulo 4]{doCarmo94} está en el capítulo \ref{chapIntegracion}.

\begin{problem}[2]
\ppart Sea $ω = x \dif y - y \dif x$ y $\inmr{j}{M}{ℝ^2}$ la inmersión de una región con borde $∂M$. Demuestra que el área de $M$ viene dada por \[ \mop{\acute{A}rea} M = \frac{1}{2} \int_{∂M} j^* ω \]

\ppart Sea $ω = x \dif y \y \dif z - y \dif x \y \dif z + z \dif x \y \dif y$ y $\inmr{j}{M}{ℝ^3}$ la inmersión de una región con borde regular $∂M$. Demuestra que el volumen de $M$ viene dado por \[ \mop{Vol} M = \frac{1}{3} \int_{∂M} j^* ω \]

\ppart Generaliza estos resultados para $ℝ^n$.
\solution
\doneby{Guille}

\spart Sabemos que el área de la variedad viene dada por la integral de la 2-forma constante $1$ sobre toda la variedad, esto es, \[ \mop{\acute{A}rea} M = \int_M 1 \df{x,y}\]

¿Qué ocurre si calculamos la diferencial de ω? Tenemos que \[ \dif ω = \dif x \y \dif y - \dif y \y \dif x = 2 \dif x \y \dif y \], es decir, 2 veces la 2-forma constante 1. Así, podemos pasar de la integral en toda la variedad a la integral en el borde a través de Stokes (\ref{thmStokes}) y nos queda que \[ \frac{1}{2} \int_{∂M} j^* ω \eqexpl{Stokes} \frac{1}{2} \int_M \dif ω = \frac{1}{2} \int_M 2 \dif x \y \dif y = \int_M \dif x \y \dif y = \mop{\acute{A}rea} M \]

\spart No es muy difícil volver a seguir el procedimiento de antes para ver que $\dif ω = 3 \dif x \y \dif y \y \dif z$ haciendo los cambios de signo correspondientes. Igual que antes, el volumen será la integral de la 3-forma constante $1$ sobre toda la variedad, así que por Stokes podremos convertir la integral sobre el borde a una integral de $\dif ω$ sobre la variedad y tendremos el resultado de nuevo.

\spart Parece claro que el resultado va a salir para todos los casos. La cuestión es formalizarlo bien, sobre todo la forma diferencial esa.

Sean $x_1, \dotsc, x_n$ las coordenadas de $ℝ^n$. Entonces definimos \[ ω = \sum_{i=1}^n \left((-1)^{i-1} x_i \bigwedge_{\substack{k = 1 \\ k ≠ i}}^n \dif x_k \right)\], poniendo ese $(-1)^{i-1}$ para compensar los cambios de signo que tendremos que hacer al sacar la diferencial

Obtenemos ahora su diferencial exterior, y nos queda que \[ \dif ω = \sum_{i=1}^n \left((-1)^{i-1} \dif x_i \bigwedge_{\substack{k = 1 \\ k ≠ i}}^n \dif x_k \right) = \sum_{i=1}^n \bigwedge_{k=1}^n \dif x_k = n \dif x_1 \y \dotsb \y \dif x_n \]

Ahora podemos aplicar Stokes. Sabemos que el volumen (o como quiera que se llame el mismo concepto para variedades $n$-dimensionales) viene dado por la integral de la $n$-forma constante $1$ sobre toda la variedad, así que \[ \frac{1}{n} \int_{∂M} j^* ω \eqexpl{Stokes} \frac{1}{n} \int_M \dif ω = \int_M \dif x_1 \y \dotsb \y \dif x_n = \mop{Hipervol.} M \]

\end{problem}

\begin{problem}[7]
Sean $ω_1, ω_2$ formas diferenciales en una variedad diferenciable $M$. Supongamos que ambas son cerradas y que $ω_2$ es exacta. Demuestra que $ω_1 \y ω_2$ es cerrada y exacta.

\solution

\doneby{Guille}

Una forma $ω$ es cerrada (\ref{defFormaCerrada}) si $\dif ω = 0$, y es exacta (\ref{defFormaExacta}) si existe otra forma $α$ tal que $\dif α = ω$. Luego lo que tenemos es que $\dif ω_1 = \dif ω_2 = 0$ y que además existe $α$ tal que $\dif α = ω_2$.

Vamos a ver primero si $ω_1 ∧ ω_2$ es cerrada. Calculamos su diferencial y vemos que \[ \dif(ω_1∧ω_2) = \dif ω_1 ∧ ω_2 \pm ω_1 ∧ \dif ω_2 = 0 \] ya que ambas son cerradas, luego $ω_1 ∧ ω_2$ es cerrada.

Se puede ver también que $ω_1 \y ω_2$. Fijándonos en la definición de la diferencial del producto exterior, podemos calcular \[ \dif(ω_1∧α) = \dif ω_1 ∧ α + (-1)^p ω_1 ∧ \dif α = (-1)^p ω_1 \y ω_2 \], con $p$ el grado de α. Si $p$ es impar y nos sale un signo negativo, simplemente cogemos $- ω_1 ∧ α$ para que nos dé $\dif(-ω_1 ∧ α) = ω_1 \y ω_2$.
\end{problem}

\begin{problem}[8] \label{ejIntegracion-8}
Sea $M^n$ una variedad orientable compacta sin borde, y sea ω una $(n-1)$-forma diferenciable en $M^n$. Demuestra que existe un punto $p∈M$ tal que $(\dif ω)_p = 0$.
\solution
\end{problem}

\begin{problem}[9] Demuestra que no existe ninguna inmersión $\appl{f}{\crc}{ℝ}$ de la circunferencia unidad en la recta real $ℝ$.

\textit{Sugerencia}: Utiliza el ejercicio \ref{ejIntegracion-8}.
\solution

\doneby{Guille}

Vamos a definir $ω = x$ como una $0$-forma en $ℝ$ (tomando como coordenada $x$). En ese caso, $\dif ω = \dif x ≠ 0$ para todo punto de $ℝ$, y por lo tanto $f^*(\dif ω)$ es constante. Tiene que ser además distinto de cero por las propiedades del pullback.

Ahora bien, $f^*(\dif ω) = \dif (f^*ω)$, una $1$-forma diferenciable en $\crc$, y por el ejercicio \ref{ejIntegracion-8} tiene que existir un punto $p ∈ \crc$ tal que $(\dif (f^*ω))_p = 0$, contradicción porque antes habíamos dicho que $\dif(f^*\dif ω)$ era constante distinto de cero.

\end{problem}

\begin{problem}[12] \label{ejIntegracion-12}
Sea $M^n$ una variedad diferenciable compacta sin borde. Demuestra que $M$ es orientable si y sólo si existe una $n$-forma diferencial ω definida en $M$ que no es nula en ningún punto.

\textit{Sugerencia}: Para demostrar que esto ocurre ``sólo si'', usa una partición de la unidad para construir una $n$-forma no nula definida globalmente en $M$.
\solution

Esto está hecho en la demostración de la proposición \ref{propEquivalenciaOrientacion}.

\end{problem}

\begin{problem}[13] Sea $M$ una variedad diferenciable compacta y orientable sin borde. Demuestra que $M$ no se puede contraer a un punto.

\textit{Sugerencia}: Utiliza el ejercicio \ref{ejIntegracion-12}, el lema de Poincaré (\ref{thmPoincare}) y el teorema de Stokes (\ref{thmStokes}).
\solution

\doneby{Guille}

Hagámoslo por reducción al absurdo y supongamos que sí se puede contraer a un punto.

Por el ejercicio \ref{ejIntegracion-12} y por ser $M$ compacta y orientable, existe una $n$-forma ω que no se anula en ningún punto de $M$. Como es una $n$-forma, está claro que\footnote{No tenemos más variables, al sacar la diferencial repetiremos diferenciales y el producto exterior de diferenciales repetidas es 0.} $\dif ω = 0$.

Si $M$ se puede contraer a un punto, entonces cualquier abierto es contractible y podemos aplicar el lema de Poincaré \ref{thmPoincare}, que nos dice que en este caso cualquier forma cerrada es exacta (y viceversa). Como acabamos de decir que $\dif ω = 0$, entonces ω es cerrada, luego también es exacta por Poincaré y entonces existirá una $(n-1)$-forma α tal que $\dif α = ω$.

Vamos a probar a integrar entonces $ω = \dif α$ sobre la variedad. Usando Stokes, tenemos que \[ I = \int_X ω \eqexpl{Poincaré} \int_X \dif α \eqexpl{Stokes} \int_{∂X} i^* α \]

Ahora bien, como $M$ no tiene borde ($∂X = ∅$), la integral $I$ sólo puede ser 0, luego es obligatorio que $\int_X ω = 0$. Pero $X$ no es vacío, así que lo único que nos queda es que en algún momento esa integral de ω se anule. Esto no puede ocurrir porque habíamos dicho que ω no se anulaba en ningún punto, sólo puede ser positiva o negativa, y es imposible entonces que esa integral se anule. Contradicción, por lo que $M$ no se puede contraer a un punto.

\end{problem}

\begin{problem}[14]
Sean $A,B,C$ funciones diferenciables en $ℝ^3$. Consideramos el siguiente sistema de ecuaciones diferenciales \begin{align*}
A &= \dpa{R}{y} - \dpa{Q}{z} \\
B &= \dpa{P}{z} - \dpa{R}{x} \\
C &= \dpa{Q}{x} - \dpa{P}{y}
\end{align*} donde $P,Q,R$ son funciones desconocidas en $ℝ^3$.

\ppart Demuestra que \[ \dpa{A}{x} + \dpa{B}{y} + \dpa{C}{z} = 0\] es condición necesaria y suficiente para que exista una solución.

\textit{Sugerencia}: Considera la forma diferencial en $ℝ^3$ dada por \[ ω = A \dif y \y \dif z + B \dif z \y \dif x + C \dif x \y \dif y\] y calcula su diferencial exterior. Por el lema de Poincaré, $\dif ω = 0$ si y sólo si existe una forma $α = P\dif x + Q \dif y + R \dif z$ con $\dif α = ω$, esta última condición es precisamente el sistema anterior.

\ppart Supongamos que la condición anterior se satisface y determina las funciones $P,Q,R$.

\textit{Sugerencia}: Considera la contración $H(p,t) = tp$ de $ℝ^3$  a $(0,0,0)$. Entonces \[ \gor{ω} = H^*ω = A(tx,ty,tz)(y t \dif t \y \dif z - zt \dif t \y \dif y) + \dotsb + \text{términos sin } \dif t \]

Así la forma α del apartado anterior vendría dada por \[ α = I \gor{ω} = \left(\int_0^1 A(tx,ty,tz) t \dif t\right)(y\dif z - z \dif y) + \dotsb \]
\solution

\spart
\doneby{Guille}

Hacemos caso de la sugerencia y calculamos esa diferencial (voy a usar la notación $\dpa{A}{x} \equiv A_x$ porque no me apetece escribir):
\begin{multline*}
\dif ω = A_x \dif x ∧ \dif y ∧ \dif z + B_y \dif y ∧ \dif z ∧ \dif x + C_z \dif z ∧ \dif x ∧ \dif y = \\
= \left( A_x + B_y + C_z \right) \dif x ∧ \dif y ∧ \dif z
\end{multline*}

Por lo tanto, decir que $\dif ω = 0$ es lo mismo que decir que se cumple la condición del apartado. Calculamos ahora la diferencial del $α$ que nos dan y vemos que \begin{multline*}
\dif α = P_y \dif y ∧ \dif x + P_z \dif z \y \dif x + Q_x \dif x ∧ \dif y + Q_z \dif z ∧ \dif y + R_x \dif x ∧ \dif z + R_y \dif y ∧ \dif z = \\
= (R_y - Q_z) \dif y ∧ \dif z + (P_z -R_x) \dif z ∧ \dif x + (Q_z - P_y) \dif x ∧ \dif y
\end{multline*}

Si igualamos coordenada a coordenada, tenemos efectivamente el sistema que nos daban. Como en $ℝ^3$ podemos aplicar Poincaré sin ningún problema, tenemos que $\dif ω = 0 \iff \dif α = ω$, que es lo que nos pedían.

\spart
\end{problem}

\begin{problem}[16]\textit{(Teorema del punto fijo de Brouwer)}.

\ppart Sea $M^n$ una variedad diferenciable compacta y orientable con borde $∂M ≠ ∅$. Demuestra que no existe ninguna aplicación diferenciable $\appl{f}{M}{∂M}$ tal que la restricción $\restr{f}{∂M}$ sea la identidad.

\textit{Sugerencia}: Supongamos que $f$ existe, y sea ω la $(n-1)$-forma en $∂M$ definida en el ejercicio \ref{ejIntegracion-12}. Claramente $\dif(f^*ω) = f^*(\dif ω) = 0$, y por lo tanto \[ 0 = \int_M \dif(f^*ω) = \int_{∂M} i^* f^* ω = \int_{∂M} ω ≠ 0\], lo que sería una contradicción.

\ppart Demuestra el teorema del punto fijo de Brouwer: sea $B⊂ℝ^n$ la bola de radio 1. Toda aplicación diferenciable $\appl{g}{B}{B}$ tiene un punto fijo, esto es, existe $q∈B$ tal que $g(q) = q$.

\textit{Sugerencia}: Si $g(p) ≠ p$ para todo $p∈B$, el medio segmento que empieza en $g(p)$ y acaba en $p$ interseca $∂B$ en un punto único, digamos $q = f(p)$. Esta aplicación $\appl{f}{B}{∂B}$ así definida satisface las condiciones del apartado anterior y lleva a una contradicción.

\solution
\end{problem}

\section{fasc-4-ejemplos}

\subsection{Variedades}
\begin{problem}[2]
Estudiar, siguiendo el modelo de $S^2$ la estructura de variedad diferenciable, con dos cartas, en $S^n$

\solution
\doneby{Pedro}

Comenzamos considerando una esfera de radio 1 en $\real^n$ que tendrá la ecuación:
\[\sum_{i=1}^n x_i^2=1\]
y describiendo explícitamente el atlas de dos cartas dado por la proyección estereográfica.

Siguiendo el ejemplo de la hoja, consideramos la proyección tomando el polo norte $(1,0...0)$ y el plano $x_1=-1$. Posteriormente construiremos la segunda carta tomando el polo sur $(-1,0...0)$ y el plano $x_1=1$. Vamos a ello.

\textbf{Primera carta}

\begin{itemize}
\item Supongamos un punto $p$ cualquiera del plano $x_1=-1$:
\[p=(-1,x_2,...x_n)\]

Si construimos la recta que lo une con el polo norte y la intersecamos con la esfera $S^n$ obtenemos el punto intersección $q$.
\[q = \left(1-2t, x_2\cdot t,...,x_n\cdot t\right)\]
Si el punto es la intersección con la esfera, su módulo deberá ser 1. Utilizamos este dato para calcular $t$.

\[1+4t^2-4t+t^2\left(\sum_{i=2}^nx_i^2\right)=1 \implies 4t^2-4t+t^2\left(\sum_{i=2}^nx_i^2\right) = 0 \implies t=\frac{4}{\sum_{i=2}^nx_i^2+4}\]

Por tanto el punto de intersección es:
\[q=\left(1-\frac{8}{\sum_{i=2}^nx_i^2+4}, \frac{4x_2}{\sum_{i=2}^nx_i^2+4},...,\frac{4x_n}{\sum_{i=2}^nx_i^2+4} \right)\]

\item Al revés. Empezamos ahora con un punto
\[x\in S^n\tq x=(α_1...α_n) \text{ con } \sum_{i=1}^n α_i^2 = 1\]

Construimos ahora el vector que une este punto con el polo norte y lo intersecamos con el plano $x_1=-1$

La recta unión con el polo norte queda de la forma:
\[\left(1+t(α_1+1),α_2t,...,α_nt \right)\]
y forzamos la intersección de esta recta con el plano para conocer el punto
\[1+t(α_1+1)=-1 \implies t = \frac{-2}{α_1+1}\]
con lo que el punto sería:
\[\left( -1, \frac{-2α_2}{α_1-1}, ..., \frac{-2α_n}{α_1-1}\right)=\left( -1, \frac{2α_2}{1-α_1}, ..., \frac{2α_n}{1-α_1}\right)\footnote{En el ejmplo de la hoja creo que escriben $α_1$ en función de las otras coordenadas, pero no veo necesaria esta complicación}\]
\end{itemize}

\textbf{Segunda carta}
\begin{itemize}
\item Supongamos un punto $p$ cualquiera del plano $x_1=1$:
\[p=(1,x_2,...x_n)\]

Si construimos la recta que lo une con el polo sur y la intersecamos con la esfera $S^n$ obtenemos el punto intersección $q$.
\[q = \left(-1+2t, x_2\cdot t,...,x_n\cdot t\right)\]
Si el punto es la intersección con la esfera, su módulo deberá ser 1. Utilizamos este dato para calcular $t$.

\[1+4t^2-4t+t^2\left(\sum_{i=2}^nx_i^2\right)=1 \implies 4t^2-4t+t^2\left(\sum_{i=2}^nx_i^2\right) = 0 \implies t=\frac{4}{\sum_{i=2}^nx_i^2+4}\]

Por tanto el punto de intersección es:
\[q=\left(-1+\frac{8}{\sum_{i=2}^nx_i^2+4}, \frac{4x_2}{\sum_{i=2}^nx_i^2+4},...,\frac{4x_n}{\sum_{i=2}^nx_i^2+4} \right)\]

\item Al revés. Empezamos ahora con un punto
\[x\in S^n\tq x=(α_1...α_n) \text{ con } \sum_{i=1}^n α_i^2 = 1\]

Construimos ahora el vector que une este punto con el polo sur y lo intersecamos con el plano $x_1=1$

La recta unión con el polo sur queda de la forma:
\[\left(-1+t(α_1+1),α_2t,...,α_nt \right)\]
y forzamos la intersección de esta recta con el plano para conocer el punto
\[-1+t(α_1+1)=1 \implies t = \frac{2}{α_1+1}\]
con lo que el punto sería:
\[\left( 1, \frac{-2α_2}{α_1+1}, ..., \frac{-2α_n}{α_1+1}\right))\]
\end{itemize}

Estudiamos ahora un punto cualquiera del plano $(-1,...x_n)$. Si lo mandamos en la esfera por la primera proyección que hemos calculado, llegamos al punto
\[\left(1-\frac{8}{\sum_{i=2}^nx_i^2+4}, \frac{4x_2}{\sum_{i=2}^nx_i^2+4},...,\frac{4x_n}{\sum_{i=2}^nx_i^2+4} \right)\]

Ahora calculamos la imagen directa de este punto por la segunda proyección estereográfica, con lo que llegamos a:
\[\left( 1, \frac{-2\frac{4x_2}{\sum_{i=2}^nx_i^2+4}}{2-\frac{8}{\sum_{i=2}^nx_i^2+4}}, ..., \frac{-2\frac{4x_n}{\sum_{i=2}^nx_i^2+4}}{2-\frac{8}{\sum_{i=2}^nx_i^2+4}}\right)=\left( 1, \frac{-4x_2}{\sum_{i=2}^nx_i^2},...,\frac{-4x_n}{\sum_{i=2}^nx_i^2}\right)\]

y podemos ver que se trata de un difeomorfismo sobre su imagen

\textcolor{blue}{En algún punto he metido la gamba con los signos porque debería salirme todo positivo. Pero ya he currado mucho con este ejercicio. Una paja y a seguir.}

\end{problem}



\begin{problem}[3]
Parametrizamos los puntos del hemisferio norte de la esfera $x_2 > 0$,
excluyendo el ecuador ($x_2 = 0$), en la forma $(θ, τ, + \sqrt{1 − θ^2 − τ^2})$ con
$θ^2 + τ^2 < 1$. Esto convierte al hemisferio norte en una carta coordenada, y podemos cubrir la esfera con seis cartas de este tipo tomando
como ecuador cada una de las intersecciones de la esfera con los planos
coordenados. COMPROBAR que, efectivamente, se trata de un atlas.

DEMOSTRAR que los dos atlas son equivalentes, viendo que los cambios
de carta de una carta de uno de ellos a una carta del otro inducen difeomorfismos.

\solution
\end{problem}

\begin{problem}[4]
Demostrar que no existe ninguna variedad diferenciable compacta que se pueda recubrir con una única carta coordenada
\solution

\doneby{Pedro}

Si una variedad se puede recubrir por una única carta será homeomorfa a un abierto de $\real^n$ y, consecuentemente, nunca podrá ser compacta.

Esta respuestá está basada en la proposición 1.28 del documento: \href{http://ocw.um.es/ciencias/geometria-y-topologia/material-de-clase-1/01-variedadesdiferenciablessubvariedades-v100901.pdf}{Variedades Diferenciales y Subvariedades.pdf}
\end{problem}

\begin{problem}[5]
Demostrar que toda variedad 1-dimensional compacta y conexa es difeomorfa a la circunferencia $S^2$
\solution

\doneby{Pedro}

Para empezar es obvio que en caso de haber un difeomorfismo entre una variedad y la circunferencia, la variedad ha de ser compacta y conexa, pues así lo es la circunferencia.

Para resolver este ejercicio me baso en la proposición VI.1.6 de \href{https://books.google.es/books?id=CAOjRFAMJFUC&pg=PA131&lpg=PA131&dq=variedad+1-dimensional&source=bl&ots=MLkMP7HMyo&sig=aLLSSaYknqPZhPsn-5jJM2MwPAc&hl=es&sa=X&ei=DeMeVZSOEczZPdLkgfgJ&ved=0CCcQ6AEwAQ#v=onepage&q&f=false}{documento.pdf}. Básicamente la copio como un bellaco pero ahí dejo el link para el que quiera profundizar.

\textcolor{blue}{Justo en la versión que se puede consultar gratis en Google han quitado las dos páginas clave en que salía esto. El lunes pillo el libro en ciencias y lo completo}

\end{problem}

\begin{problem}[6]
Demostrar, como consecuencia del teorema de invarianza del dominio, que si $n \neq m$, no pueden ser homeomorfos $\real^n$ y $\real^m$. Tampoco es posible que sean homeomorfos un abierto de $\real^n$ con uno de $\real^m$
\solution

\doneby{Pedro}

En el fascículo 2 que podemos encontrar en moodle aparece la demostración de este hecho, que repetimos a continuación.

Supongamos abiertos $U \subset \real^n$ y $V\subset \real^m$ y la función $\appl{F}{U}{V}$ un difeomorfismo, es decir, una aplicación biyectiva, infinitamente diferenciable y con inversa infinitamente diferenciable.

\begin{enumerate}
\item Consideramos la función $G$ que es la función inversa de $F$, de forma que $G \circ F = 1_U$ y $F \circ G = 1_V$ siendo $1_X$ la identidad dentro del conjunto $X$.

\item Aplicando la regla de la cadena obtenemos:
\[G_{*,F(p)}\circ F_{*,p} = (1_U)_{*,p} \text{ y }  F_{*,p} \circ G_{*,F(p)} = (1_V)_{*,F(p)}\]

\item Pero, puesto que la matriz de la diferencial es la matriz jacobiana sabemos que
\[(1_U)_{*,p} = 1_{\tgs_p} \text{ y } (1_V)_{*,F(p)} = 1_{\tgs_{F(p)}}\]

\item Puesto que las aplicaciones $F_{*,p}$ y $G_{*,F(p)}$ son inversas la una de la otra los espacios $\tgs_p$ y $ 1_{\tgs_{F(p)}}$ son necesariamente isomorfos y por tanto $n$ y $m$ son iguales
\end{enumerate}

De hecho es imposible un \textbf{homomorfismo} entre abiertos de $\real^n$ y $\real^m$ pero esto se trata de un resultado topológico cuya demostración no entraría en el temario de este curso.

No obstante podemos encontrar esta última demostración en el siguiente \href{http://www.cmat.edu.uy/~rpotrie/documentos/pdfs/invarianciadimension.pdf}{documentopdf}
\end{problem}

\begin{problem}[7]
Demostrar que, si $\appl{f}{M}{N}$ es una función continua y localmente inyectiva de variedades topologícas de dimensión $n$, entonces la imagen de todo abierto $U \subset M$ es un abierto de $N$. En particular, $f(M)\subset N$ debe ser un abierto, que puede ser toda la variedad $N$
\solution

\doneby{Pedro}

Esto es un resultado de Topología que no voy a rehacer ya que no le veo mucha relación con lo que estamos estudiando en esta asignatura.

Por comentar algo relacionado con lo que estamos viendo, he viso en Wikipedia, y cito textualmente: ``El teorema de la invariancia del dominio establece que una función continua y localmente inyectiva entre dos variedades topológicas n-dimensionales debe ser abierta.''
\end{problem}

\begin{problem}[8]
Sea $S$ el conjunto de sucesiones $\appl{σ}{\nat}{\real}$ de números reales.

Definimos una topología en $S$ exigiendo que todas las funciones naturales de proyección
\[\appl{μ_{i_1,i_2,...,i_n}}{S}{\real^n}\]
sean continuas.\footnote{Estas funciones básicamente llevan la sucesión a un vector de $\real^n$ formado por $n$ elementos de la sucesión.}

Definimos una función $\appl{F}{S}{S}$ mediante
\[F(x_0,x_1,...,x_n,...)=(x_1,x_2,...,x_n,...)\]
Demostrar que la función $F$ es continua e inyectia, pero su imagen no es un abierto de $S$

\solution


\end{problem}

\begin{problem}[9]
Sea $U$ una bola unidad abierta en $\real^n$. Comprobar que la aplicación
\[f(\vx)=\frac{\vx}{\sqrt{1-\norm{\vx}^2}}\]
es un difeomorfismo de $U$ en todo $\real^n$
\solution

\yoP

Para comprobar que $f$ es un difeomorfismo debemos ver que es diferenciable, biyectiva y con inversa diferenciable. Vamos a ello.

La función, descompuesta en coordenadas, queda de la forma:
\[f(\vx)=\left(\frac{x_1}{\sqrt{1-\norm{\vx}}}, \frac{x_2}{\sqrt{1-\norm{\vx}}}, ..., \frac{x_n}{\sqrt{1-\norm{\vx}}}\right)\]

Vamos a derivarla:
\[\frac{\partial f}{\partial x_i}=\left(\frac{x_1x_i}{(\sqrt{1-\norm{\vx}})^3},\frac{x_2x_i}{(\sqrt{1-\norm{\vx}})^3},..\frac{1}{\sqrt{1-\norm{\vx}}}+\frac{x_i^2}{(\sqrt{1-\norm{\vx}})^3}.,\frac{x_nx_i}{(\sqrt{1-\norm{\vx}})^3}\right)\]

Podemos observar que la derivada existe (y por tanto la función es diferenciable) en todo punto con norma distinta de 1. Puesto que nos estamos restringiendo a $U$ que es la bola unidad \textbf{abierta} no hay problema con esto.

Podemos ver de manera sencilla que la función es inyectvia pues la derivada nunca se anula y podemos ver que es sobreyectiva por contrucción. Para cualquier punto de $\real^n$ que tomemos podemos escribirlo como $f(\vx)$\footnote{Esto queda claro al calcular la función inversa, cosa que haremos a continuación}.

Por último nos queda estudiar la inversa.

\[f(\vx)=\vy \implies (y_1,....y_n)=\left(\frac{x_1}{\sqrt{1-\norm{\vx}}}, \frac{x_2}{\sqrt{1-\norm{\vx}}}, ..., \frac{x_n}{\sqrt{1-\norm{\vx}}}\right)\]

A ojo de buen cubero podemos ver que la función inversa sería
\[f^{-1}(\vy)=\frac{\vy}{\sqrt{1+\norm{\vy}}}\]
cosa que podemos comprobar fácilmente.

Resulta también trivial la observación de que esta función inversa también es diferenciable, por lo que queda claro que $f$ es un difeomorfismo.

\end{problem}


\subsection{Campos}
\begin{problem}[1]
(\textbf{Grupos uniparamétricos de automorfismos}) En cada uno de los siguientes ejemplos se da una familia uniparamétrica de automorfismos de $\real^n$ y se pide que se compruebe que es un grupo y determine el campo asociado (\textbf{generador infinitesimal del grupo}). En todos los casos el grupo es un grupo de transformaciones lineales y el campo es un campo lineal (coeficientes de grado a lo más uno)

\ppart Grupo de traslaciones
\[τ_1(x_1,...,x_n)=(x_1+t,x_2,...,x_n)\]

\ppart Grupo de homotecias
\[τ_t(x_1,...,x_n)=(e^tx_1, e^tx_2,...,e^tx_n\]

\ppart Sea $A$ una matriz $n\times n$. Definimo un grupo uniparamétrico de automorfismos, asociado a la matriz $A$, mediante
\[τ_t(X)=e^{tA}X\]
¿Es el primer ejemplo un caso particular de este?

\ppart
Supongamos ahora $n=2$, y sea
\[ \left( \begin{array}{cc}

\cos(t) & -\sin(t) \\
\sin(t) & \cos(t)

\end{array} \right)\]
la matriz de una rotación de ángulo variable $t$ en el plano. Definimos un grupo uniparamétrico de automorfismos
\[τ_t(x_1,x_2)=A(t)\cdot {x_1 \choose x_2}\]

¿Es este ejemplo un caso particular del c)?

\solution
\yoP

Para demostrar que cada uno de estos conjuntos es un grupo debemos identificar la operación que define el grupo, demostrar que es asociativa y encontrar el elemento neutro o identidad y el inverso.

\spart
La operación suma se define de la siguiente forma:
\[(τ_a+τ_b)(x_1,...,x_n)=(x_1+a+b,x_2,...,x_n)\]

Es evidente que la operación es asociativa, el elemento neutro es $τ_0$ y el inverso de $τ_t$ es $τ_{-t}$

Queda claro que es un grupo.

Vamos a encontrar el campo asociado. La teoría de lo que vamos a hacer a continuación viene en las páginas 73-74 de \href{http://matematicas.unex.es/~ricarfr/EcDiferenciales/LibroEDLat.pdf}{documento.pdf}

Básicamente nos da un teorema y su demostración. El teorema dice:

Sea $X$ un grupo uniparamétrico local de clase $k$. Para cada $f\in C^{\infty}(U)$ y $p \in U$ definimos
\[(Df)(p)=\lim_{t \to 0}\frac{f[X(t,p)]-f(p)}{t}\]
entonces $D \in D_k(U)$ y lo llamaremos generador infinitesimal de X.

El ejemplo concreto que vamos a hacer (o uno muy similar) así como los siguientes vienen resuletos al final de la página 16 de \href{http://matematicas.unex.es/~ricarfr/EcDiferenciales/LibroEDLat.pdf}{documento.pdf}

Así para este ejemplo tendríamos la aplicación flujo $\appl{\phi}{\real^{n+1}}{\real^n}$ siendo $\phi(x_1,...,x_n,t)=(x_1+t,x_2,...,x_n)$.

\[X = \left(\frac{\partial \phi}{\partial t}\right)_{t=0} \frac{\partial}{\partial x_i}=\frac{\partial}{\partial x}\]


\textbf{Del último documento mencionado cabe destacar:}

\begin{defn}[Generador\IS infinitesimal]
Sea $\{σ_t\}$ un grupo monoparamétrico de transformaciones de U. Llamamos \textbf{generador infinitesimal} de $\{σ_t\}$ al campo vectorial que asigna al punto $p$, el vector tangente a la curva $(-ε,ε)\to U$, $t \to σ_t(p)$

Consideremos $\appl{\phi}{\real \times U}{U}$ la aplicación flujo del grupo $\phi(t,p)=σ_t(p)$. entonces el generador infinitesimal puede considerarse
\[X = \sum_{i=1}^n \left( \frac{\partial \phi_i}{\partial t}\right)_{t=0}\frac{\partial}{\partial x_i}\]
\end{defn}

\end{problem}

\begin{problem}[2]
Sea $D$ el campo en $\real^2$ definido como
\[D=x \frac{\partial}{\partial x}+y \frac{\partial}{\partial y }\]

El campo está definido en todo el plano pero

\ppart Una integral primera definida en todo el plano es necesariamente constante

\ppart Para cada punto, diferente al origen hay un entorno en el que hay una integral primera. Determinar todas esas integrales primeras no globales y los abiertos máximos en que están definidas.
\solution


\yoP

\spart
Vamos a tratar de resolver y buscar la integral primera: funciones $H$ tales que $D(H) = 0$. Para ello, resolvemos el par de ecuaciones
\begin{align}
\frac{\partial H}{\partial x} &= \frac{1}{x} \implies H(x,y)=\log(x)+f(y)\\
\frac{\partial H}{\partial y} &= \frac{1}{y} \implies H(x,y)=\log(y)+g(x)
\end{align}

De donde concluimos que $H(x,y)=\log(x)+\log(y)$. El problema de esta integral primera es que no está definida en todo el plano.

Tenemos que buscar otra forma de encontrar integrales primeras definidas en todo el plano. Para ello resolvemos el sistema
\begin{align}
\frac{\partial H}{\partial x} &= -y \implies H(x,y)=-xy+f(y)\\
\frac{\partial H}{\partial y} &= x \implies H(x,y)=yx+g(x)
\end{align}

No hay elección posible de $C_1$ y $C_2$ que resuelva ese sistema. Sin embargo, el campo es no nulo en todo punto salvo en $(0,0)$, y tienen que existir integrales primeras en entornos de esos puntos. Así, sólo nos queda una opción, que $\dpa{H}{x} = \dpa{H}{y} = 0$, luego $H(x,y)$ tiene que ser constante.

Otro punto de vista es el siguiente: si resolvemos el sistema de EDOs asociado \begin{align*}
x'(t) &= x(t) \\
y'(t) &= y(t)
\end{align*} nos queda que las curvas solución son de la forma $γ(t) = (c_1e^t, c_2e^t)$. Cuando $t = 0$, $γ(0) = (c_1, c_2)$ luego está claro que las constantes son las coordenadas del punto inicial de la curva $(x_0, y_0) = (c_1, c_2)$.

Haciendo el corte de γ con el plano $x = 1$, tenemos \[ 1 = x_0e^t \implies t = - \log x_0 \], y sustituyendo en la ecuación de la segunda coordenada queda $y = \frac{y_0}{x_0}$, que efectivamente son curvas constantes.

\spart Retomamos el primer cálculo de integral primera que hicimos: $H(x,y)=\log(x)+\log(y)$

Estas integrales primeras están definidas en todo punto salvo en los ejes de coordenadas.

\end{problem}

\begin{problem}[3]
Estudiar el campo en el plano definido como
\[D=(y+x(1-x^2-y^2))\frac{\partial}{\partial x} + (-x+y(1-x^2-y^2))\frac{\partial}{\partial y}\]
usando, si te parece conveniente, un cambio a coordenadas polares.
\solution
\yoP

Vamos a ver las curvas solución o curvas integrales del campo. Básicamente esto consiste en buscar una función tal que en todo punto su vector tangente sea el dado por D. Es decir, que su derivada coincida con el campo.

Buscamos $\appl{α}{I}{\real^2}$ siendo $α(t)=(x(t),y(t))$, tal que
\begin{align}
\frac{dx}{dt} &= y+x(1-x^2-y^2) \\
\frac{dy}{dt} &= -x+y(1-x^2-y^2)
\end{align}

Dado que esto parece un tanto inmanejable vamos a atender al consejo dado y pasamos todo a coordenadas polares. Así el campo quedaría:
\[D=(r(\sin(\theta)+\cos(\theta)(1-r^2)))\left(\cos(\theta)\frac{\partial}{\partial r} - r\sin(\theta)\frac{\partial}{\partial \theta} \right)+\]
\[+(r(-\cos(\theta)+\sin(\theta)(1-r^2)))\left(\sin(\theta)\frac{\partial}{\partial r} + r\cos(\theta)\frac{\partial}{\partial \theta} \right)\]
operando un poco podemos dejarlo más bonito como:
\[D= r(1-r^2)\frac{\partial}{\partial r}+r^2\frac{\partial}{\partial \theta}\]

En estas condiciones podemos considerar $α(t)=(r(t),\theta(t))$ y al buscar la curva integral nos quedaría el sistema de ecuaciones:
\begin{align}
\frac{dr}{dt} &= r(1-r^2) \implies dt = \frac{dr}{r-r^3} \implies t=\log(r)-\frac{1}{2}\log(1-r^2) \\
\frac{d\theta}{dt} &= r^2 \implies d\theta=\frac{r^2dr}{r-r^2} \implies \theta = -\frac{1}{2}\log(1-r^2)
\end{align}

Si despejamos $t$ de la primera ecuación obtenemos:
\[r= \frac{-1 \pm \sqrt{1+e^t}}{e^t}\]
pero vemos que si tomamos la opción con el signo menos habrá valores de $t$ para los que la $r$ sea negativa lo que nos daría problemas en el $\log(r)$. Por tanto nos queda
\[α(t)=\left(\frac{-1 + \sqrt{1+e^t}}{e^t}, -\frac{1}{2}\log\left(\frac{2-2\sqrt{1+e^t}}{e^{2t}} \right)\right)\]

\textcolor{red}{TRIIIIIIIIIIIIIIIIPLEEEEEEEEEE}
\end{problem}

\begin{problem}[5]
Para cada uno de los campos $D_i$, definido en un abierto $U_i$ encontrar un sistema de coordenadas en el que el campo se endereza

\ppart
\[D_1 = x \frac{\partial}{\partial x}+2y\frac{\partial}{\partial y} \text{ siendo } U_i=\{(x,y) \tq x > 0\}\]

\ppart
\[D_2 = \frac{\partial}{\partial x}+\sin(x)\frac{\partial}{\partial y} \text{ siendo } U_2 = \real^2\]

\ppart
\[D_3 = x\frac{\partial}{\partial x}+(1-x^2)\frac{\partial}{\partial y} \text{ siendo } U_3 = \{(x,y) \tq -1 < x < 1\}\]

\solution

\spart
Para enderezar el campo calculamos su integral primera:
\[0 = D(H) = x\frac{\partial H}{\partial x}+2y\frac{\partial H}{\partial y}\]
Para resolver esta ecuación debemos resolver el sistema:
\begin{align*}
\frac{\partial H}{\partial x} &= -2y\\
\frac{\partial H}{\partial y} &= x
\end{align*}

de donde obtenemos nada porque no sale. Cuando esto no conduce a nada directamente, el remedio es calcular las curvas solución. Resolvemos
\begin{align*}
\od{x}{t} &= x \\
\od{y}{t} &= 2y
\end{align*} y nos da que
\begin{align*}
x(t) &= e^t x(0) \\
y(t) &= e^{2t} y(0)
\end{align*}

Ahora tenemos que cortar estas curvas solución con un plano. No puede ser el plano $x = 0$ porque no pasan por $x = 0$. Cortamos por un plano $y_0$ que no sé qué es, parece que es el punto donde estamos enderezando el campo. Resolvemos
\[ e^{2t} y(0) = y_0 \implies t = \frac{\log y_0 - \log y(0)}{2} \], que sustituyendo en $x(t)$ nos da \[ x = e^{\frac{\log y_0 - \log y(0)}{2}} x(0) = x \sqrt{\frac{y_0}{y(0)}} \] y entonces la función $H$ que buscamos es \[ H(x,y) =  x \sqrt{\frac{y_0}{y}} \]

Para enderezar el campo, hay que aplicar una fórmula de la que el profesor no se acuerda. A veces se ve pero en otros casos hay que hacer una integral de una función de $n$ variables integrando con respecto a una de ellas y en general es horroroso y no lo vamos a ver.

\spart

Para enderezar el campo calculamos su integral primera
\[0 = D(H) = \frac{\partial H}{\partial x}+\sin(x)\frac{\partial H}{\partial y}\]
Para resolver esta ecuación debemos resolver el sistema:
\begin{align}
\frac{\partial H}{\partial x} &= -\sin(x)\\
\frac{\partial H}{\partial y} &= 1
\end{align}

de donde obtenemos $H(x,y)=\cos(x)+y$

Ahora debemos buscar una función $G$ tal que $D(G)=1$ para ello basta con tomar $G(x,y)=x$

¿Determinan las funciones $H$ y $G$ un sistema de coordenadas locales? Para ello debemos estudiar el rango de su matriz jacobiana:
\[\left( \begin{array}{cc}
-\sin(x) & 1  \\
1 & 0  \end{array} \right)\]

y vemos que el determinante es siempre 1 por lo que tenemos un sistema de coordenadas locales en el entorno de cualquier punto del plano. Si conseguimos probar que el cambio de coordenadas es biyectivo, tendremos un sistema de coordenadas definido en todo el plano $\real^2$.

Tenemos pues el cambio de coordenadas:
\begin{align}
x_1 &= \cos(x)+y\\
y_1 &= x
\end{align}

que es claramente invertible siendo:
\begin{align}
x = y_1\\
y = x_1 - \cos(y_1)
\end{align}

Entonces, el campo $D$ se endereza en un sistema de coordenadas definido en todo el plano.

\spart
\yoP

Buscamos nuevamente una función $H$ que sea integral primera del campo. En este caso no es posible calcularla directamente, de modo que tendremos que hacer algo parecido a lo que hacíamos en el apartado \textbf{a)}.

Calculamos directamente la curva solución del campo:
\begin{align}
\dot{x}&=x \implies x(t)=e^tx(0)\\
\dot{y}&=(1-x^2) \implies y(t)=\int 1-e^{2t}x(0)^2 dt \implies y(t)=t-\frac{e^{2t}x(0)^2}{2}+y(0)+\frac{x(0)^2}{2}
\end{align}

Tomamos un punto en el que el campo no se anule como puede ser el punto $(1,0)$. Ahora debemos tomar una hipersuperficie que no contenga al vector $D_p$, que será el plano $x=1$. Veamos en qué punto la curva solución corta a esta hipersuperficie:

\[e^t x(0)= 1 \implies t = \log\left(\frac{1}{x(0)}\right)\]
lo que nos da un valor de la segunda coordenada del punto:
\[y(t)=\log\left(\frac{1}{x(0)}\right)-\frac{1}{2}+y(0)+\frac{x(0)^2}{2}\]

Concluimos que la integral primera del campo sería:
\[H(x,y)=\log\left(\frac{1}{x}\right)-\frac{1}{2}+y+\frac{x^2}{2}\]

Para cercionarnos de que todo está bien podemos comprobar de forma sencilla que $D(H)=0$.

Para terminar de enderezar el campo deberíamos encontrar una función $G$ tal que $D(G)=1$. Para ello basta con tomar $G(x,y)=\log(x)$. Así, nos queda que el cambio de variables que permite enderezar el campo es:
\begin{align}
x_1 = \log\left(\frac{1}{x}\right)-\frac{1}{2}+y+\frac{x^2}{2}
y_1 = \log(x)
\end{align}

Para comprobar en qué puntos este cambio de variables es válido estudiamos el rango de su matriz Jacobiana:

\[\left( \begin{array}{cc}
x-\frac{1}{x} & \frac{1}{x}  \\
1 & 0  \end{array} \right)\]

Pudiendo ver fácilmente que el rango es 2 salvo en $x=0$ donde se nos hace infinito y no estamos muy seguros de que ocurre.

A la hora de estudiar si el cambio de coordenadas es global posiblemente nos encontremos con que lo es salvo en los puntos con $x=0$. No obstante esta parte se deja como ejercicio para el lector.
\end{problem}

\begin{problem}[6]
Calcula el laplaciano
\[\frac{\partial^2}{\partial x^2}+\frac{\partial^2}{\partial y^2}\]

en coordenadas polares

\solution
\yoP

Siendo $x=r\cos(α)$ e $y=r\sin(α)$ tenemos
\[2(-\sin(α)+\cos(α))\frac{\partial}{\partial r}\frac{\partial}{\partial α}+r(-\cos(α)-\sin(α))\frac{\partial^2}{\partial α^2}\]
\end{problem}

\begin{problem}[7]
Expresar en coordenadas cilíndricas $(x=ρ\cos(α), y=ρ\sin(α), z=z)$ el campo
\[D= 2 \frac{\partial}{\partial x}-\frac{\partial}{\partial y}+3\frac{\partial}{\partial z}\]

\solution
\yoP

Simplemente tendremos que aplicar en la ecuación del campo los cambios:
\begin{align}
\frac{\partial}{\partial x} &= \cos(α)\frac{\partial}{\partial ρ}-ρ\sin(α)\frac{\partial}{\partial α}
\frac{\partial}{\partial y} &= \sin(α)\frac{\partial}{\partial ρ}+ρ\cos(α)\frac{\partial}{\partial α}
\end{align}

Con lo que nos queda:
\[D=(2\cos(α)-\sin(α))\frac{\partial}{\partial ρ}-(2ρ\sin(α)+ρ\cos(α))\frac{\partial}{\partial α}+3\frac{\partial}{\partial z}\]

\end{problem}

\begin{problem}[8]
Consideramos los campos en $\real^3$

\begin{align}
D_1 &=(2+y^2)e^z \frac{\partial}{\partial x}\\
D_2 &=2xy\frac{\partial}{\partial x}+(2+y^2)\frac{\partial}{\partial y}\\
D_3 &=2xy^2\frac{\partial}{\partial x} - y(2+y^2)\frac{\partial}{\partial y}+(2+y^2)\frac{\partial}{\partial z}
\end{align}

\ppart Demostrar que estos tres campos generan, en cada punto de $\real^3$, el espacio tangente en el punto

\ppart
Calcular también 3 1-formas tales que, en cada punto de $\real^3$, determinen la base dual de la formada por los 3 campos dados.
\solution
\yo

\spart
Para comprobar que los tres campos generan el espacio tangente basta con comprobar que los vectores que representan cada campo son linealmente independientes. Es decir, tenemos que ver que la siguiente matriz tiene rango máximo:
\[\left( \begin{array}{ccc}
(2+y^2)e^z & 0 & 0  \\
2xy & 2+y^2 & 0\\
2xy^2 & -y(2+y^2) & 2+y^2  \end{array} \right)\]

Podemos ver que el determinante de esta matriz es:
\[\left((2+y^2)e^z\right)\left(2+y^2 \right) \left(2+y^2 \right)\]
que podemos ver fácilmente que no se anula nunca, pues estamos siempre multiplicando términos no nulos.

\spart

Lo que nos están pidiendo son tres 1-formas $ω_i$ tales que $ω_i(D_j)=1$ si $i=j$ y $0$ en caso contrario. Lo que vamos a hacer es construir estas formas a mano, forzando que se cumplan estas propiedades:
\[ω_1 = \frac{1}{(2+y^2)e^z}+ady+bdz\]
con esto hemos asegurado $ω_1(D_1)=1$. Ahora calculamos $a$ y $b$ forzando $ω_1(D_2)=0$ y $ω_1(D_3)=0$.

Así nos queda
\[ω_1 = \frac{1}{(2+y^2)e^z}+- \frac{2xy}{(2+y^2)e^z(2+y^2)}dy+\left(-\frac{2xy^2}{(2+y^2)e^z})-\frac{2xy^2(2+y^2)}{(2+y^2)e^z(2+y^2)}\right)\frac{1}{2+y^2}dz\]

Ahora pasamos a calcular $ω_2$. Para forzar que al evaluarlo sobre el primer campo obtengamos un $0$ basta con hacer que no tenga componente dx. Y sabiendo que $ω_2(D_2)=1$ tenemos que
\[ω_2 = \frac{1}{2+y^2}dy+cdz\]
calculamos ahora $c$ forzando que $ω_2(D_3)=0$ con lo que nos queda:
\[ω_2 = \frac{1}{2+y^2}dy+\frac{y(2+y^2)}{(2+y^2)^2}dz\]

Por último y de forma trivial tenemos que
\[ω_3 = \frac{1}{2+y^2}dz\]

\textbf{Observación importante de Julián.}

Estas formas que hemos obtenido se corresponden con las filas de la inversa de la matriz de los campos. Este hecho que observamos y que podría parecer fortuito se produce siempre y tiene la siguiente explicación.

Si escribimos la matriz que tiene las formas $ω_i$ como filas y la multiplizamos por la izquierda por la matriz de los vectores de campo obtenemos en cada coordenada de la matriz solución:
\[a_{ij}=ω_i D_j\]
que coincide con la evaluación de la forma $ω_i$ en el campo $D_j$. Por la construcción de las $ω_i$, que son la base dual de la formada por los campos, obtenemos como resultado la matriz identidad.
\end{problem}

\begin{problem}[9] Sea $C = \gen{X,Y,Z}$ el espacio vectorial de dimensión 3 generado por los campos \[ X = z \dpa{}{y} - y\dpa{}{z} \quad Y = -z \dpa{}{x} + x \dpa{}{z} \quad Z = y\dpa{}{x} - x\dpa{}{y} \]

\ppart Demostrar que existe un isomorfismo $\appl{Φ}{C}{ℝ^3}$ tal que, para $D,D' ∈ C$, se tiene que \[ Φ([D,D']) = Φ(D) × Φ(D') \]

\ppart Demostrar que el flujo de un campo $D ∈ C$ está formado por rotaciones alrededor de un eje común. Encontrar la relación de ese eje con el vector $Φ(D)$.
\solution

\yo

\spart
El isomorfismo es $Φ(aX+bY+cZ) = (a,b,c)$, y hay que comprobar que el corchete de Lie es lo mismo que el producto vectorial.

\spart Tomamos por ejemplo el campo $X$. El campo es el mismo para todo $x$, luego sólo tenemos que considerar lo que ocurre en el plano $yz$. Y en ese plano, el campo es una rotación alrededor del origen. Es decir, que el flujo del campo $X$ son rotaciones a lo largo del vector $(1,0,0)$ que es casualmente $Φ(X)$.

Esto nos da la idea de que, para un campo $D$, el flujo va a ser una rotación alrededor del eje $Φ(D)$. Para demostrar esto, el profesor propone un argumento que consiste en transformar el eje de rotación en el $(1,0,0)$ de tal forma que se lleven flujos a flujos y demostrar que la rotación es alrededor de ese eje.

\end{problem}
