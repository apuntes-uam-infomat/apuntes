% -*- root: ../GeometriaDiferencial.tex -*-
\chapter{Campos vectoriales y formas diferenciales: Teoremas de Frobenius y Poincaré}

\section{Curvas integrales}

No sé si esto va aquí.

Si tenemos una aplicación $\appl{F}{X}{Y}$, entonces la definición de la diferencial en un punto \[ (DF)_x = \appl{F_{*, x}}{Π_x }{Π_{F(x)} Y} \] es la misma que para abiertos de $ℝ^n$.

Si $F$ es inyectiva y $D$ es un campo en $X$, entonces sí existe un campo $F_*(D)$ definido no en $Y$ sino en $F(X) ⊂ Y$.

Vamos a ver varios resultados en esto.

\begin{defn}[Curva\IS integral] Sea $\appl{γ}{I}{X}$ una curva donde $I = [-a, a]$ es un intervalo simétrico alrededor del origen, y $D$ un campo en $X$. Decimos que γ es una curva integral de $D$ por el punto $x_0$ si se cumple que $γ(0) = x_0$ y además $γ_*\left(\dpa{}{t}\right) = \restr{D}{γ(I)}$ donde $\dpa{}{t}$ es un campo de vectores que a cada punto le asigna el vector tangente a la curva.
\end{defn}

Supongamos por ejemplo que $D = \sum a_i(x_1, \dotsc, x_n) \dpa{}{x_i}$. Entonces, dada $γ(t) = (x_1(t), \dotsc, x_n(t))$, tendríamos que \[ γ_*\left(\dpa{}{t}\right) = \sum x_i'(t) \dpa{}{x_i}\] ya que recordemos que aplicar la función es sólo permutar los símbolos: \[ γ_* \left(\dpa{}{t}\right) f = \dpa{}{t} (f○γ) \]

Al igualar $D$ con la composición esa tendríamos que, para $i = 1, \dotsc, n$, \[ x_i'(t) = a_i(x_1(t), \dotsc, x_n(t))\]. Todo eso junto es un sistema de ecuaciones diferenciales ordinarias autónomo. Es decir, que el campo da lugar a un sistema de ecuaciones locales, que al resolverlo dan cosas.

Hay una definición y un teorema útiles en geometría. Vamos a verlos.

\begin{defn}[Caja] Dado $x_0$ un punto y $D$ un campo en $X$, se dice que una caja para $D$ en $x_0$ es una tripleta formada por un entorno abierto $U_0$ de $x_0$, un real $a > 0$ (o infinito) y una función $Φ$ que cumplen ciertas condiciones.

$Φ$ debe ser una función $\appl{Φ}{U_0 × (-a, a)}{X}$ diferenciable ($C^∞$). Además $∀x∈U_0$ fijo se obtiene una función $γ_x ≝ \appl{Φ(x, t)}{(-a, a)}{X}$ que define una curva integral en $X$. Dicho de otra forma, la función $Φ_0$ ``pega'' todas las curvas.

La última condición es que, $∀t ∈ (-a, a)$ fijo podemos definir una función $\appl{τ_t}{U_0}{X}$ que por definición es simplemente $τ_t ≝ Φ(x,t)$ y que cumple el ser un difeomorfismo de $U_0$ con su imagen.
\end{defn}

\begin{theorem} Para toda $D$ y $x_0 ∈ X$, existe una caja y además es única.

Además, si $t_1, t_2, t_1 + t_2 ∈ (-a, a)$, entonces $τ_{t_1+t_2} = τ_{t_1} ○ τ_{t_2} = τ_{t_2} ○ τ_{t_1}$.
\end{theorem}

Ese último enunciado del teorema nos da una especie de propiedad de grupo para τ. De hecho, a τ se le llama el \concept[Flujo\IS de un campo]{flujo de un campo}.

Por ejemplo, si vemos el campo de velocidades de un fluido estacionario, en el que la velocidad sólo depende del punto $x$ del fluido, la función $τ_t(x)$ nos da una progresión del líquido, cómo se mueven las partículas a lo largo del tiempo por la curva que pasa por $x$.

Geométricamente, un campo lo que hace es definir un flujo cuando se integra: para cada $t$, se obtiene una función que va de cada punto en el punto imagenpor el flujo, y ese movimiento determina las curvas solución y está determinado por ellas, por supuesto.

En este caso, se dice que el campo es el generador infinitesimal del flujo y el flujo se dice que es el flujo del campo flujo flujo flujo.

Hay dos teoremas importantes sobre los campos.

\begin{theorem} Sea $D$ un campo en $X$ y $x_0$ un punto en $X$ donde el campo no se anula ($D_{x_0} ≠ 0$). Entonces existe un sistema $y_1, \dotsc, y_n$ de coordenadas locales en un entorno de $x_0$ en el cual $D = \dpa{}{y_1}$.
\end{theorem}

Este teorema lo que está diciendo es que se puede cambiar de carta de forma que en la nueva carta el campo se escribe de esa forma. Es necesario que el campo no sea nulo, porque si no la derivada esa no se anularía.

Esto es importante porque en Geometría Diferencial a veces los problemas se resuelven de manera intrínseca, sin usar coordenadas locales. Pero cuando hagamos los cálculos en coordenadas locales, elegiremos un sistema mejor adaptado al problema para hacer el cálculo como si fuera en abiertos de $ℝ^n$. Lo que dice el teorema es que nos conviene usar las coordenadas locales esas para tener una expresión lo más simple posible.

La idea de la demostración del teorema es la siguiente. Tenemos el campo que no se anula en un punto, y consideramos una hipersuperficie dada por una función $f(x_1, \dotsc, x_n) = K$ constante. La curva solución del sistema que nos daría las nuevas coordenadas será una curva transversal a la superficie.

Entonces, para cada punto cerca de $x_0$, consideramos la curva solución y la cortamos con la hipersuperficie. Como el campo es transversal, todos los vectores hacen cosas y yo ya estoy muy perdido porque hasta el hobre este creo que se está peridiendo. Estoy empezando a escribir cosas sin sentido. Lo que $D = \dpa{}{y_1}$ significa es que $D(y_i)$ es cero si $i ≠ 1$.

Escribir el campo así es lo mismo que encontrar funciones tales que al derivarlas da cero y luego una función $y_1$ tal que vale 1. En definitiva, buscamos funciones que cumplen el sistema
\begin{align*}
D(y_2) = D(y_3) = \dotsb = D(y_n) &= 0 \\
D(y_1) &= 1
\end{align*}

Encontrar las que valen $0$ no es demasiado difícil.

Por definición, cada nosequé le pasa algo y es constante sobre las curvas solución, que implica ese sistema, que es lo que falta y es cierto porque si yo tengo una función en un entorno $x_0$ en el que estamos $f$ restringida a las curvas solución de $D$ es constante en tonces $D(f) = 0$. Esto es lo que me faltaría ver. Fijaros que $f$ restringida a las curvas solución es constante sobre cada curva, no constante entre diferenteces curvas. ¿Por qué es cierto esto? Por la definición de curva solución.

\textit{Guille: No he entendido puto nada de lo que ha dicho ni de lo que ha escrito. Pablo dice que sí pero no se lo cree ni él. Dudo que siquiera el profesor sepa qué puñetas ha dicho.}

\seprule

\begin{defn}[Integral\IS primera] La integral primera es algo que viene en la hoja

\end{defn}

Es fácil de ver que las $y_j$ de ese nuevo sistema de coordenadas son las integrales primeras.

Algo sobre las hojas. Tengo hambre y no voy a copiar mucho.

Habría que demostrar que todo eso es una carta. Habría que calcular el determinante de la matriz jacobiana (el wronskiano) y ver que no se anula en el punto.

\subsubsection{Ejemplos}

Supongamos la recta real $ℝ$ con coordenada $x$, y una partícula sometida a un potencial $U(x)$. Es decir, que la fuerza sobre la partícula es $F = -U'(x)$. Sabemos que $F = ma$, luego \[ -U'(x) = F = m a = m \od[2]{x(t)}{t} = \od{p}{t} \] donde $p = m \od{x}{t} = mv$ es el momento lineal.

Vamos a hacer el cálculo en un plano $xp$, donde $x$ es la coordenada y $p$ es el momento. En estas coordenadas, $\od{x}{t} = \frac{p}{m}$. Es decir, que con este truco hemos pasado a un sistema de ecuaciones de primer orden.

Esto se puede hacer como un campo \[ D = \frac{p}{m}\pd{}{x} - U'(x) \pd{}{p} \] en el plano. Busquemos las integrales primeras del campo: funciones $H$ tales que $D(H) = 0$. Sabemos que las integrales primeras existen localmente en entornos de puntos en los que el campo no se anule.

Para encontrarla, tenemos que resolver la ecuación en derivadas parciales \[ \frac{p}{m} \pd{H}{x} - U'(x) \pd{H}{p} = 0 \]

Para resolver eso escribimos \[ \pd{H}{x} = U'(x) \qquad \pd{H}{p} = \frac{p}{m}\]

De la primera ecuación sacamos que $H(x,p) = U(x) + C(p)$. Derivando esto con respecto a $p$, tenemos que $\pd{H}{p} = C'(p) = \frac{p}{m}$, luego $C(p) = \frac{p^2}{2m}$, de tal forma que \[ H = U(x) + \frac{p^2}{2m} \]

Esta es la ecuación de la energía total del sistema o mecánica, donde $\frac{p^2}{2m}$ es la energía cinética. La energía mecánica se conserva así que eso de ahí es cosntante (y su derivada es cero).

Ahora bien, ¿qué haríamos para resolver el movimiento de la partícula? ¿Qué habría que hacer para continuar? ¿Cómo usamos el hecho de que la energía se mantiene constante?

Queremos conocer no ya la curva en el plano de fases $xp$, sino también su proyección en el eje $x$ en función del tiempo. Lo que hacemos es sustituir en la ecuación de antes $p$ por $m\od{x}{t}$, luego \[ H = U(x) + \frac{1}{2m}\left(m\od{x}{t}\right)^2 = E_0 \] donde $E_0$ es constante. Es decir, hemos pasado una ecuación de primer orden separable, que se reduce a una integral, y despejando y haciendo cosas e integrando se sale.

Otro ejemplo: consideramos un punto $(a,b) ∈ ℝ^2$, y consideramos para cada punto $(a,b)$ la parábola $y = x^2 + (b-a^2)$, que se peude parametrizar por $γ(t) = (t, t^2 + (b-a^2))$. ¿Cómo calculamos el campo cuyas curvas solución son esas? Tenemos que derivar. Es claro que el campo será \[ D_{(x,y)} = (1,2t) \] Resolviendo el sistema $D = \pd{}{x} + 2x \pd{}{y}$ nos queda que $x(t) = t +c_1$ y que $y(t) = t^2 + 2c_1 t + c_2$, es decir, las mismas curvas de las familias de antes con $a = c_1$ y $b =c_2$. El flujo está dado por \[ τ_t(x,y) = (t, t^2 + (y-x^2))\]

Vamos a buscar también enderezar el campo. Consideramos \[ D(H) = 0 = \pd{H}{x} + 2x \pd{H}{y} \] y haciendo lo mismo de antes la solución es $H(x,y) = -x^2 + y$, que está diciendo que las curvas solución están contenidas en parábolas, cosa que ya sabíamos desde el principio.

El resto del ejemplo es demostrar que el determinante de la mariz jacobiana es no nulo en todo punto y entonces las coorenadas locales que enderazan el campo son coordenadas globales en este caso, porque en todo punto la matriz jacobiana tiene detemrinante no nulo y se comprueba de hecho que es una carta loca, lse calcula la inversa, y luego hay un segundo ejemplo que no da tiempoa mirar hoy que es en una sola variable y que nosequé.
