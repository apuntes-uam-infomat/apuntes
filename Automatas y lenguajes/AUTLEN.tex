\documentclass{apuntes}

% Paquetes adicionales

% --------------------



\title{Autómatas y lenguajes}
\author{Pedro Valero y Alberto Parramón}

\date{2014/2015}
\usepackage{forest}

\begin{document}
\pagestyle{plain}

\maketitle
\tableofcontents
\newpage

\printindex

\chapter{Introducción}
Vamos a trabajar con tres elementos fundamentales:
\begin{itemize}
\item \textbf{Máquinas/Autómata}
\begin{itemize}
\item Autómatas finitos $\Rightarrow$ Expresiones regulares
\item Autómatas de pila $\Rightarrow$ Lenguajes independientes del contexto
\end{itemize}
\item \textbf{Problemas} ¿Qué se puede computar?. Conjeturas que se creen ciertas pero cuya veracidad, por ahora, no se ha demostrado.

\item \textbf{Lenguajes/Gramática}
\end{itemize}

Nuestro objetivo es ver qué relación existe entre estos tres elementos. Para ello, primero debemos establecer algunas definiciones.

\section{Lenguaje}
\begin{defn}[Símbolo]
``Letra", elemento de un conjunto
\end{defn}

\begin{defn}[Alfabeto]
Conjunto finito de símbolos no vacío.
\end{defn}

\begin{defn}[Palabra (Cadena)]
Secuencia finita de símbolos tomados de un alfabeto.
La palabra vacía tiene 0 símbolos y se representa por $\lambda$.
\end{defn}

Será conveniente acostumbrarnos a usar el término ``cadena'' en lugar del término ``palabra'' ya que representa mejor el concepto que queremos representar.


\begin{defn}[Longitud de cadena]
Número de símbolos que contiene.
\end{defn}

\begin{defn}[Lenguaje]
Conjunto de palabras, cualquier subconjunto de $\Sigma^*$.
\end{defn}

Hay algunos casos particulares de lenguajes:
\subsection{Lenguajes particulares}
\begin{defn}[Lenguaje universal (sobre $\sum$)]
Denotado por $\sum^*$ representa el conjunto de todas las palabras que se pueden formar con los símbolos de $\Sigma$, incluido $\lambda$.
\end{defn}

\begin{defn}[Lenguaje de un autómata]
Conjunto de palabras que acaban en un estado final del autómata y, por tanto, son aceptadas por el mismo.
\end{defn}

\begin{defn}[Lenguaje vacío]
Lenguaje que no contiene ningún elemento: $\phi$.
\end{defn}

\begin{defn}[Lenguaje $\lbrace \lambda \rbrace$]
Lenguaje que sólo contiene $\lambda$.
\end{defn}
El lenguaje $\lbrace \lambda \rbrace$ es distinto del lenguaje vacío aunque $\lambda$ sea la palabra vacía. En particular $|\{\lambda\}|=1$ y $|\phi|=0$.

\begin{defn}[Lenguaje $\Sigma^+$ ]
\[ \Sigma^+ = \Sigma \setminus \lbrace \lambda \rbrace \]
\end{defn}

\begin{defn}[Lenguajes Regulares]
Son lenguajes que pueden ser admitidos por autómatas finitos.
\end{defn}

\subsection{Operadores de utilidad}
Tenemos dos operadores importantes:
\begin{enumerate}
\item \begin{defn}[Cierre estrella (star-closure)]
El operador estrella se corresponde con la suma infinita:
\[a^* = \lambda + a + a^2 + a^3 + ...\]

\end{defn}
\item \begin{defn}[Cierre positivo (positive-closure)]
Este operador se corresponde con la suma infinita:
\[a^+ = a + a^2 + a^3 + ...\]
\end{defn}
\end{enumerate}
En otras palabras, estos conceptos nos sirven para entender por qué $\Sigma ^*$  representa todas las palabras posibles. Para poder entender esto debemos entender la multiplicación como una concatenación y la suma como un \textit{OR}. Así el ``elemento neutro del producto'' sería la cadena vacía.

Tomemos ahora el alfabeto binario $\Sigma = \lbrace 0, 1 \rbrace$
Entonces:
\[\Sigma ^* = (0+1)^* = \lambda + (0+1)+(0+1)^2+(0+1)^3+... = \]
\[= \lambda + 0 + 1 + 00 + 01 +10 +11 +000+001+010+011+100+101+110+111+...\]
Y con esto vemos cómo se forman todas las posibles combinaciones de bits de diferente longitud. Si en lugar de este alfabeto hubiésemos tomado nuestro alfabeto castellano, habríamos obtenido todas las posibles combinaciones de letras.

Si cada conjunto de símbolos representa una cadena, es lógico pensar que no tiene sentido la operación suma como la hemos conocido siempre. La forma de entenderlo es que si yo tengo la palabra \textit{abc} y también tengo la palabra \textit{cda}, en total tengo \textit{abc}+\textit{cda}, es decir, tengo ambas palabras (unión).

\section{Expresiones regulares}

\begin{defn}[Expresión regular]
Forma alternativa de representar un lenguaje regular.
\end{defn}

Dado un alfabeto $\Sigma$ existen tres tipos de expresiones regulares primitivas:
\begin{enumerate}
\item $\emptyset$

L($\emptyset$) = $\emptyset$
\item $\lambda$

 L($\lambda$)=$\lbrace \lambda \rbrace$
\item $a\in \Sigma$

L($a$) = $\lbrace a \rbrace$
\end{enumerate}

A partir de estas expresiones regulares primitivas podemos construir expresiones regulares compuestas aplicando la siguiente regla:

Siendo $\alpha, \beta$ dos expresiones regulares primitivas o compuestas sobre $\Sigma$ también lo son:
\begin{enumerate}
\item $\alpha + \beta$ (Unión de lenguajes)

L($\alpha + \beta$) = L($\alpha $) $\cup$ L($\beta$)
\item $\alpha . \beta$ (Concatenación de lenguajes)

L($\alpha . \beta$) = L($\alpha $). L($\beta$)
\item $\alpha^*$ (Cierre)

L($\alpha^*$) = L($\alpha$)$^*$

L($\beta^*$) = L($\beta$)$^*$

El cierre es la repetición de cero o más veces de las expresiones regulares a las que aplica.
\end{enumerate}

Orden de precedencia de los operadores (de más a menos):
\begin{enumerate}
\item *
\item .
\item +
\end{enumerate}
Cuando la precedencia no esté clara o se quiera alterar, se pueden (y deben) usar paréntesis.

\begin{example}
Encontrar los lenguajes definidos por las siguientes expresiones regulares:
\begin{enumerate}
\item$a.(b+a).b$\\
 Cadenas de tres símbolos que empiezan por 'a' y acaban por 'b' y el símbolo central es una 'a' o una 'b': \{abb,aab\}
\item $(a+b)$\\
Cadenas de un solo símbolo, que es o 'a' o 'b': \{a,b\}
\item $(a+b)*$\\
Todas las cadenas posibles formadas por los símbolos a y b (incluso la cadena vacía)
\item $(a+b).(a+b)*$ \\
Todas las cadenas posibles formadas por los símbolos a y b. Pero no incluye la cadena vacía ya que por $(a+b)$ necesariamente deben contener una 'a' o una 'b'.
\item $(aa+bb)*$ \\
Todas las cadenas posibles formadas por 'a' y 'b' con la condición de que siempre aparezcan los símbolos consecutivos un número par de veces. Es decir, cadenas del tipo 'aaaabbaabbbbbb', (no valdría 'aaabb') (incluyendo la cadena vacía).

\end{enumerate}

\end{example}


\chapter{Gramática}
\begin{defn}[Gramática]
Hay varias definiciones para este término. No son muy precisas pero nos dan una idea de su significado:
\begin{enumerate}
\item Mecanismo para formalizar matemáticamente un lenguaje.
\item Conjunto de reglas que determinan cómo formar las cadenas de un lenguaje.
\end{enumerate}
\end{defn}

\begin{example}
Tomemos las reglas:
\begin{enumerate}
\item ORACIÓN $\rightarrow$ SUJETO PREDICADO
\item SUJETO $\rightarrow$ ARTÍCULO NOMBRE
\item PREDICADO $\rightarrow$ VERBO
\item ARTÍCULO $\rightarrow$ el | un
\item NOMBRE $\rightarrow$ coche | perro
\item VERBO $\rightarrow$ come | corre
\end{enumerate}
Estas reglas constituyen una gramática que nos permite generar un lenguaje. En este caso el lenguaje estaría por formado todas las cadenas que se pueden construir a partir de estas reglas. Empezando siempre por el axioma (en este caso: ``ORACIÓN'').
%TODO Ejemplo de árbol de derivación con estas reglas
\end{example}

Una gramática está compuesta por una serie de elementos que definiremos a continuación.

\begin{defn}[Símbolos terminales (T)]
Conjunto de símbolos que pueden aparecer en la cadena final (o sentencia). En el ejemplo anterior serían elementos terminales aquellos escritos en minúscula. Para ellos no existe ninguna regla que indique cómo se derivan.
\end{defn}

\newpage
\begin{defn}[Símbolos no terminales (N)]
Conjunto de símbolos que no pueden aparecer en la cadena final. Simplemente son usados para definir las reglas de derivación.
\end{defn}

\noindent Los conjuntos T y N deben ser disjuntos, es decir $T \cap N = \emptyset$. Utilizaremos el símbolo $\Sigma$ para referirnos a la unión de ambos, $\Sigma = T \cup N$.

\begin{defn}[Reglas de producción (P)]
Explican cómo se transforma un símbolo no terminal en un conjunto de símbolos terminales y/o no terminales.
\end{defn}

\begin{defn}[Símbolo inicial / Axioma (S)]
Indica dónde empieza a construirse la cadena. En el ejemplo anterior, el axioma sería el símbolo ORACIÓN. Una gramática sólo puede tener un único axioma.
\end{defn}

\begin{defn}[Gramática (G)]
Cuádrupla formada por T, N, P y S.

\[ G = ( T, N, P, S) \]
\end{defn}

Una gramática permite generar cadenas para un lenguaje. Por ejemplo, para la gramática anterior:

ORACIÓN $\rightarrow$ (derivamos ORACIÓN:)

SUJETO PREDICADO $\rightarrow$ (derivamos SUJETO:)

ARTÍCULO NOMBRE PREDICADO $\rightarrow$ (derivamos ARTÍCULO:)

el NOMBRE PREDICADO $\rightarrow$ (derivamos NOMBRE;)

el coche PREDICADO $\rightarrow$ (derivamos PREDICADO:)

el coche VERBO $\rightarrow$ (derivamos VERBO:)

el coche corre (acabamos, pues no hay más que derivar)

Este proceso se llama derivación. Cada una de las cadenas en una derivación se denomina {\em forma sentencial}. La última de ellas es una cadena válida del lenguaje generado por la gramática, y se denomina {\em sentencia}. Está formada únicamente por símbolos terminales de la gramática. El lenguaje generado por una gramática, $L(G)$, es el conjunto de todas las sentencias posibles, es decir, el conjunto de todas las cadenas de símbolos no terminales que pueden derivarse a partir del axioma.

Vamos a ver algunos ejemplos de gramáticas y los lenguajes que generan:
\begin{example}
Tomemos la gramática generada por las reglas:
\begin{enumerate}
\item S $\rightarrow$ aSb
\item S $\rightarrow$ $\lambda$
\end{enumerate}

\begin{gather*}
T = \lbrace a, b \rbrace \\
N = \lbrace S \rbrace
\end{gather*}

Y su axioma es S.

El lenguaje generado por esta gramática serían todas las palabras de la forma: $a^i b^i$ con $ i=0,1,... \infty$
\end{example}

\begin{example}
Ahora vamos a tratar de construir la gramática que define un lenguaje dado:
L=$\lbrace (ab)^na, n \geq 0 \rbrace$

La gramática que define este lenguaje es:
\begin{enumerate}
\item S $\rightarrow$ abS
\item S $\rightarrow$ a
\end{enumerate}

El autómata finito asociado a este lenguaje sería:
\begin{center}
\includegraphics[scale=0.75]{automata1.png}
\end{center}
\end{example}


\begin{defn}[Gramáticas independientes del contexto]
Son aquellas cuyas reglas tienen un único símbolo no terminal en el lado izquierdo.
\end{defn}


\begin{example}[Gramática dependiente de contexto]
\begin{itemize}
\item aSb $\rightarrow$ abb
\item cSd $\rightarrow$ cdd
\end{itemize}
S puede derivarse dependiendo de lo que la rodee, es decir, de su contexto.
\end{example}

\begin{example}[Gramática independiente de contexto (regular)]
\begin{itemize}
\item A $\rightarrow$ aA
\item A $\rightarrow$ a
\end{itemize}
A la derecha tenemos únicamente símbolos terminales o bien símbolos terminales acompañados de un único símbolo no terminal.
Si el elemento no terminal está a la izquierda se denomina gramática lineal por la izquierda. En caso contrario, gramática lineal por la derecha.
\end{example}

\newpage
{\bf Nota a lo anterior:} Una gramática es {\em lineal por la derecha} (right-linear) si todas sus reglas de producción son de una de las dos formas siguientes:

\begin{itemize}
\item B $\rightarrow$ aA
\item B $\rightarrow$ a
\end{itemize}

\noindent con $A, B \in N$ y $a \in T^{*}$. Una gramática es {\em lineal por la izquierda} (left-linear) si todas sus reglas de producción son de una de las dos formas siguientes:

\begin{itemize}
\item B $\rightarrow$ Aa
\item B $\rightarrow$ a
\end{itemize}

\noindent con $A, B \in N$ y $a \in T^{*}$. Una gramática es {\em regular} si es lineal por la izquierda o lineal por la derecha. Todas las gramáticas regulares son independientes del contexto.

\begin{defn}[Equivalencia de gramáticas]
Dos gramáticas son equivalentes si generan el mismo lenguaje
\end{defn}

\section{Gramáticas independientes del contexto}
Como ya vimos una gramática puede representarse como una cuádrupla G=(N,T,S,P), es decir, consta de símbolos no terminales, símbolos terminales, un axioma y unas reglas de producción.

En el caso de una gramática independiente del contexto las reglas de P son de la forma:
\begin{itemize}
\item $A \rightarrow x$

Con $A\in N$, $x \in \Sigma^*$ con $\Sigma=T\cup N$
\end{itemize}

\begin{example}
El lenguaje:
\[L = \lbrace ww^R : w \in (a+b)^*\rbrace\]
es independiente del contexto puesto que puede representarse por medio de una gramática G independiente del contexto, que sería:
\begin{itemize}
\item $S \rightarrow aSa$
\item $S \rightarrow bSb$
\item $S \rightarrow \lambda$
\end{itemize}

\newpage
Para demostrar que el lenguaje generado por la gramática, L(G), es el mismo que L, habría que hacer dos cosas:

\begin{enumerate}
\item Probar que cualquier palabra de $L(G)$ está en $L$.
\item Probar que cualquier palabra de $L$ está en $L(G)$.
\end{enumerate}

El punto 1 es fácil de ver, pues está claro que cualquier cadena generada por $G$ es simétrica (siempre que añadimos una $a$ al principio añadimos otra al final, y lo mismo para $b$).

Para demostrar el punto 2 vamos a probar que si $w \in L$ entonces $w \in L(G)$ usando inducción:

\begin{itemize}
\item Todas las cadenas de $L$ tienen un número par de símbolos: $|w| = 2n$  $\forall w \in L$, $n=0,1,2,...$

\item Para $n=0$ tenemos $w = \lambda \in L$ y se cumple que $w \in L(G)$. Tomamos este caso como base de la inducción.

\item Supongamos que se cumple la hipótesis para $n$: si $w \in L$ con $|w| = 2n$ entonces $w \in L(G)$.

\item Demostremos que se cumple la hipótesis para $n+1$:

Sea $w \in L$ con $|w| = 2n+2$. Entonces $w$ debe ser de la forma $ava$ o $bvb$ con $v \in L$ y $|v| = 2n$. Por hipótesis tenemos que $v \in L(G)$, es decir se puede generar a partir del axioma $S$. Finalmente si $w = ava$ podemos generarla a partir del axioma con la regla $S \rightarrow aSa$, y si $w = bvb$ podemos generarla a partir del axioma con la regla $S \rightarrow bSb$. Por tanto también $w \in L(G)$.

\end{itemize}

\end{example}

\begin{defn}[Derivación directa]
Dada una gramática independiente del contexto G=(N,T,S,P) y sean $v$, $w$ dos formas sentenciales, decimos que w es derivación directa de v:
\[v \rightarrow w\ \equiv v=xZy \wedge w=x\alpha y \wedge \exists \ regla \ en \ P \tq Z \rightarrow \alpha\]
\end{defn}

\noindent con $Z \in N$ y $\alpha \in \Sigma^{*}$.

\begin{defn}[Derivación]
Dada una gramática G=(N,T,S,P) y sean $v$, $w$ dos formas sentenciales, decimos que w es derivación de v, y lo escribimos $v \rightarrow^{+} w$, si existe una cadena de formas sentenciales $a_{0}$, $a_{1}$, $a_{2}$,... $a_{n}$, tales que:
\[v = a_0 \rightarrow a_1 \rightarrow a_2 \rightarrow ... \rightarrow a_n = w\]
\end{defn}

\newpage
\begin{defn}[Lenguaje generado por G]
Dada una gramática G=(N,T,S,P) definimos el lenguaje generado por ella como:
\[L(G) = \lbrace w \in T^*: S \rightarrow^{+} w \rbrace\]
\end{defn}


Veamos algunos ejemplos:

\begin{example}
Dado el lenguaje:
\[L = \lbrace a^n b^n : n\geq 0 \rbrace\]

La gramática que genera este lenguaje es:
\begin{itemize}
\item $S \rightarrow \lambda$
\item $S \rightarrow aSb$
\end{itemize}
\end{example}

\begin{example}
Dado el lenguaje:
\[L = \lbrace w \in (a+b)^* \tq n_a(w)=n_b(w)\rbrace\]

La gramática que genera este lenguaje es:
\begin{itemize}
\item $S \rightarrow aSb | bSa | \lambda$
\item $S \rightarrow SS$
\end{itemize}

Para construirla nos hemos fijado en que una palabra w puede ser de 4 formas:
\[w = \left\{ \begin{array}{lcc}
             aw_0b &   con  & w_0 \in L \\
             \\ bw_0a &  con & w_0 \in L \\
             \\ aw_0a  \Rightarrow  w = w_1w_2  & con  & w_1,w_2 \in L\\
             \\ bw_0b  \Rightarrow  w = w_1w_2  &  con &  w_1,w_2 \in L
             \end{array}
   \right.\]
\end{example}

Una sentencia puede ser derivada de diferentes formas a partir de una misma gramática. Para estos casos vamos a definir derivaciones ``leftmost'' y ``rightmost'':

\begin{defn}[Leftmost]
Consiste en derivar, en cada paso, el elemento no terminal colocado más a la izquierda. Se deja para el lector el arduo trabajo de deducir que significa una derivación ``rightmost''.
\end{defn}

Esto nos lleva a definir un nuevo concepto:

\begin{defn}[Ambigüedad]
Una gramática se define como ambigua si existen dos o más \textbf{árboles de derivación distintos} para la misma sentencia.

Otra forma de definirlo sería considerar ambiguas aquellas gramáticas para las que existen dos \textbf{derivaciones leftmost (o rightmost)} distintas para la misma sentencia.
\end{defn}

\begin{example}
Consideremos la gramática dada por las reglas:
\begin{itemize}
\item $E \rightarrow E + E | E \times E | I$
\item $I \rightarrow a | b | c$
\end{itemize}

Se trata de una gramática ambigua ya que la sentencia $a+b\times c$ tiene dos derivaciones distintas leftmost.
\begin{enumerate}
\item $E \rightarrow E + E \rightarrow I + E \rightarrow a + E \rightarrow a + E \times E \rightarrow a + I \times E \rightarrow a + b \times E \rightarrow a + b \times I \rightarrow a + b \times c$
\item $E \rightarrow E \times E \rightarrow E + E \times E \rightarrow I + E \times E \rightarrow a + E \times E \rightarrow a + I \times E \rightarrow a+b \times E \rightarrow a + b \times I \rightarrow a + b \times c$
\end{enumerate}
\end{example}

Ya vimos que dos gramáticas son equivalentes si generan el mismo lenguaje pero vamos a recalcar que hay \textbf{infinitas} gramáticas que generan el mismo lenguaje.

Dada una gramática G=(T,N,S P) para obtener otra equivalente basta con hacer otra:
\[G' =(T, N \cup \lbrace Z \rbrace, Z, P \cup \lbrace Z \rightarrow E \rbrace)\]

\newpage

\chapter{Autómatas finitos: deterministas y no deterministas}
\begin{defn}[Autómata finito determinista]
Se representa como:
\[ A=(Q, \Sigma, \delta, q_0, F)\]
 donde:
\begin{itemize}
\item Q = conjunto de estados
\item $\Sigma$ =  alfabeto de entrada
\item $\delta$ = función de transición: $\delta : Q\times \Sigma \rightarrow Q$
\item $q_0$ = estado inicial $\in$ Q
\item F = conjunto de estados finales, $F \subset Q$
\end{itemize}
\end{defn}

% La función de transición no es inyectiva, dos elementos del dominio pueden tener la misma imagen (desde dos estados distintos se puede pasar al mismo estado).
%\begin{defn}[Autómata Finito Determinista. AFD\IS]
%Implica que la función de transición es inyectiva. Dado un estado y una entrada sólo hay un estado al que podamos pasar.
%\[\delta: Q \times \Sigma \rightarrow Q\]
%\end{defn}

\begin{defn}[Función de transición extendida\IS]
Consiste en una extensión de la función de transición a cadenas. Se representa como $\delta ^*$:
\[\delta^*(q, w)=q_1\]
Siendo $w\in \Sigma ^*$, $q$ el estado en el que comenzamos y $q_1$ el estado al que llegamos tras procesar toda la palabra. Recordemos que $\Sigma$ es el alfabeto de entrada (conjunto de símbolos) y $\Sigma^*$ es el conjunto formado por todas las posibles cadenas de símbolos que puedes crear con dicho alfabeto.
\end{defn}

\begin{defn}[Lenguaje aceptado\IS por un AFD]
El lenguaje aceptado por un autómata finito determinista, A, es el conjunto de palabras que llevan al autómata a un estado final.
\[L(A) = \lbrace w \in \Sigma^* \ : \ \delta^*(q_0, w) \in F \rbrace\]
\end{defn}

Veamos algún ejemplo:
\begin{example}
Queremos un autómata que reconozca el lenguaje: L=$\lbrace$101,110$\rbrace$

El autómata resultado es:
\begin{center}
\includegraphics[scale=0.75]{automata2.png}
\end{center}
\obs: Un autómata determinista tiene que tener todas las transiciones definidas, se sobreentiende que las transiciones que no están dibujadas van a un sexto estado en el cual se quedan colgadas.

Este autómata es determinista y su transición de estados dada una entrada "101" sería:

 \begin{tabbing}
   \hspace*{2cm} \= \hspace*{2cm} \= \hspace*{2cm} \= \hspace*{2cm} \= \kill
  entrada:\> 1   \> 0   \> 1   \\
 q0 \> q1 \> q3 \> q4  \\
 \end{tabbing}

Por tanto "101" forma parte del lenguaje del autómata.

Pero podríamos representar el mismo lenguaje con un autómata no determinista:
\begin{center}
\includegraphics[scale=0.75]{automata3.png}
\end{center}
Y su transición de estados dada una entrada "101" sería:

 \begin{tabbing}
   \hspace*{2cm} \= \hspace*{2cm} \= \hspace*{2cm} \= \hspace*{2cm} \= \kill
  entrada: \> 1   \> 0   \> 1  \\
 q0 \> q1 \> q4 \> q5\\
  \> q2 \> - \> - \\

 \end{tabbing}

Como al menos uno de los caminos lleva a un estado final, la cadena "101" forma parte del lenguaje del autómata (los guiones indican transición no definida, o a un estado vacío).

La ventaja de un autómata no determinista es que podemos explorar varias ramas en paralelo.
\end{example}


\begin{defn}[Transición $\lambda$]
Transición que puede ocurrir sin consumir ningún valor de entrada. Un autómata finito que tenga transiciones de este tipo se considera no determinista.
\end{defn}

\begin{defn}[Autómata finito no determinista. AFN\IS]
Autómata con función de transición de la forma:
\[\delta: Q\times (\Sigma \cup \lbrace \lambda \rbrace) \rightarrow 2^Q\]
Es decir, dado un estado y una entrada (posiblemente vacía) salta a un conjunto de estados.
\end{defn}

\begin{defn}[Función de transición de un AFN extendida\IS]
Consiste en una extensión de la función de transición a cadenas. Se representa como $\delta ^*$:
\[\delta^*(q, w) = E\]
Siendo $w\in \Sigma ^*$, $q$ el estado en el que empezamos y $E$ el conjunto de estados a los que llegamos tras procesar toda la palabra.
\end{defn}

\begin{defn}[Lenguaje aceptado\IS por un AFN]
El lenguaje aceptado por un autómata finito no determinista, A, es el conjunto de palabras que llevan al autómata a un estado final.
\[L(A) = \lbrace w \in \Sigma^* \ : \ \delta^*(q_0, w)\cap F \neq \emptyset \rbrace\]
\end{defn}

\begin{example}
Diseñar un autómata para el siguiente lenguaje

Tenemos el alfabeto: $\Sigma = \lbrace 0,1,2,3,4,5,6,7,8,9,+,-,\cdot \rbrace$ con las siguientes restricciones:
\begin{enumerate}
\item Signo puede o no aparecer
\item Parte decimal puede aparecer o no
\item Parte entera puede o no aparecer
\item Debe haber al menos parte entera o decimal.
\end{enumerate}

El autómata queda:
\begin{center}
\includegraphics[scale=0.75]{automata4.png}
\end{center}
\end{example}

\newpage

\begin{defn}[Fuentes de indeterminismo de un AF]
Un autómata finito no determinista se caracteriza por tener alguna de las siguientes propiedades:
\begin{enumerate}
\item Con la misma entrada, varias transiciones posibles para un mismo estado.
\item Hay transiciones lambda
\item Se puede transitar a $\emptyset$ (transiciones no definidas)
\end{enumerate}
\end{defn}

\begin{example}
Otro ejemplo de autómata no determinista podría ser:
\begin{center}
\includegraphics[scale=0.75]{automata3a.png}
\end{center}
Cuya transición de estados dada una entrada "101" sería:

 \begin{tabbing}
   \hspace*{2cm} \= \hspace*{2cm} \= \hspace*{2cm} \= \hspace*{2cm} \= \hspace*{2cm} \kill
 Estados \> 1   \> 0   \> 1   \\
 q0 \> - \> - \> -  \\
 q1 \> q2 \> q4 \> q5\\
 \end{tabbing}

En este autómata, podemos avanzar al estado 'q1'  a través de la transición $\lambda$, aunque el primer símbolo de la entrada sea un '1', (segunda línea de la tabla). Sin embargo en el camino en el que nos mantenemos en el estado 'q0'  (primera línea de la tabla), no tenemos la transición definida con entrada '1' y vamos al estado vacío. Llegamos a un estado final, por tanto la palabra "101" pertenece al lenguaje de este autómata.

\end{example}

\begin{theorem}
Los autómatas finitos no deterministas y deterministas son equivalentes.
\end{theorem}

Esto significa que dado un autómata finito determinista que acepta un determinado lenguaje, existe otro no determinista que acepta el mismo lenguaje, y viceversa. Se utilizan los AFN por comodidad, porque las demostraciones formales son más sencillas.

\section{Equivalencia entre AF y ER}
Vamos a ver cuál es la relación existente entre los autómatas finitos y las expresiones regulares.

Como ya vimos una gramática puede expresarse como una cuádrupla G=(N,T,S,R), es decir, consta de símbolos no terminales, símbolos terminales, un símbolo inicial o axioma y unas reglas de producción.

Recordamos también que una gramática regular es aquella que es lineal por la derecha o lineal por la izquierda

Hay 4 formas de representar un lenguaje regular, y en ellas reside la equivalencia entre autómatas finitos y expresiones regulares. Las 4 formas de representar un lenguaje regular son:
\begin{enumerate}
\item Describiendo todos sus componentes
\item Con una gramática regular
\item Con una expresión regular
\item Mediante un AFN/AFD
\end{enumerate}

\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Autómatas a pila}
Dado el lenguaje:
\[L=\lbrace ww^R \tq w \in (0+1)^*\rbrace\]
que representa palabras capicúas sobre $\lbrace 0, 1\rbrace$ con un número par de símbolos, vamos a intentar construir un autómata finito para él.

Esto no es posible ya que siempre necesito llegar hasta la mitad de la palabra ``almacenando'' lo que hemos leído para después comprobar que lo leemos al revés. Puesto que la palabra puede tener longitud arbitraria, necesitaremos una cantidad de memoria arbitraria y esto no es viable (sería necesario un autómata con un número infinito de estados).

Es aquí donde surgen los autómatas a pila. Estos autómatas se caracterizan por que en cada salto indicamos una entrada, saca el símbolo de la cima de la pila y añade una cadena a la pila.

Para el lenguaje dado, el autómata a pila que lo representa sería:

\begin{center}
\includegraphics[scale=0.75]{automata5.png}
\end{center}
En teoría, las etiquetas de los arcos del autómata son de la forma:
\[A_b^c\]
donde $A$ sería la entrada leída, $b$ el elemento que extraemos del tope de la pila y $c$ la cadena que insertamos en la pila. Por tanto una transición solo se puede dar si aparte de tener la entrada correspondiente, la cima de la pila coincide con lo que vamos a extraer de ella. Introducir $az$ implica que la 'a' se queda como cima de la pila, y la 'z' detrás.

En algunos ejercicios usaremos la notación $\{b,A,c\}$ con idéntico significado.

\newpage
\begin{defn}[Autómata a pila]
Un autómata a pila se representa como:
\[A=(Q, \Sigma, \delta, q_0, F, \topl, A_0)\]
siendo:
\begin{itemize}
\item $Q$: conjunto de estados
\item $\Sigma$: alfabeto de entrada
\item $\delta$: función de transición: $\delta:Q\times(\Sigma \cup \{\lambda\})\times \topl \rightarrow 2^{Q\times \topl^*}$
\item $q_0$: estado inicial $\in Q$
\item $F$: conjunto de estados finales
\item $\topl$: alfabeto de la pila
\item $A_0$: símbolo inicial de la pila $\in \tau$
\end{itemize}

\noindent {\bf Nota:} En realidad el codominio de $\delta$ es el conjunto de subconjuntos finitos de $Q\times \topl^*$.

Básicamente consiste en un autómata, como los vistos hasta ahora, acompañado de una pila en la que realizaremos inserciones y extracciones en cada transición.
\end{defn}

Vamos a ver un pequeño ejemplo que explica cómo entender la función de transición:
\begin{example}
La evaluación de la función de transición:
\[\delta(q,a,x)=\{(p,y)\}\]

\noindent con $q, p \in Q$, $a \in \Sigma$, $x \in \topl$ y $y \in \topl^{*}$.
Implica que, estando en el estado 'q', ante una entrada 'a', habiendo en la cima de la pila un 'x' pasamos al estado 'p', insertando en la pila 'y', y sacando la 'x'.
\end{example}

En estos autómatas los conceptos de determinismo o no determinismo se mantienen. Es decir, un autómata a pila será no determinista si dada una entrada y un elemento a extraer de la cima de la pila tiene varias acciones que puede llevar a cabo (varios pares ('estado','inserción en pila')). Profundizaremos más adelante en este concepto.

\obs Aunque un autómata finito determinista es equivalente a uno no determinista, con autómatas a pila no ocurre lo mismo.

\begin{defn}[Autómata a pila determinista]
Un autómata a pila será determinista si cumple las siguientes condiciones:
\begin{itemize}
\item No hay transiciones $\lambda$ o, si las hay, no hay ninguna otra transición con un símbolo diferente. Es decir, si desde un estado p y con a en la pila pudieras pasar a otro q por una transición lambda, no habría otra posible transición desde el estado p y con a en la pila.
\item Dada una situación (estado p, símbolo de entrada x y símbolo a en la cima de la pila) $\delta (p,x,a)$ contiene como mucho un elemento $(q,b)$.
\end{itemize}
\end{defn}

\begin{defn}[Descripción instantánea]
Se trata de una representación de la situación actual del autómata. (q,X,A) es una descripción instantánea donde:\\
\begin{enumerate}
\item q = Nodo/estado en el que nos encontramos
\item X = Entrada que falta por leer, $X \in \Sigma^{*}$
\item A = Contenido de la pila, $A \in \topl^{*}$
\end{enumerate}

Dada una descripción instantánea podemos continuar el procesamiento de la cadena sin perder información.
\end{defn}

\begin{defn}[Precedencia entre descripciones instantáneas]
Decimos que una descripción instantánea precede a otra:
\[(q,xX,aA) \vdash (p, X, bA)\]
si:
\[(p,b) \in \delta(q, x, a)\]
Siendo 'p','q' nodos del autómata, 'x' el siguiente símbolo de entrada que se va a leer, 'X' el resto de la cadena de entrada; 'a' el carácter que hay en la cima de la pila, 'A' el resto del contenido de la pila y,'b' una cadena de símbolos que insertamos en la pila. En este transición se lee 'x', se saca 'a' de la cima de la pila y se introduce 'b'.

Es decir, una descripción instantánea precede a otra si hay una transición que nos lleva de una a otra.

\end{defn}

\begin{defn}[Precedencia *]
Decimos que hay precedencia * entre dos descripciones instantáneas:
\[(q,X,A) \vdash^* (p, Y, B)\]
cuando hay una secuencia $d_0,d_1,..., d_n$ de descripciones instantáneas tales que:
\[(q,X,A) = d_0 \vdash d_1 \vdash ... \vdash d_n = (p, Y, B)\]
\end{defn}

\noindent con $p, q \in Q$, $X, Y \in \Sigma^{*}$ y $A, B \in \topl^{*}$.

Basándonos en estas definiciones, podemos representar el lenguaje aceptado por un autómata a pila como:
\[L(A) = \lbrace w \in \Sigma^* \tq (q_0, w, A_0) \vdash^* (p, \lambda, X)\rbrace\]
con $p\in F, X \in \topl^*$

\begin{example}
Queremos encontrar un autómata que represente el lenguaje:
\[L = \lbrace a^nb^n, n \geq 0\rbrace\]

El autómata de pila que representa este lenguaje es:

\begin{center}
\includegraphics[scale=0.75]{automata6.png}
\end{center}
\end{example}

\newpage
\chapter{Gramáticas de atributos}
Un compilador se encarga de generar el código máquina a partir de un código dado.

En primer lugar debemos saber que un compilador realiza tres tareas:
\begin{enumerate}
\item \textbf{Análisis morfológico}. A estas alturas consideramos que ya nos viene hecho y no nos preocupamos por ello.
\item \textbf{Análisis sintáctico}. Consiste en construir el árbol de derivación. Es decir, se comprueba que la sentencia obtenida sale de derivar el axioma.
\item \textbf{Análisis semántico}. Consiste en recorrer el árbol de derivación calculando atributos y realizando comprobaciones semánticas.
\end{enumerate}

Vamos a centrarnos ahora en análisis semántico.
\section{Análisis semántico}

Vamos a explicar brevemente la idea que hay detrás de esto:

Partiendo de una gramática independiente del contexto, y derivando el axioma hasta obtener una sentencia, queremos obtener alguna función específica de nuestra gramática.

Es entonces cuando surgen las gramáticas de atributos, que añaden lo siguiente a la gramática independiente del contexto:
\begin{itemize}
\item Incorporan atributos a los nodos no terminales.

\item Incorporan funciones sobre esos atributos en las reglas de derivación. (Además veremos que estas funciones se podrán realizar en instantes concretos).

\item Incorporan una \textbf{información global} a la gramática. La información global está formada por un conjunto de variables que son accesibles desde cualquier nodo del árbol.
\end{itemize}
Por tanto, una vez obtenido el árbol de derivación, el análisis semántico recorrerá dicho árbol utilizando el recorrido en  \textbf{profundidad por la izquierda y con vuelta atrás} (lo explicamos más adelante) corroborando el buen funcionamiento de estas nuevas funciones.

El paso de información de un nodo a otro del árbol se podrá realizar mediante tres métodos:

\begin{itemize}
\item Síntesis: la información se propaga del nodo inferior al nodo superior.

\item Herencia: la información se propaga del nodo superior al nodo inferior.

\item Usando la información global.
\end{itemize}

Vamos a ver un ejemplo con detalle, explicando sobre él algunos de los conceptos:

Como hemos dicho, la idea es que dada una gramática independiente del contexto, podemos conseguir que esta realice funciones específicas. Lo conseguimos añadiendo atributos y especificaciones a las reglas de derivación.

\begin{example}
Consideremos la gramática:
\[G=\{\{(,)\}, \{L,I\}, L, P\}\]
Con las reglas de derivación P:
\begin{itemize}
\item $L \rightarrow (I)$
\item $I \rightarrow (I)$
\item $I \rightarrow II$
\item $I \rightarrow λ$
\end{itemize}

En primer lugar vamos a derivar el axioma y obtener una sentencia, nos queda (por ejemplo) el siguiente árbol de derivación:

\begin{forest}
for tree={
  draw,
  minimum height=1cm,
  anchor=north,
  align=center,
  child anchor=north
},
[{L}, align=center, name=SS
  [$($, tier=word]
  [{I}, name=PDC
    [{I}, name=MS
      [{$($}, tier=word]
      [{I}
        [{λ}, tier=word]]
      [{$)$}, tier=word]]
    [{I}
      [{$($}, tier=word]
      [{I}
        [{$($}, tier=word]
        [{I}
          [{λ}, tier=word]]
        [{$)$}, tier=word]]
      [{$)$}, tier=word]]
    ]
    [{$)$}, tier=word]
 ]
\end{forest}

Vemos que sintácticamente es correcto ya que se obtiene de derivar el axioma $L$.

Queremos hacer que esta gramática nos devuelva la profundidad de una expresión, es decir, el máximo número de paréntesis contenidos unos en otros.

Para ello, vamos a utilizar gramática de atributos, en primer lugar debemos añadir a los elementos L e I un atributo profundidad.

Vamos a intentar hacerlo propagando el atributo profundidad hacia arriba (es decir, usando síntesis). Por ello, un nodo terminal como sería λ debería tener profundidad 0. Por lo que la cuarta regla queda de la forma:
\[I \rightarrow λ \{I.prof=0\}\]

En las dos primeras reglas, debemos realizar una propagación hacia arriba, aumentando en uno la profundidad. Así estas dos primeras reglas quedan de la forma:
\[L \rightarrow (I) \{L.prof = I.prof+1\}\]
\[I_1 \rightarrow (I_2) \{I_1.prof=I_2.prof+1\}\]

Para la tercera regla, podemos ver que la profundidad que asciende será el máximo de las profundidades de cada uno de los símbolos en los que deriva. La tercera regla quedaría:
\[I_1 \rightarrow I_2I_3 \{I_1.prof = max(I_2.prof, I_3.prof)\}\]

Si ahora analizamos los instantes en que se realizaría la función de cada regla y agrupamos todo lo indicado anteriormente llegamos a:
\[G=\{\{(,)\}, \{L(prof),I(prof)\}, L, P, \emptyset \}\]
Con P:
\begin{itemize}
\item $L \rightarrow (I) \{2: \ L.prof = I.prof+1\}$
\item $I_1 \rightarrow (I_2) \{2: \ I_1.prof=I_2.prof+1\}$
\item $I_1 \rightarrow I_2I_3 \{2: \ I_1.prof = max(I_2.prof, I_3.prof)\}$
\item $I \rightarrow λ \{0: \ I.prof=0\}$
\end{itemize}

Así, hemos conseguido una gramática de atributos que realiza una función específica (obtener la profundidad). Lo hemos logrado a partir de una gramática independiente del contexto añadiendo atributos y el instante en el que debo realizar cada asignación en las reglas de derivación.

Además, una gramática de atributos contiene una información global. En este caso no la vamos a usar por lo que la declaramos vacía (es el último símbolo que se ha añadido a G).

También debemos saber que el árbol se recorre en \textbf{profundidad por la izquierda y con vuelta atrás}. Esta técnica consiste en recorrer siempre el hijo más a la izquierda, cuando no queden hijos a la izquierda, continuamos con el siguiente hijo más a la izquierda. Cuando no queden hijos volvemos al nodo superior y así sucesivamente.

Si suponemos un caso simple en el que un nodo raíz tiene n hijos inmediatos, podemos ver que al aplicar este procedimiento recorremos el nodo raíz n+1 veces. Por tanto el nodo raíz tendrá n+1 instantes.

Vamos a dejar claro a qué nos referimos con el instante en el que realizo la función de cada regla. Para ello, debemos saber que al realizar el análisis semántico cada nodo sabe qué regla de derivación se ha usado sobre él, y por tanto conocerá el número de hijos inmediatos que tiene. Así, por ejemplo un nodo I al que le aplicamos la regla $I_1 \rightarrow I_2 I_3$, tiene 3 instantes:

-El instante 0, en el que se visita el nodo $I_1$.

-El instante 1, en el que se vuelve al nodo $I_1$ después de haber visitado el nodo $I_2$.

-El instante 2, en el que se vuelve al nodo $I_1$ después de haber visitado el nodo $I_3$.

Veamos ahora como queda el árbol realizando el recorrido en profundidad por la izquierda y con vuelta atrás y aplicando las distintas funciones:

\begin{forest}
for tree={
  draw,
  minimum height=1cm,
  anchor=north,
  align=center,
  child anchor=north
},
[{L\\0:nada\\ p=2 en instante 2}, align=center, name=SS
  [$($, tier=word]
  [{$I^1$\\p=2 en instante 2}, name=PDC
    [{$I^2$\\p=1 en instante 2}, name=MS
      [{$($}, tier=word]
      [{$I^4$\\p=0 en instante 0}
        [{λ}, tier=word]]
      [{$)$}, tier=word]]
    [{$I^3$\\p=2 en instante 2}
      [{$($}, tier=word]
      [{$I^5$\\p=1 en instante 2}
        [{$($}, tier=word]
        [{$I^6$\\p=0 en instante 0}
          [{λ}, tier=word]]
        [{$)$}, tier=word]]
      [{$)$}, tier=word]]
    ]
    [{$)$}, tier=word]
 ]
\end{forest}

Hemos puesto superíndices a las I para poder referirnos ahora a ellas:

El recorrido en profundidad de esté árbol quedaría:

Empezamos en L, estamos en el instante 0 de L... bajamos a $($, como es terminal no hacemos nada... subimos a L, instante 1 de L... bajamos a $I^1$, instante 0 de $I^1$...bajamos a $I^2$, instante 0 de $I^2$... bajamos a $($ como es terminal no hacemos nada... subimos a $I^2$, instante 1 de $I^2$...bajamos a $I^4$, instante 0 de $I^4$, que como es un nodo que deriva con la regla $I\rightarrow \lambda$ le aplicamos la función $I.prof=0$... subimos a $I^2$, instante 2 de $I^2$, que como es un nodo que deriva con la regla $I_1\rightarrow (I_2)$, le aplicamos la función $I_1.prof=I_2.prof+1$, por tanto tenemos ahora mismo $I^2.prof=1$... bajamos a $)$, como es un nodo terminal no hacemos nada... subimos a $I^2$, instante 3 de $I^2$... subimos a $I^1$, instante 1 de $I^1$... bajamos a $I^3$, instante 0 de $I^3$... etc etc etc.

\end{example}



\begin{example}
Vamos a apoyarnos en la gramática definida en el ejemplo anterior y a modificar simplemente las acciones, con el fin de obtener un programa que cuente el número de listas (parejas de paréntesis).

Vamos a realizarlo de tres formas distintas: con síntesis, herencia y con información global. Estas diferentes formas dan lugar a diferentes acciones, pero el árbol de derivación sigue siendo el mismo.

Cada una de las reglas de derivación serían:

\begin{itemize}
\item \textbf{Síntesis}
\[G=\{\{(,)\}, \{L(n),I(n)\}, L, P\}\]
\begin{itemize}
\item $L \rightarrow (I) \{2: \ L.n = I.n+1\}$
\item $I_1 \rightarrow (I_2) \{2: \ I_1.n=I_2.n+1\}$
\item $I_1 \rightarrow I_2I_3 \{2: \ I_1.n = I_2.n + I_3.n)\}$
\item $I \rightarrow λ \{0: \ I.n=0\}$
\end{itemize}

\item \textbf{Herencia}
\[G=\{\{(,)\}, \{L(n),I(antes, despues)\}, L, P\}\]
\begin{itemize}
\item $L \rightarrow (I) \{0: \ I.antes=1, \ 2: \ L.n=I.despues\}$
\item $I_1 \rightarrow (I_2) \{0: I_2.antes = I_1.antes+1, \ 2: \ I_1.despues=I_2.despues\}$
\item $I_1 \rightarrow I_2I_3 \{0: \ I_2.antes = I_1.antes, \ 1: \ I_3.antes=I_2.despues, \ 2: \ I_1.despues=I_3.despues\}$
\item $I \rightarrow λ \{0: \ I.despues=I.antes\}$
\end{itemize}
Hemos usado alguna acción que se sale de un esquema puro de herencia por ser imposible realizarlo de otra forma.

\item \textbf{Información global}
\[G=\{\{(,)\}, \{L,I\}, L, P, \{n\}\}\]
\begin{itemize}
\item $L \rightarrow (I) \{0: \ n=0; \ 1: \ n = n+1\}$
\item $I_1 \rightarrow (I_2) \{0: \ n=n+1\}$
\item $I_1 \rightarrow I_2I_3$
\item $I \rightarrow λ $
\end{itemize}
Este caso es bastante más sencillo, pues en cada derivación tienes acceso al contador global y basta con incrementarlo, sin preocuparte por los sucesores.

Usando información global es realmente importante \textbf{indicar los instantes en que se realiza cada acción} puesto que de lo contrario habría lugar a confusión. (En los casos anteriores los atributos imponían un orden sin ambigüedad).

\end{itemize}
\end{example}

En las transparencias podéis ver estos tres ejemplos para diferenciar la herencia, la síntesis y la información global (llamada tabla de símbolos):

\includepdf[frame=true, noautoscale=true, delta=10 10, nup=2x4,pages={2-9}, scale=0.72]{pdf/GramaticaAtributos.pdf}

\includepdf[frame=true, noautoscale=true, delta=10 10, nup=2x4,pages={10-17}, scale=0.72]{pdf/GramaticaAtributos.pdf}

\includepdf[frame=true, noautoscale=true, delta=10 10, nup=2x4,pages={18-25}, scale=0.72]{pdf/GramaticaAtributos.pdf}

\includepdf[frame=true, noautoscale=true, delta=10 10, nup=2x4,pages={26-27}, scale=0.72]{pdf/GramaticaAtributos.pdf}

\begin{example}
Para ver claramente las diferencia entre análisis semántico y sintáctico nos podemos fijar en lo siguiente, según el ejemplo 1, el código:
\begin{verbatim}
                           int _x,_y
                               _x=7
\end{verbatim}
es correcto semántica y sintácticamente, mientras que el código:
\begin{verbatim}
                           int _x,_y
                               _z=7
\end{verbatim}
es sintácticamente correcto pero no semánticamente.
\end{example}

\begin{example}
Vamos a tomar un caso sencillo con dos reglas sacadas del último ejemplo mostrado en las transparencias. La semántica es:
\begin{itemize}
\item $L \rightarrow i \{st(i.nombre,L.tipo\}$
\item $A \rightarrow i = E \{in TS (i.nombre)==true; \; gt(i.nombre)==E.tipo; \; sv(i.nombre, E.valor)\} $
\end{itemize}

Para la primera regla, el orden en que se recorrería el árbol de derivación es:
\begin{verbatim}
- En el instante 0 bajamos del nodo L al nodo i,
- En el instante 1 volvemos al nodo L.
\end{verbatim}

Como es lógico, la operación de setType representada en la gramática no puede realizarse hasta conocer el tipo de L y el nombre de i, por lo que se realiza en el instante 1.

Lo representaríamos como:
\[L \rightarrow i \{1:st(i.nombre,L.tipo\}\]

Vamos ahora con la segunda regla. El orden en el que se recorrería el árbol de derivación seria:
\begin{verbatim}
- En el instante 0 bajamos del nodo A al nodo i, en el instante 1 volvemos al A.
- En ese instante bajaríamos al nodo =, del que volveríamos en el instante 2.
- Por último bajaríamos al nodo E y volveríamos del mismo en el instante 3
\end{verbatim}

Siguiendo esta secuencia y analizando en qué momento tenemos disponibles los valores para cada operación la segunda regla de la gramática sería de la forma:
\[A \rightarrow i = E \{ 1: \ in TS (i.nombre)==true; 3: \ gt(i.nombre)==E.tipo; 3: \ sv(i.nombre, E.valor)\}\]

En este tercer ejemplo es importante añadir algunas comprobaciones más en las reglas, que no vienen en las trasparencias:
\begin{itemize}
\item En la regla $A \rightarrow i=E$ comprobar $inTS(i.nombre)==true$ (es decir, ¿está en la tabla de símbolos i.nombre?)

\item En la regla $E_1 \rightarrow E_2 + E_3$ y $E_1 \rightarrow E_2 * E_3$ comprobar que $E_2.tipo=E_3.tipo$

\item En la regla $E \rightarrow i$ comprobar $inTS(i.nombre)==true$ y $gt(i.nombre)==E.tipo$ con gt=getType (es decir, ¿es el parametro tipo de i.nombre igual al de E?).
\end{itemize}
\end{example}



\chapter{Analizador morfológico}
Empezamos este capítulo recordando la función de un compilador.

Dado un archivo \textit{fuente}, este archivo pasará a través de un analizador de código, que realiza tres funciones, utilizando para ello una tabla de símbolos que él mismo genera:
\begin{itemize}
\item Análisis morfológico
\item Análisis sintáctico
\item Análisis semántico
\end{itemize}
Tras ser analizado, se genera un árbol de derivación como los vistos hasta ahora.

Nos centramos ahora en el analizador morfológico (también llamado léxico o scanner). Este realiza principalmente la siguiente función:

\textbf{Obtención de unidades sintácticas.} Son los llamados tokens. Estos pueden ser identificadores, constantes, palabras reservadas ($if$, $them$, $for$,...) u otros símbolos (simples: $+$, $=$,... o dobles: $:=$,...).\\

No obstante, el analizador morfológico también es importante en la consecución de las siguientes tareas secundarias:
\begin{enumerate}
\item Eliminar delimitadores (espacios en blanco, tabuladores, saltos de línea...).
\item Eliminación de comentarios en el código.
\item Detecta errores morfológicos. (Símbolos inválidos, constantes e identificadores mal construidos...)
\item Inicializa algunas tareas semánticas, es decir, calcula el valor de algunos atributos de constantes o identificadores.
\end{enumerate}

Lo vemos con un ejemplo: tenemos un lenguaje que admite el siguiente tipo de objetos:
\begin{itemize}
\item Identificadores: letra seguida de cero o más dígitos y letras.
\item Constantes: (números enteros).
\item Palabras reservadas: \textit{begin}, \textit{end}, \textit{int}, \textit{print}.
\item Símbolos: tanto simples: ';' como dobles: ':='.
\end{itemize}

Con este lenguaje, y dado el siguiente fichero de entrada  \textit{fuente}.

\begin{verbatim}
    begin
        int A;
        A := 100;
        print A;
    end
\end{verbatim}

El analizador morfológico generará un fichero de salida semejante al siguiente:

\begin{verbatim}
    <"begin",TOK_BEGIN>
    <"int",TOK_INT>
    <"A",TOK_ID, valor='A'>
    .
    .
    .
    <"100",TOK_CONST, valor=100>
    .
    .
    .
\end{verbatim}

La 4ª tarea secundaria, que tenía el analizador morfológico, es la que realiza la función de crear un atributo valor e inicializarlo.

\chapter{Analizador sintáctico}

\section{Introducción}

Para llevar a cabo el análisis sintáctico de una entrada se emplean tablas de análisis. Estas permiten analizar una sentencia, con el fin de saber si se trata de una sentencia válida para una gramática dada o no.

Existen dos tipos de análisis: \textbf{ascendente} y \textbf{descendente}

Veamos un ejemplo:
\begin{example}
Dada la gramática:
\begin{itemize}
\item 1) E $\rightarrow$ E + E
\item 2) E $\rightarrow$ E x E
\item 3) E $\rightarrow$ -E
\item 4) E $\rightarrow$ (E)
\item 5) E $\rightarrow$ id
\end{itemize}

Vamos a realizar un \textbf{análisis ascendente} partiendo de la siguiente sentencia:
\begin{center}
(id+id)xid
\end{center}

Para ello vamos a contar con la ayuda de una pila y nos basaremos en dos reglas básicas:
\begin{enumerate}
\item \textbf{Reducción}
Se aplicará siempre que sea posible. No hay elección.

Se lleva a cabo cuando los elementos de la cima de la pila coinciden con la parte derecha de alguna regla de nuestra gramática.

En este caso se extraen los elementos de la pila y se sustituyen por la parte izquierda de la regla indicada anteriormente.

\item \textbf{Desplazamiento}
Se aplica cuando no puede realizarse ninguna reducción.

Consiste en introducir en la cima de la pila el siguiente elemento de la sentencia que estamos analizando
\end{enumerate}

Aplicando estas reglas a nuestra sentencia obtenemos el siguiente resultado:
\begin{center}
\begin{tabular}{| c | c | c | c |}
\hline
Instante & Entrada & Pila & Acción \\
\hline
0 & (id+id)xid & - & Desplazamiento \\
\hline
1 & id+id)xid & ( & Desplazamiento \\
\hline
2 & +id)xid & (id & Reducción(5) \\
\hline
3 & +id)xid & (E & Desplazamiento \\
\hline
4 & id)xid & (E+ & Desplazamiento \\
\hline
5 & )xid & (E+id & Reducción(5)\\
\hline
6 & )xid & (E+E & Reducción(1) \\
\hline
7 & )xid & (E & Desplazamiento \\
\hline
8 & xid & (E) & Reducción(4) \\
\hline
9 & xid & E & Desplazamiento \\
\hline
10 & id & Ex & Desplazamiento \\
\hline
11 & - & Exid & Reducción(5) \\
\hline
12 & - & ExE & Reducción(2) \\
\hline
13 & - & E & Fin \\
\hline
\end{tabular}
\end{center}
Puesto que en la pila sólo queda el axioma, concluimos que la sentencia es válida para este lenguaje.
\end{example}

Tras este ejemplo podemos definir formalmente el algoritmo de análisis ascendente.

\begin{defn}[Análisis ascendente]
Este algoritmo consiste de dos pasos:
\begin{verbatim}
     Mientras queden elementos en la entrada:
       desplazamos
       mientras podemos reducir:
           reducimos

     Si en la pila sólo está el axioma:
         OK.
     En caso contrario:
         ERROR.
\end{verbatim}
\end{defn}

Una vez visto el análisis ascendente el siguiente paso es estudiar el análisis descendente.

\begin{defn}[Análisis descendente]
Algoritmo para determinar si una entrada es válida o no para una gramática dada mediante derivaciones (partiendo del axioma)

Es decir, tomamos el axioma y aplicamos derivaciones sucesivas intentando llegar a la sentencia que queremos analizar.

Si logramos generar la sentencia que estamos analizando, esta será válida. (En caso contrario no)
\end{defn}

Vamos a trabajar con gramáticas sencillas en las que sólo haya una derivación posible en cada paso. En caso de no ser así deberíamos avanzar todo lo posible para después hacer backtracking, comprobando que no dejamos caminos sin explorar.

Veámoslo con un ejemplo:
\begin{example}
Dada la gramática:
\begin{itemize}
\item E $\rightarrow$ TB
\item B $\rightarrow$ +TB | λ
\item T $\rightarrow$ FX
\item X $\rightarrow$ *FX | λ
\item F $\rightarrow$ i | (E)
\end{itemize}
Vamos a usar un \textbf{análisis descendente} para comprobar si es válida la sentencia:
\begin{center}
i*i
\end{center}
Para hacerlo apoyándonos en una pila, como en el ejemplo anterior, los pasos a seguir son los siguientes:

\begin{tabular}{| c | c | c |}
\hline
Instante & Pila & Acción\\
\hline
1 & E & Derivamos\\
\hline
2 & B | T & Derivamos \\
\hline
3 & B | X | F & Derivamos\\
\hline
4 & B | X | i & Extraemos, pues i está en la sentencia dada\\
\hline
5 & B | X & Derivamos \\
\hline
6 & B | X | F | * & Extraemos, pues * está en la sentencia dada \\
\hline
7 & B | X | F & Derivamos \\
\hline
8 & B | X | i & Estraemos, pues i está en la sentencia dada \\
\hline
9 & B | X & Derivación λ\\
\hline
10 & B & Derivación λ \\
\hline
\end{tabular}

Si al finalizar nos queda la pila vacía concluimos que la sentencia estudiada es correcta.
\end{example}


A lo largo de esta sección profundizaremos sobre el análisis ascendente y el análisis descendente.


\section{Tablas de análisis ascendente}

Vamos a estudiar ahora diferentes tablas de análisis (y autómatas asociados) que se utilizan para realizar el análisis ascendente.

\subsection{Tablas LR(0)}

\begin{defn}[Tabla LR(n)]
Tabla empleada para el procesamiento de entrada desde la izquierda (\textbf{L}eft) mediante derivaciones \textbf{R}ight-most con \textbf{n} símbolos de entrada.

\end{defn}

Veamos un ejemplo de como funciona esta tabla de análisis
\begin{example}
Consideremos la gramática G=(T, N, E, P):
\begin{itemize}
\item E $\rightarrow$ T | E+T
\item T $\rightarrow$ i | (E)
\end{itemize}

El primer paso para realizar el análisis LR(O) consiste en añadir un axioma E' y la regla:
\begin{center}
E' $\rightarrow$ E\$
\end{center}

De forma que se obtiene la siguiente \textbf{gramática extendida}:
\begin{itemize}
\item E' $\rightarrow$ E \$
\item E $\rightarrow$ T
\item E $\rightarrow$ E+T
\item T $\rightarrow$ i
\item T $\rightarrow$ (E)
\end{itemize}

Ahora lo que hacemos es añadir un '.' delante del símbolo que estemos analizando en cada paso.

Para realizar el análisis por este método vamos a construir un autómata finito determinista, que procesa una cadena de símbolos, empezando por el estado S0:

\begin{center}
\includegraphics[scale=0.45]{img/automatalr0.jpg}
\end{center}

Si aplicamos el algoritmo de análisis LR(0) a lo bruto, tras cada reducción todo lo que hay en la pila (una vez aplicado el correspondiente cambio fruto de la reducción) pasa al inicio de la cadena de entrada y saltamos al estado $S_0$ para continuar con el análisis.

No obstante, esta práctica implica deshacer lo andado muchas veces y alarga mucho el desarrollo del algoritmo. Para evitar esto, en la pila guardamos, además de la última entrada leída, el estado en que nos encontramos y tras una reducción nos desplazamos al estado indicado en la pila justo antes de la reducción y añadimos la nueva cadena (fruto de la reducción) al inicio de la cadena de entrada.

A continuación explicamos cómo se realiza el análisis a lo bruto.

Si el análisis de una cadena llega al estado de aceptación ($S_{acc}$) en este autómata, se termina el análisis concluyendo que la cadena es sintácticamente correcta.

Para construir el autómata seguimos los siguientes pasos:
\begin{itemize}
\item Partimos en el estado $S_0$ del axioma de la gramática extendida ($E'$).
\item Situamos un '.' delante del símbolo que analizamos, en este caso empezamos por el símbolo E. Ya que la regla de derivación del axioma es $E' \rightarrow E\$$. Por tanto nos queda $E' \rightarrow .E\$$
\item Ahora tenemos que \textbf{cerrar} el símbolo que esta inmediatamente después del punto. Si es un terminal ya estaría cerrado. Si es un no terminal lo cerramos escribiendo las reglas de derivación del mismo, poniendo de nuevo un '.' delante del primer símbolo de cada una de las reglas y cerrando el símbolo inmediatamente posterior al '.'. Así terminamos el estado $S_0$
\item Creamos los siguientes estados. La transición de un estado a otro se da a partir de la entrada de un símbolo. Si entra un símbolo que se encuentra inmediatamente después del '.', entonces se irá a un nuevo estado del autómata en el que ahora el '.' se encontrará en la siguiente posición dentro de la regla de derivación. Si llega un símbolo que no está inmediatamente después del '.', se saltará a un estado de error.
\item Si se llega a un estado en el que el '.' queda a la derecha de la regla de derivación (sin ningún símbolo inmediatamente después), este estado será un \textbf{estado final}. Esto implica que nada más llegar a este estado se \textbf{reducirá} la regla (introduciendo en la entrada la pare izquierda de la regla )y volveremos al estado inicial $S_0$.
\end{itemize}

A partir de este autómata se puede crear una tabla, denominada \textbf{tabla de análisis LR(0)} que resume el funcionamiento del autómata:

\begin{center}
\includegraphics[scale=0.3]{img/tablaanallr0.jpg}
\end{center}

En la cual vemos que se indica la acción a realizar según el estado en el que nos encontremos y el símbolo de entrada que leamos.

Así, para realizar el análisis de una entrada nos basta con utilizar esta tabla y una pila en la que vayamos guardando las acciones que vamos realizando.

A la hora de analizar una entrada realizamos los siguientes 5 tipos de acciones:
\begin{itemize}
\item ERROR: si llegamos a una casilla en blanco de la tabla se deduce que la entrada es incorrecta.
\item Desplazar (símbolo terminal): Avanzamos un símbolo en la entrada y lo introducimos en la pila junto con el número del estado al que saltas. Corresponde a las casillas dx, siendo x el estado al que saltamos.
\item Reducir: Sacar de la pila la parte derecha de la regla (doble de símbolos de los que tiene la parte derecha ya que sacamos símbolo y número de estado al que saltó). Tras la reducción se considera que volvemos al estado $S_0$ con símbolo de entrada el de la parte izquierda de la regla que se acaba de reducir. Corresponde a las casillas rx, siendo x la regla de la gramática que reducimos.
\item Ir a (desplazamiento de símbolo no terminal). Saltar al estado indicando introduciendo en la pila el no terminal y el estado al que se salta. Se aplica justo después de realizar una reducción. No se avanza por tanto en la cadena de entrada. Corresponde a las casillas de la tabla en la que hay solo un número (estado al que saltamos).
\item Aceptar: Se acepta el símbolo e entrada si llegamos al estado de aceptación $S_{acc}$.
\end{itemize}

La siguiente tabla recoge el resultado detallado del análisis de la entrada (por comodidad mostramos en análisis mejorado, guardando en la pila el estado en que nos encontramos):
\[i+i+i\$\]
\begin{tabular}{| c | c | c | c | c | c |}
\hline
Instante & Entrada &  Pila2 & Acción \\
\hline
0 & i+i+i\$ & 0 & d4: desplazar i, saltar a 4\\
\hline
1 & +i+i\$ & 0i4 & r3: Reducción con regla 3, T -> i \\
\hline
2 & +i+i\$ & 0& 7: desplazar T, ir a 7 \\
\hline
3 & +i+i\$ & 0T7 & r1: reducción E -> T\\
\hline
4  & +i+i\$ & 0 & 1: desplazar E, ir a 1 \\
\hline
5 & +i+i\$  & 0E1 & d2: desplazar +, saltar a 2\\
\hline
6 & i+i\$  & 0E1+2 & d4: desplazar i, saltar a 4\\
\hline
7 & +i\$ & 0E1+2i4 & r3: reducción T -> i \\
\hline
8 & +i\$ & 0E1+2 & 3: desplazar T, ir a 3 \\
\hline
9 & +i\$ & 0E1+2T3 & r2: reducción E -> E+T \\
\hline
10 & +i\$ & 0 & 1: desplazar E, ir a 1 \\
\hline
11 & +i\$ & 0E1 & d2: desplazar +, saltar a 2 \\
\hline
12 & i\$ & 0E1+2 & d4: desplazar i, saltar a 4 \\
\hline
13 & \$ & 0E1+2i4 & r3: reducción T -> E\\
\hline
14 & \$ & 0E1+2 & 3: desplazar T, ir a 3 \\
\hline
15 & \$ & 0E1+2T3 & r2: reducción E -> E+T \\
\hline
16 & \$ & 0 & 1: desplazar E, ir a 1 \\
\hline
17 & \$ & 0E1 & Acepar: desplazas \$ y saltas a $S_{acc}$ \\
\hline
\end{tabular}
\end{example}

\begin{example}
Veamos un ejemplo del análisis de una expresión que termina en error:

\begin{center}
\includegraphics[scale=0.3]{img/tablaanallr0error.jpg}
\end{center}
\end{example}

\subsubsection{Conflictos, y herramientas para solucionarlos}
Vamos a definir nuevos conceptos que pondremos en práctica en esta sección.

Las tablas LR(0) no son suficientemente potentes para representar todo tipo de gramáticas. Podemos encontrarnos dos tipos de conflictos:

\begin{itemize}
\item Conflicto desplazamiento/reducción: Se producen cuando te encuentras en un estado final y además de la reducción, existe la posibilidad de desplazar.
\item Conflicto reducción/reducción: Se producen cuando te encuentras en un estado final y puedes realizar una reducción utilizando dos reglas diferentes.
\end{itemize}

Para solucionar estos conflictos definimos primero(x) y siguiente(x):

\begin{defn}[Primero(A)]
El primero de A es el conjunto de terminales que pueden aparecer al principio de una cadena derivada de A.
\end{defn}

Veamos cómo calcular el primero de A. Para ello observamos que existen tres diferentes casos para una regla de la forma $A \rightarrow α$:
\begin{enumerate}
\item $α \in T$ (Si α es un símbolo terminal):  primero(A)=α
\item $α \in N$ (Si α es un símbolo no terminal): primero(A)=primero(α)

%\item $α = α_1α_2...α_n \in T \cup %N$: Este sería el caso más %interesante. Vamos a construir %primero(A) por partes.
%\begin{verbatim}
%primero(A) añadimos primero(α1)-{λ}
%si λ pertenece a primero(α1):
%    añadimos primero(α2)-{λ}
%    si λ pertenece a primero(α2):
%        añadimos primero(α3)-{λ}
\end{enumerate}

Veamos un ejemplo
\begin{example}
Dada la gramática:
\begin{itemize}
\item $E \rightarrow TE'$
\item $E' \to +TE'$
\item $E' \to λ$
\item $T \to FT'$
\item $T' \to *FT'$
\item $T' \to λ$
\item $F \to (E)$
\item $F \to i$
\end{itemize}

Vamos a calcular el primero de algunos símbolos. Por ejemplo:

primero(E')=$\{+, λ\}$

primero(T')=$\{*, λ\}$

primero(F)=$\{(, i\}$

primero(T)=$\{(, i\}$

primero(E)=$\{(, i\}$
\end{example}

\begin{example}
Si tuviéramos la misma gramática que en el apartado anterior cambiando la regla $T' \rightarrow λ$ por $T' \rightarrow λT$, entonces:

primero(T')=$\{*,λ, (, i\}$
\end{example}



\begin{defn}[Siguiente(A)]
Dada una gramática, el siguiente de un elemento, A, es el conjunto de símbolos terminales que pueden aparecer justo después de A en alguna forma sentencial derivada del axioma.
\end{defn}

Para calcularlo formalmente, dada una regla $\appl{}{X}{\alpha A \{\beta_1,\beta_2,...\}}$, con $\alpha, \beta_i \in \sum^*$
\begin{enumerate}
\item añadimos primero($\beta_1$) $\setminus \lambda$  a siguiente(A).
\item si $\lambda \in$ primero($\beta_1$), repetimos (1) con $\beta_2$.
\end{enumerate}
\begin{itemize}
\item iteramos hasta que $\lambda \notin$ primero($\beta_j$) o se acaben los símbolos a su derecha.
\item si se acaban los símbolos a su derecha, añadimos siguiente(X) a siguiente(A).
\item si el algoritmo te lleva a que en siguiente de un símbolo se debe unir siguiente de ese mismo símbolo, se ignora.
\end{itemize}

\obs $\$ \in $ Siguiente(axioma) siempre (Al formar la gramática extendida). En este caso como el axioma es E, y ya existe un E', habría que definir una nueva regla del tipo $E'' \rightarrow E\$$

Veamos un ejemplo para poner en práctica lo aprendido:

\begin{example}
Considerando la misma gramática del ejemplo anterior, tenemos:

E es el axioma, y por tanto tenemos que:

siguiente(T)=primero(E') $\cup$ siguiente(E') $\cup$ siguiente(E) = $\{ +, ), \$\}$

siguiente(E')=siguiente(E) = $\{ ), \$ \}$

siguiente(E)=$\{ ), \$\}$

siguiente(F)=primero(T') $\cup$ siguiente(T) $\cup$ siguiente(T') = $\{ +, *, ), \$ \}$

siguiente(T')=siguiente(T) = $\{ +, ), \$ \}$
\end{example}


\subsection{Tablas SLR(1)}

Las tablas de análisis SLR(1) surgen para solucionar los conflictos desplazamiento/reducción. Lo vemos con un ejemplo:
\newpage
\begin{example}
Definimos la siguiente gramática extendida para aplicarle la tabla de análisis LR(0):

\begin{itemize}
\item (0) B' $\rightarrow$ B \$
\item (1) B $\rightarrow$ bD;Ef
\item (2) D $\rightarrow$ d
\item (3) D $\rightarrow$ D;d
\item (4) E $\rightarrow$ e
\item (5) E $\rightarrow$ e;E
\end{itemize}

Genera el siguiente autómata:
\begin{center}
\includegraphics[scale=0.4]{img/automatalr0conflicto.jpg}
\end{center}

En el cual podemos observar que en el estado final $S_7$ tenemos dos posibles acciones si entra un ';', la de reducir (por ser estado final y encontrarse el '.' a la derecha de la regla) o la de desplazar al estado $S_{10}$

Por tanto nos quedaría la siguiente tabla de análisis LR(0):

\begin{center}
\includegraphics[scale=0.3]{img/tablaanalisislr0conflicto.jpg}
\end{center}
\end{example}
Concluimos que no es por tanto un autómata LR(0) ya que tenemos conflictos que debemos solucionar. Para ello usaremos SLR(1).

\begin{defn}[Tabla SLR(1)]
Tabla que mejora la tabla de análisis LR(0) modificando las transiciones de los estados finales del autómata.

En el caso de LR(0) realizaban una reducción siempre, mientras que en SLR(1) se específica cuándo hay que realizar una reducción, cuándo un desplazamiento, y cuándo vamos a un estado de error.
\end{defn}

Por tanto el autómata quedará igual a simple vista (sólo que ahora habra más transiciones a estados de error aunque estas no aparezcan dibujadas). Los cambios los mostraremos en la tabla de análisis.

La idea principal del análisis SLR(1) es que sólo aplicaremos las reducciones de reglas de la froma $X \rightarrow $ algo, delante del \textbf{Siguiente(X)}.

Vamos a calcular los elementos siguientes de los no terminales B, D y E.

\begin{itemize}
\item siguiente(B) $\rightarrow$ {\$}, por tanto las reducciones de B sólo se producirán delante del símbolo \$.
\item siguiente(D) $\rightarrow$ {;}, por tanto las reducciones de B sólo se producirán delante del símbolo \$.
\item siguiente(E) $\rightarrow$ {f}, por tanto las reducciones de B sólo se producirán delante del símbolo \$.
\end{itemize}

Se eliminan así los conflictos, quedando la tabla de análisis de la siguiente manera:

\begin{center}
\includegraphics[scale=0.4]{img/tablaanalisisslr1.jpg}
\end{center}

Como podemos observar, en el estado S7, se reduce siguiendo la regla (4) (ver las reglas de la gramática definidas al principio del ejemplo), pero sólo si el siguiente elemento de la entrada es una f, ya que siguiente(E)={f}.
\newpage
Conclusión: Para realizar una tabla de análisis SLR(1) basta con:
\begin{enumerate}
\item Hacer la tabla de análisis LR(0).
\item Calcular los elementos siguientes de los símbolos no terminales.
\item Modificar las filas de la tabla que correspondan a estados finales. Poniendo huecos en blanco en todas las casillas salvo en aquellas en las que haya desplazamiento y aquellas en las que realmente reduzcamos, es decir, en las que el siguiente elemento del que vayamos a reducir coincida con el de la entrada.
\end{enumerate}


\subsection{Tablas LR(1)}
Las tablas LR(1) surgen para corregir los conflictos desplazamiento/reducción que no es capaz de solventar el análisis SLR(1).

Veamos dos ejemplos en los que el análisis SLR(1) falla:

\begin{example}
Definimos la siguiente gramática extendida para aplicarle la tabla de análisis SLR(1):

\begin{itemize}
\item (0) E' $\rightarrow$ E \$
\item (1) E $\rightarrow$ E+E
\item (2) E $\rightarrow$ E*E
\item (3) E $\rightarrow$ i
\end{itemize}

Genera el siguiente autómata:
\begin{center}
\includegraphics[scale=0.5]{img/automataslr1conflicto.jpg}
\end{center}

En el cual podemos observar que en el estado final $S_6$ podríamos desplazar o reducir para los símbolos '+' y '*'. Ya que siguiente(E)=$\{+,*\$\}$.

\newpage
Por tanto nos quedaría la siguiente tabla de análisis:

\begin{center}
\includegraphics[scale=0.4]{img/tablaanalisisslr1conflicto.jpg}
\end{center}
\end{example}

\begin{example}
Definimos la siguiente gramática extendida para aplicarle la tabla de análisis SLR(1):

\begin{itemize}
\item (0) S' $\rightarrow$ S \$
\item (1) S $\rightarrow$ xb
\item (2) S $\rightarrow$ A
\item (3) A $\rightarrow$ aAb
\item (4) A $\rightarrow$ x
\end{itemize}

Genera el siguiente autómata:
\begin{center}
\includegraphics[scale=0.5]{img/automataslr1c1.jpg}
\end{center}

En el cual vuelve a ocurrir algo parecido a lo del ejemplo anterior. En este caso tenemos que:
\begin{itemize}
\item siguiente(S)=$\{\$\}$
\item siguiente(A)=$\{b,\$\}$
\end{itemize}
Por tanto nos quedaría la siguiente tabla de análisis:

\begin{center}
\includegraphics[scale=0.4]{img/tablaanalisisslr1c1.jpg}
\end{center}
\end{example}

Mediante el análisis SLR(1) no añadíamos ningún estado más al autómata, únicamente cambiábamos la tabla de análisis. Ahora, con LR(1) vamos a añadir más estados a nuestro autómata. Así, para formar un autómata LR(1) realizamos los siguientes pasos:

\begin{enumerate}
\item Ahora la gramática extendida no va a tener una regla que sea $S' \rightarrow S\$$ sino que esta regla será $S' \rightarrow S\{\$\}$.
\item Vamos a formar cada estado como en LR(0), poniendo un '.' delante del símbolo que estamos evaluando y \textbf{cerrando} ese símbolo como ya explicamos anteriormente.
\item A cada regla que aparezca en cada estado del autómata se deberá añadir entre corchetes lo que llamaremos el \textbf{símbolo de adelanto}.

Este símbolo es el siguiente(X) si tenemos $X \rightarrow ABC...$, es decir, el siguiente del símbolo no terminal situado a la izquierda de la regla.

\obs Al realizar un desplazamiento se mantiene el símbolo de adelanto de cada regla sobre la que desplazamos y se recalcula para las reglas añadidas para componer el cierre .

\end{enumerate}

Como resultado, tendremos un mayor número de estados ya que si el símbolo de adelanto cambia, habrá que definir un nuevo estado.

\begin{example}
Usando la gramática del ejercicio anterior, generamos el siguiente autómata usando LR(1):

\begin{center}
\includegraphics[scale=0.65]{img/automatalr1.jpg}
\end{center}
\obs En este ejemplo hay una errata. En los estados $S_0$, $S_3$ y $S_7$ la regla $A::== .Ab \{\$\}$ debería ser $A::== .Ab \{b\}$, puesto que Siguiente(A) =$\{b\}$ y la regla $A::== .x \{\$\}$ debería ser $A::== .x \{b\}$

Como podemos observar, en este autómata se eliminan los conflictos que teníamos antes. Nos fijamos en la clave de esto.

Nos quedaría la siguiente tabla de análisis:

\begin{center}
\includegraphics[scale=0.4]{img/tablaanalisislr1.jpg}
\end{center}
\end{example}

\subsection{Tablas LALR(1)}

El análisis LALR(1) supone reducir el tamaño de la tabla de análisis de LR(1), a cambio de la posibilidad de aparición de conflictos reducción/reducción.

Debemos tener en cuenta que buena parte de la complejidad del algoritmo recae en el coste de procesar la entrada siguiendo un autómata y que, cuando menor sea el mismo menor será el coste.

La principal diferencia que aporta el análisis LALR(1) consiste en la agrupación de estados finales que sólo difieran en los símbolos de adelanto.

Veamos como transformar un autómata LR(1) en un autómata LALR(1).

\includepdf[frame=true, noautoscale=true, delta=10 10, nup=2x4,pages={32-39}, scale=0.72]{pdf/lrpres.pdf}
\includepdf[frame=true, noautoscale=true, delta=10 10, nup=2x4,pages={40-41}, scale=0.72]{pdf/lrpres.pdf}



\section{Análisis descendente}
Vamos a estudiar cómo se desarrollan los algoritmos de análisis descendente.

Ya los mencionamos anteriormente pero, para ver cómo funcionan, vamos a realizar algunos ejemplos por fuerza bruta, para captar la idea del asunto.

\begin{example}
Empezaremos por una gramática sencillita:
\begin{itemize}
\item S $\rightarrow$ aSb
\item S $\rightarrow$ ab
\end{itemize}
y trataremos de ver si la cadena $aabb$ se deriva de esta gramática.

Para empezar a estudiar el ejemplo, debemos tener en cuenta dos máximas del análisis descendente:

\textbf{La cadena se lee desde la izquierda}

\textbf{Realizaremos siempre derivaciones Left most}

Vamos a realizar el ejercicio por \textit{fuerza bruta}.
\begin{verbatim}
Para empezar derivamos el axioma con la primera regla (en realidad daría igual
cual coger).
Obtenemos por tanto S->aSb y vemos que es compatible con la cadena buscada.

Tomamos ahora el elemento no terminal situado más a la izquierda y lo derivamos.
Obtenemos así S->aSb->aaSbb que vemos que es compatible con la entrada.

Derivamos una vez más el siguiente elemento no terminal más a la izquierda.
En esta ocasión llegamos a S->...->aaaSbbb que ya no es compatible con la
cadena de modo que deshacemos la última operación.

Tratamos de aplicar la segunda regla.
Así obtenemos S->...->aaabbb que tampoco es compatible por lo que volvemos
a deshacer el último paso.

Nos hemos quedado sin reglas por aplicar, de modo que debemos deshacer una
acción más. Volvemos al estado S->aSb y tratamos de aplicar la segunda regla:
Llegamos a S->aSb->aabb y vemos que coincide con la cadena buscada.
\end{verbatim}
\end{example}

Al explicar el algoritmo empleado hemos hecho alusión a la compatibilidad. Definámosla formalmente.

\begin{defn}[Compatibilidad]
Para comprobar si la cadena que tenemos ahora mismo es \textbf{compatible} con la cadena que estamos buscando simplemente vemos si los primeros símbolos terminales (hasta el primer no terminal) coinciden.
\end{defn}

Tal y como lo hemos explicado ,el algoritmo de análisis descendente presenta dos problemas graves:
\begin{enumerate}
\item Es extremadamente ineficiente
\item Recursividad por la izquierda.

Si nos encontramos con una gramática del tipo
\begin{itemize}
\item S $\rightarrow$ b
\item S $\rightarrow$ Sb
\end{itemize}
y buscamos la cadena $abb$ entraríamos en un problema de recursión infinita pues aplicar la primera regla no nos da la solución final en ningún caso y con la segunda regla tendremos siemrpe al inicio de la cadena un símbolo que no es terminal.
\end{enumerate}

Para clasificar las gramáticas según puedan causarnos o no este problema vamos a definir un nuevo concepto

\begin{defn}[Gramática LL(1)]
Gramática en la que todas las reglas presentan en la parte derecha 1 símbolo no terminal seguido de un símbolo cualquiera (terminal o no terminal).

Además, dos reglas con la misma parte izquierda deben un terminal distinto al inicio de su parte derecha.
\end{defn}

Estas gramática son muy interesantes ya que presentan un claro determinismo, que nos evita de hacer backtracking con lo que hacen la búsqueda muy eficiente.


Veremos dos métodos para el análisis de gramáticas de este tipo pero antes debemos definir un nuevo concepto muy importante de cara al análisis descendente: \textbf{Forma normal de Greigbach}

\subsection{Forma normal de Greigbach}

\begin{defn}[Forma normal de Greigbach]
Decimos que una gramática está en forma normal de Greigbach si todas las reglas son de la forma:
\[A \rightarrow a\beta \text{ donde } a \in T, \ \beta \in N^*\]
\end{defn}

\obs Todas las gramáticas pueden expresarse en forma normal de Greigbach.

Una vez que una gramática está expresada de esta forma, comprobamos si es, además, LL(1) y si es así ya lo tenemos.

Vamos a ver cómo tratar una gramática que no esté expresada en forma normal de Greigbach. En estos casos debemos solucionar, antes de nada, los dos problemas que nos impiden que la gramática esté en esta forma normal

\begin{enumerate}
\item \textbf{Eliminación de reglas recursivas por la izquierda}

Dada una gramática de la forma
\begin{itemize}
\item A $\rightarrow$ A$\beta$
\item A $\rightarrow$ α
\end{itemize}
la convertimos en otra
\begin{itemize}
\item A $\rightarrow$ αX
\item X $\rightarrow$ $\beta$X|λ
\end{itemize}

\item \textbf{Eliminar símbolos no terminales del principio de la parte derecha de las reglas.}


Vamos a clasificar las reglas en tres tipos:
\begin{enumerate}
\item $A \rightarrow aZ$
\item $A_i \rightarrow A_jα$ con $A_i$ precediendo a $A_j$
\item $A_i \rightarrow A_jα$ con $A_j$ precediento a $A_i$
\end{enumerate}

El algoritmo a seguir sería:
\begin{enumerate}
\item Dejamos las reglas de Tipo a) como están.
\item Eliminamos las reglas de Tipo c), empezando con aquellas cuyo símbolo de la parte derecha tiene mayor precedencia
\item Eliminamos las reglas de Tipo b), empezando con aquellas cuyo símbolo de la parte izquierda tenga menor precedencia.
\end{enumerate}
\item \textbf{Eliminar símbolos terminales de más.}

Para ello, dada una regla
\[A \rightarrow abX\]

pasamos a dos reglas:
\[A \rightarrow aBX\]
\[B \rightarrow b\]

\item \textbf{Eliminar reglas λ}
\item \textbf{Eliminar indeterminismo}

Dadas reglas de la forma
\begin{enumerate}
\item $A \rightarrow aZ$
\item $A \rightarrow aB$
\end{enumerate}
sacamos factor común y llegamos a
\begin{enumerate}
\item $A \rightarrow aW$
\item $W \rightarrow B$
\item $W \rightarrow Z$
\end{enumerate}

Tras este paso vemos si aparecen reglas recursivas. En caso afirmativo, las eliminamos nates de seguir.
\item \textbf{Volvemos al primer paso y repetimos}

\obs Si la gramática no es LL(1) este algoritmo no converge
\end{enumerate}

Veamos un ejemplo de cómo aplicar este algoritmo
\begin{example}
Tomamos la gramática:
\begin{itemize}
\item $E \rightarrow E+T$
\item $E \rightarrow T$
\item $T \rightarrow T*T$
\item $T \rightarrow F$
\item $F \rightarrow i$
\end{itemize}
Primero eliminamos las reglas recursivas por la izquierda y nos quedamos en:
\begin{itemize}
\item $E \rightarrow TX$ (tipo 2)
\item $X \rightarrow +TX|λ$ (tipo 1)
\item $T \rightarrow FY$ (tipo 2)
\item $Y \rightarrow *FY|λ$ (tipo 1)
\item $F \rightarrow i$ (tipo 1)
\end{itemize}
donde hemos indicado el tipo de cada regla, preparándonos así para el paso siguiente.

Ahora tenemos que eliminar los símbolos no terminales del principio de la parte derecha de las reglas. Para ello aplicamos las siguientes transformaciones
\begin{itemize}
\item $T \rightarrow FY \ \implies T \rightarrow iY$
\item $E \rightarrow TX \ \implies E \rightarrow FYX \implies F \rightarrow iYX$
\end{itemize}
en el orden exacto en que se han indicado.

El resultado por el momento es:
\begin{itemize}
\item $E \rightarrow iYX$
\item $X \rightarrow +TX$
\item $X \rightarrow λ$
\item $T \rightarrow iY$
\item $Y \rightarrow *FY$
\item $Y \rightarrow λ$
\item $F \rightarrow i$
\end{itemize}

Pero a esta gramática aún le falta algo para ser de Greibach, tenemos que eliminar las transiciones vacías, obteniendo:
\begin{itemize}
\item $E \rightarrow iYX$
\item $E \rightarrow iY$
\item $E \rightarrow iX$
\item $E \rightarrow i$
\item $X \rightarrow +TX$
\item $X \rightarrow +T$
\item $T \rightarrow iY$
\item $T \rightarrow i$
\item $Y \rightarrow *FY$
\item $Y \rightarrow *F$
\item $F \rightarrow i$
\end{itemize}
El método seguido se basa en la duplicación de aquellas reglas que contengan $Y$ ó $X$ (los no terminales que ocasionaban transiciones λ) añadiéndoles una opción sin esas variables, que es lo que obtendríamos si empleásemos la derivación λ
\end{example}

El último paso llevado a cabo en el ejemplo (eliminación de reglas λ) no es siempre necesario.

Recordemos que queríamos saber si una gramática era de forma normal de Greibach con el fin de reconocer si era LL(1). Desde el último estado que hemos alcanzado en la gramática, para convertirla en una gramática LL(1) deberíamos eliminar los no terminales que aparecen repetidos en numerosas reglas.

Sin embargo, desde el paso anterior tendríamos directamente que la gramaica es LL(1).

La pregunta que surge ahora está clara:

\subsection{¿Cuándo nos interesa eliminar las transiciones λ?}
En general, nos interesará eliminar las transiciones λ siempre que al hacerlo no estemos generando una gramática no LL(1). Es decir, queremos eliminar estas transiciones sin dar lugar a gramáticas no deterministas.

En general,
\[\text{ primero}(X) \cap \text{ siguiente}(X) = \emptyset \implies \ X \rightarrow λ\text{ no molesta para LL(1)}\]

En el ejemplo anterior ninguna de las reglas λ nos molestaban de modo que podíamos prescindir del último paso para garantizar que la gramática es LL(1)

\subsection{Analisis LL(1) usando la tabla}
El algoritmo a seguir es el siguiente
\begin{enumerate}
\item Inicializamos la pila con S\$
\item Inicializamos la entrada al primer elemento de la cadena
\item Comparamos la pila con la entrada
\begin{enumerate}
\item pila=entrada=\$ \textbf{FIN}
\item pila contiene x$\in T$
\begin{enumerate}
\item x = entrada $\implies$ \textbf{desplazamos entrada y pop}
\item x $\neq$ entrada $\implies$ \textbf{ERROR}
\end{enumerate}
\item pila contiene $x \in N \implies$ \textbf{saco x de la pila y meto $\beta$}.
\end{enumerate}
\end{enumerate}

Veamos un pequeño ejemplo de cómo aplicar este algoritmo.
\begin{example}
Consideremos la gramática:
\begin{itemize}
\item $S \rightarrow E \$$
\item $E \rightarrow TE'$
\item $E'\rightarrow +TE'$
\item $E'\rightarrow λ$
\item $T \rightarrow FT'$
\item $T' \rightarrow *FT'$
\item $T' \rightarrow λ$
\item $F \rightarrow i$
\item $F \rightarrow (E)$
\end{itemize}
Y vamos a analizar con ella la entrada
\[i+i*i\$\]

La tabla queda:
%TODO copiar tabla
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c |}
\hline
Simbolo & + & * & i & ( & ) & \$ \\
\hline
E &  &  & E $\rightarrow$TE' & $E\rightarrow TE'$ & & \\
\hline
E' & $E'\rightarrow +TE'$ & & & & $E'\rightarrow λ$ & $E'\rightarrow λ$\\
\hline
T & &  & $T \rightarrow FT'$ & $T \rightarrow FT'$ & & \\
\hline
T' & $T' \rightarrow λ$ & $T' \rightarrow λ$ & & & $T' \rightarrow λ$ & $T'\rightarrow λ$  \\
\hline
F & & & $F\rightarrow i$ & $F\rightarrow (E)$ & &\\
\hline
\end{tabular}
\end{center}

y el análisis resulta:
\begin{center}
\begin{tabular}{| c | c | c | c |}
\hline
0 & i+i*i\$ & S\$ & derivar E$\rightarrow$TE' \\
\hline
1 & i+i*i\$ &  TE'\$ & derivar T $\rightarrow$ FT' \\
\hline
2 & i+i*i\$ &  FT'E'\$ & derivar F$\rightarrow$i \\
\hline
3 & i+i*i\$ &  iT'E'\$ & desplazar entrada \\
\hline
4 & +i*i\$ &  T'E'\$ & derivar T' $\rightarrow$ λ \\
\hline
5 & +i*i\$ &  E'\$ & derivar E' $\rightarrow$ TE' \\
\hline
6 & +i*i\$ &  +TE'\$ & desplazar \\
\hline
7 & i*i\$ &  TE'\$ & dderivar T $\rightarrow$ FT' \\
\hline
8 & i*i\$ &  FT'E'\$ & derivar F $\rightarrow$ i \\
\hline
9 & i*i\$ &  iT'E'\$ & desplazar \\
\hline
10 & *i\$ &  T'E'\$ & T' $\rightarrow$ *FT' \\
\hline
11 & *i\$ &  *FT'E'\$ & desplazar \\
\hline
12 & i\$ &  FT'E'\$ & F $\rightarrow$ i \\
\hline
13 & i\$ &  iT'E'\$ & desplazar \\
\hline
14 & \$ &  T'E'\$ & T' $\rightarrow$ λ \\
\hline
15 & \$ &  E'\$ & E' $\rightarrow$ λ \\
\hline
16 & \$ &  \$ & OK \\
\hline
\end{tabular}
\end{center}
\end{example}

\begin{example}
Consideremos la gramática:
\begin{itemize}
\item $P \rightarrow iEtPP' \$$
\item $P \rightarrow a$
\item $P'\rightarrow EP$
\item $P'\rightarrow λ$
\item $E \rightarrow b$
\end{itemize}
Vamos a construir ahora la tabla de análisis asociado.

Para ello tenemos que ver cuál es el siguiente de cada elemento no terminal y dejar claro en la tabla que sólo aplicamos la reducción delante del siguiente

La tabla de análisis asociada sería:
\begin{center}
\begin{tabular}{| c | c | c | c | c | c | c |}
\hline
Simbolo & a & t & e & b & i & \$ \\
\hline
P &  $P \rightarrow a$&  & &  &  $P \rightarrow iEtPP'$ & \\
\hline
P' & & & $P' \rightarrow  EP$   $ P' \rightarrow λ$ & & &  $ P' \rightarrow λ$ \\
\hline
E & &  &  & $E \rightarrow b$ & & \\
\hline
\end{tabular}
\end{center}

Como podemos observar, esta gramática no es LL(1)
\end{example}

Vamos a hacer incapié en la diferencia entre gramática LL(1) y lenguaje LL(1)
\begin{defn}[Gramática LL(1)]

Gramática cuya tabla de análisis LL(1) no presenta conflictos
\end{defn}

\begin{defn}[Lenguaje LL(1)]

Lenguaje para el cual existe una gramática LL(1) que lo genera
\end{defn}

\begin{example}
La gramática
\begin{itemize}
\item $ S \rightarrow aSb$
\item $ S\rightarrow ab$
\end{itemize}
no es una gramática LL(1), cosa que podemos comprobar construyendo su tabla de análisis LL(1). Sin embargo, su lenguaje asociado si que es LL(1) ya que podemos transformarla en
\begin{itemize}
\item $ B \rightarrow b$
\item $ S \rightarrow aW$
\item $ W \rightarrow aWb$
\item $ W \rightarrow b$
\end{itemize}
que si es LL(1) (de nuevo lo comprobamos construyendo su tabla de análisis LL(1)).
\end{example}


\subsection{Análisis LL(2) usando la tabla}
La principal diferencia del análisis LL(2) respecto al LL(1) radica en que ahora vamos a tomar \textbf{dos símbolos de adelanto}

Veámoslo para el caso particular de la gramática
\begin{itemize}
\item S $\rightarrow$ aSb
\item S $\rightarrow$ ab
\end{itemize}

En este caso sería tremendamente sencilla la tabla de símbolos:
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Simbolo & aa & ab \\
\hline
S &  S $\rightarrow$ ab &  S $\rightarrow$ aSb \\
\hline
\end{tabular}
\end{center}


Pero aún quedan casos en los que no podemos resolver los conflictos ni usando LL(2).

Por ejemplo, en la gramática
\begin{itemize}
\item FUNCION -> TIPO ID (ARGS);
\item FUNCION -> TIPO ID (ARGS) \{CUERPO\}
\item ARGS -> λ
\item ARGS -> ARG ARGS
\item TIPO -> int | float
\item ARG -> ID
\item ID -> $(a+...+z)(a+...+z)^*$
\end{itemize}

A la hora de trabajar con la regla \textbf{FUNCION -> TIPO ID (ARGS)} no sabemos cuántos argumentos vamos a encontrar.

La solución para este problema pasa por usar expresiones regulares, lo que nos lleva al análisis LL(*)

\subsection{Análisis LL(*)}
Consiste en emplear expresiones regulares en lugar de símbolos de adelanto.

Continuando con el ejemplo anterior, para resolver el problema con LL(*) consideramos la expresión regular:
\[r=(int+float).(a-z)^+."(".[(a-z)^+]*.")"\]
y la tabla quedaría (para la regla que causaba el problema)
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Símbolo & r.";" & r."ε" \\
\hline
FUNCION & FUNCION -> TIPO ID (ARGS); &  FUNCION -> TIPO ID (ARGS) \{CUERPO\} \\
\hline
\end{tabular}
\end{center}
En este caso no hay problemas pues es bastante sencilla la tabla mostrada. No obstante, en un caso más general sería necesario cuidar que no se solapen las expresiones regulares empleadas en el análisis.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\chapter{Ejercicios}
\input{tex/Ejercicios.tex}

\chapter{Ejercicios 1ª Hoja}
\input{tex/ejerciciosHoja1/ejsAutlen.tex}

\chapter{Ejercicios 2ª Hoja}
\input{tex/ejerciciosHoja2/HOJA2.tex}

\chapter{Ejercicios 3ª Hoja}
\input{tex/ejerciciosHoja3/HOJA3.tex}


\printindex
\end{document}
