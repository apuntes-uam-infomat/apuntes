\section{Teoremas del Rango}

¿Dónde está escondida la indentidad en un sistema de ecuaciones (lineales o no)?

\begin{theorem}[Teorema\IS del rango (1)]
Sea \[\appl{F}{\Omega\subset \real^M\times\real^N}{\real^N}\]
\[F\in C^1, (\ga,\gb) \in \Omega \text{ con } \ga \in \real^M, \gb \in \real^N\]
Supongamos que $DF(\ga,\gb)$ tiene rango $n$ (máximo posible).

Entonces: $\exists$ un abierto $\omega$ con $(\ga,\gb) \in \omega$ y una función \[ \appl{G}{\omega\subset\real^M\times\real^N}{\real^M\times\real^N}, G\in C^1 (\omega)\] con inversa local diferenciable, tal que \[F\circ G(\gor{u},\gor{v}) = \gor{v}, \forall(\gor{u},\gor{v})\in \omega\]

\end{theorem}

\begin{proof}
 Reordenamos las variables de manera que \[DF(\ga,\gb) = \begin{array}{c|c} A &B \end{array}\]
 \[A \in M_{m\times m}, B = D_yF(\ga,\gb), \det B \neq 0\]
 
 Definimos \[H(\gx,\gy) = (\gx,F(\gx,\gy))\]
 Calculamos:
 \[DH = \left(\begin{array}{c|c}
         I & \\
         \underbrace{D_xF}_{m\times n} & \underbrace{D_yF}_{n\times n}
        \end{array}\right)\]
        
        
  Estudiamos el determinante: $\det DH = \det D_yF \neq 0$ debido a la reordenación de las variables que hemos hecho al principio. Además, $F\in C^1 \implies H \in C^1$. Estamos en condiciones de aplicar el teorema de la función inversa. $\exists$ una inversa LOCAL $H^{-1}$

  \[H(x,y) = (u,v) \dimplies (x,y) = H^{-1}(u,v) \equiv (\underbrace{G_1(u,v)}_{\real^M},\underbrace{G_2(u,v)}_{\real^N})\]
  
  \begin{gather*}
H(H^{-1}(u,v)) = (u,v)\\
H(G_1(u,v),G_2(u,v))\\
= (G_1(u,v),F(G_1(u,v),G_2(u,v)))
  \end{gather*}
 Tomando $G(u,v) = (G_1(u,v),G_2(u,v))$ obtenemos que $F\circ G(u,v) = v$, para $(u,v)$ en un entorno del punto $(\ga,\gb)$
 
\end{proof}

\begin{theorem}[Teorema del Rango 2]
 \[\appl{F}{\real^N}{\real^N\times\real^M}\]
 \[F \in C^1, \ga \in \Omega\]
 
 Rango de $DF(\ga) = n$ (máximo).
 
 Entonces, $\exists \omega $ abierto en $\real^N\times\real^M$, con $F(\ga) \in \omega$.
 
 Y una función $ G\in C^1(\omega), \appl{G}{\real^M\times\real^N}{\real^M\times\real^N}$
 
  $G$ tiene inversa local diferenciable tal que $(G\circ F) (\underbrace{\gx}_{\real^N}) = (\underbrace{\gx}_{\real^N},\underbrace{\gor{0}}_{\real^M})$. 
\end{theorem}

\begin{proof}
 \[DF(\ga) = \begin{pmatrix}
              \dpa{F_1}{x_1} &\dots &\dpa{F_1}{x_n}\\
              \vdots&\ddots&\vdots\\
              \dpa{F_n+m}{x_1} &\dots & \dpa{F_n+m}{x_n}
             \end{pmatrix}
\]
Reordemamos las $F_j$ de la siguiente manera:
\[DF(\ga) = \overbrace{\left(\begin{array}{c}
		  \det\neq 0\\
		  \hline
                  \text{Resto}
                  \end{array}\right)}^{n \text{ columnas }}\begin{array}{c} \} \text{ n filas}\\ \} \text{ m filas}\end{array}\]

Definimos: 
\begin{align*}
H: \real^N\times\real^M &\longrightarrow \real^N\times\real^M\\
(\gx,\gy) &\longrightarrow \underbrace{F(\gx)}_{\real^N} + (\underbrace{\gor{0}}_{\real^N}, \underbrace{\gy}_{\real^M}) = (F(\gx),\gy)
\end{align*}

\[F(\gx) = H(\gx,\gy) = (F_1(\gx),F_2(\gx),...,F_n(\gx), F_{n+1}(\gx)+\gy_1,...,F_{n+m}(\gx)+\gy_m)\]
\[DH = \left(\overbrace{D_xF}^{\text{ N columnas}} \; \begin{array}{|c}0  \\ \hline Id \end{array}  \right) \begin{array}{c} \}\text{ n filas} \\  \}\text{ m filas} \end{array} \implies \det DH \neq 0
\]

Estamos en condiciones de aplicar el teorema de la función inversa $ \implies \exists$ una inversa local $\invers{H}$ tal que
\[\invers{H} \circ H(u,v) = (u,v), u\in \real^N,v\in\real^M\]
En particular:
\[\left. \begin{array}{c} \invers{H} \circ H (\gor{u},\gor{0}) = (\gor{u},\gor{0})\\
H(\gor{u},\gor{0}) = (F(\gor{u}) + (\gor{0}, \gor{0})) \end{array} \right\} \implies \invers{H} \circ H(\gor{u}+(\gor{0},\gor{0})) = \invers{H}(F(\gor{u})) = (\gor{u},\gor{0})\]
REVISAR: A partir del $\implies$ soy yo, no azorero.
\end{proof}

\begin{theorem}[Resultado general]
\[\appl{F}{\real^N}{\real^K}, F\in C^1\]
Con rango $DF = p < min\{n,k\}$

Existe $\Gamma (u_1(\gx),...,u_n(\gx)) = (\underbrace{u_1,...,u_p,0,...,0}_{k})$, siendo $\Gamma = \Phi \circ F \circ \invers{\Phi}$.
 
 Siendo $U$ un cambio de variable.
\end{theorem}

\paragraph{Hoja 3: Problema 21}

\[\left\{\begin{array}{cc}
   F_1\equiv x^2+z^2+2xz-2x-2z+1&=0\\
   F_2\equiv x^2+4y^2+4z^2+4xy+4xz+8xy&=0
  \end{array}\right.\]
  ¿Es depejable en función de z en un entorno de $(x,y) = (0,-1), z=1$?
  
Solución:

1) Ver que el punto safisface las ecuaciones.

2) Ese sistema es como definir:
\[\appl{F}{\real^3}{\real^2}, F\in C^1, F(0,-1,1) = (0,0)\]

3) Calculamos el determinante de $DF(0,-1,1)$ y vemos que da $0$. 

Conclusión: no podemos aplicar el teorema, pero pensando un poco vemos que 

\[F_1 = (x+z)^2 -2(x+z) + 1 = (x+z-1)^2\]
\[F_1 = 0 \dimplies x=1-z\]
\[F_2(x,y,z) = F_2(1-z,y,z) = (1-z)^2 + 4y^2 + 4z^2 + 4(1-z)y + 4(1-z)z+8yz\]
\[ =... = a(z)y^2+b(z)y+c(z) \implies y=\frac{-b\pm \sqrt{...}}{2a}\]
¿Cual de las 2 soluciones escoger? Sabemos (por el enunciado) que si $z=1$ entonces $y=-1$. Escogeremos la solución a la que dandole el valor $z=1$ nos de $-1$.

\paragraph{Hoja 3: Problema 22}

\[\begin{array}{cc}
   x^3+z^3y^3+z &= 0\\
   cos(xyz)+sen(z)-1 = 0
  \end{array}\]
 ¿Es despejable en función de $z$ en un entorno de $(x,y) = (0,0), z=0$.
 
 Solución:
 
 1) El punto es solución del sistema.
 
 2) Definimos \[\appl{F}{\real^3}{\real^2}, F\in C^1, F(0,0,0)=(0,0)\]
 
 3) Calculamos el determinante de $DF(0,0,0)$ y vemos que da $0$.
 
 Conclusión: no podemos aplicar el teorema\\
 Supongamos que si se puede despejar. Entonces tendríamos algo de la forma:

 \[\left\{\begin{array}{cc}
   [x(z)]^3+z^3[y(z)]^3+z &= 0\\
   cos(x(z)y(z)z)+sen(z)-1 = 0
  \end{array}\right\}\rightarrow \left\{ \begin{array}{cc}
               3[x(z)]^3x'(z) + 3z^2[y(z)]^2 + z^32y(z)y'(z) + 1 &=0\\
               -sen(x(z)y(z)z) \cdot\{...\} + cos(z) &= 0
              \end{array}\right\}
              \equiv\left\{
              \begin{array}{cc}
               0+1&=0\\
               0+1&=0
              \end{array}\right.\]
  Esto demuestra que no pueden existir las derivadas.

  
  \section{Subvariedades diferenciales}
  
  \paragraph{Introducción}
  
  En $\real^3$ tenemos puntos (dimensión 0), curvas (dimensión 1), superficies (dimensión 2) y abiertos (dimensión 3) sobre los que integrar en los que la imaginación resulta bastante útil. Pero... ¿qué pasa en $\real^N$? 
  
  Entonces en $\real^N$ tenemos objetos de dimensión $0,...,N$ sobre los que vamos a poder definir propiedades, integrales, etc.
  
  Repasamos la idea de que en $\real^3$ podíamos representar una superficie de varias maneras y como calcular su plano tangente.
  \begin{itemize}
   \item Gráfica: $z=f(x,y)$
   \item Parametrización: $\appl{\phi}{D\subset\real^2}{\real^3}$
     
     $\phi(u,v) = (x(u,v),y(u,v),z(u,v))$
     
     Para calcular el plano tangente:
     
     \begin{itemize}
      \item \[T_u = \left( \dpa{x}{u},\dpa{y}{u},\dpa{z}{u}\right)\]
      \item\[T_v = \left( \dpa{x}{v},\dpa{y}{v},\dpa{z}{v}\right)\]
      \item\[ \overrightarrow{n} = T_u\times T_v\]
     \end{itemize}

     Nos podemos encontrar el problema de que $\overrightarrow{n} = \overrightarrow{0}$. ¿Cómo preveer lo que puede salir?, el rango de la matriz de las 6 derivadas tiene que ser 2.
     
   \item Conjunto de nivel $F(x,y,z) = 0$ .
   
   Para calcular el plano tangente en este caso tenemos que $\overrightarrow{n} = \nabla F$. 
   
   Nos puede ocurrir que $F$ no sea derivable o que $\nabla F = \overrightarrow{0}$. Supongamos que sea diferenciable, ¿cómo preveer que puede salir? Otra vez la matriz de las derivadas tiene que tener rango máximo (en este caso 1)
  \end{itemize}
  
  Vamos a ver que pasa con las curvas en $\real^3$ y cómo calcular la recta tangente
  
  \begin{itemize}
   \item Parametrizada: \[\sigma(t) = (x(t),y(t),z(t))\]
   
   \item Intersección de 2 superficies transversales, es decir,
   
   \[C = \left\{\begin{array}{cc} F_1(x,y,z) &= 0\\ F_2(x,y,z) = 0 \end{array} \right.\]
   
   Posibles enemigos que nos podemos encontrar: superficies cuya intersección sea un plano. Si se da este caso, entonces tenemos que los vectores normales a las 2 superficies son paralelos. Para evitar esto, la matriz formada por los 2 vectores normales tenga rango máximo.
                                                                   
  \end{itemize}

  Los ingredientes para esta sección de la asignatura son:
  \begin{itemize}
    \item
    \item
   \item Matriz diferencial
   \item Rango
  \end{itemize}

  
  \begin{defn}[Subvariedad diferenciable]
  Sea $M \subset \real^{M+N}$.
  
  Diremos que M es una subvariedad diferenciable en $\real^{N+M}$ de dimensión n \[\dimplies \forall \exists \text{un entorno abierto} U \subset \real^{N+K}, \ga \in U \tlq U\cap M = \{\gx\in U\tq F(\gx) = \gor{0}\} \]\[\text{\textbf{para alguna función} } F\in C^1(U)\]
  \[\appl{F}{U\subset \real^{N+K}}{\real^K} \tlq \text{ rango } DF \text{ máximo } (=k)\]
  
  \[U\cap M = \left\{\begin{array}{cc}
                     F_1(x_1,...,x_{n+k}) = 0\\
                     F_2(x_1,...,x_{n+k}) = 0\\
                     \vdots\\
                     F_k(x_1,...,x_{n+k}) = 0
                    \end{array}\right.\] 
  \end{defn}

  Vamos a ver en un ejemplo un problema que tiene la definición:
  
  \paragraph{Ejemplos:}



Veamos ejemplos de si algunos objetos son variedades diferenciables o no:
PASAR A PARAGRAPHS

\paragraph{1)}
  Superficie en $\real^3$.
  
  \[\appl{F}{U\subset\real^3}{\real}\]
  \[\{(x,y,z) \tq F(x,y,z) = 0\}\]
  En este caso tenemos $N=2, K=1$.
  La condición de rango nos dice que $\nabla F(\gx) \neq (0,0,0) \implies $ en cada punto existe un vector normal $\overrightarrow{n}$
  \obs $M = \{z = f(x,y)\}$.
  
  Basta tomar $F(x,y,z) = f(x,y)-z$.
  \[DF = \left(\dpa{f}{x},\dpa{f}{y},-1\right) \neq (0,0,0)\]
  Las gráficas de funciones de 2 variables en $\real^3$ son siempre subvariedades (la condición de rango es gratuita)
  
\paragraph{2)}  Curvas en $\real^3$
  
  \[\sigma(t) = (x(t),y(t),z(t))\equiv S_1 \cap S_2 = \]
  \[= \{F_1(x,y,z) = 0\}\cap \{F_2(x,y,z) = 0\}\]
  Si tomamos $U\cap \sigma = \{(x,y,z)\in\real^3 \tq F_1 = 0 \y F_2 = 0\}$

  Siendo \[\appl{F}{U\subset\real^3}{\real^2}, N+K=3,K=2\]\[F(x,y,z) = (F_1(x,y,z),F_2(x,y,z))\]
  
  Veamos la condición de rango en este caso:
  
  \[rango \begin{pmatrix} \dpa{F_1}{x}&\dpa{F_1}{y}&\dpa{F_1}{z}\\\dpa{F_2}{x}&\dpa{F_2}{y}&\dpa{F_2}{z}\end{pmatrix}\]
  Para que el rango sea máximo, los vectores tienen que ser no paralelos, es decir, $S_1, S_2$ sean transversales, no paralelas.
  
  \paragraph{3)} Una manera un tanto rebuscada de definir un punto.
 \begin{gather*}
 \appl{F}{\real^K}{\real^K}
 \gx \rightarrow \gx - \ga
 \end{gather*}  
 
 \[M = \{\gx \in \real^K \tq F(\gx) = \gor{0}\} = \{\ga\}\]
 
 Tenemos $DF = Id \implies $ rango máximo.
 
 $\{\ga\}$ es una subvariedad diferenciable (dimensión 0, codimensión K)
 
 \paragraph{4)} $\appl{F}{\Omega\subset\real^N}{0}$. En este caso tenemos codimensión $0$ y dimensión $N$.
 
\paragraph{5)}
   \[\appl{F}{\real^2}{\real}\]
  
  Con $F(x,y) = x^3 - y^6$.
  \[M = \{(x,y) \tq x^3-y^6 = 0\}\]
  \[DF = (3x^2-6y^5)\]
  \[DF(0,0) = (0,0) \dimplies \text{ Rango 0}\]
  ¿Quiere esto decir que $M$ no es una subvariedad diferenciable en el 0?
  
  NOOOO
  
  Lo que quiere decir que no hemos encontrado la función que cumpla las hipótesis.
  \[M = \{x^3=y^6\} = \{x = y^2\}  = \{x-y^2 = 0\}\]
  
  Tomando $G(x,y) = x-y^2$, en la que $DG(x,y) = (1,2y)$ tiene rango 1 en el origen.
  

  Llamaremos a $N$ dimensión de $M$ y $K$ Codimensión.
 
  \paragraph{6)}
  
  \[M = \{(x,y)\in \real^2 \tq x^2-y^2 = 0\}\]
  
  Si 
	\[\appl{F}{\real^2}{\real}\]
	\[F(x,y) = x^2-y^2\]
  
  $DF = (2x,-2y)$. La condición de rango falla en $(0,0)$.
  
  Valoramos si este objeto NO es una subvariedad o si tendremos que definir una función de una manera más inteligente.
  
  En este caso, vemos que $M = \{ y=x \cup y = -x \}$. No debería ser una subvariedad, para ello vamos a intentar demostrarlo por reducción al absurdo.
  
  \emph{Supongamos} M subvareidad entonces existe un $U, (0,0) \in U$ y $\appl{G}{U\subset\real^2}{\real}, U\cap M = \{G(x,y) = 0\}$
  
\[rango DG(x,y) = 1, \forall(x,y) \in U\]
\[rango\left(\dpa{G}{x},\dpa{G}{y}\right) = 1\].

\subparagraph{Caso 1} Supongamos $\dpa{G}{x}(0,0) \neq 0$

Podemos aplicar el teorema de la función implícita: podemos despejar $x = x(y)$. En este caso:

$U \cap M = \{x(y)^2-y^2 = 0\}$.

Si fijamos $y=\varepsilon, \implies x(\varepsilon) = \pm \varepsilon$ No es una función. 

Es imposible que $\dpa{G}{x}(0,0) \neq 0$

\subparagraph{Caso 2} Pasa lo mismo con la derivada respecto de y (Ejercicio para el lector)


\textbf{Conclusión: } Este es el ejemplo de que cualquier objeto que tenga autointersección no puede ser subvariedad.


\paragraph{7)} $M = \{(x,y) \in \real^2 \tq x^2-y^2 = 0, y\ge 0\}$

Vamos a suponer que existe una función $F \in C^1$ que representa ese objeto (que viene definido por 2 condiciones). $M = \{F(x,y) = 0\}$ para alguna $F$.

Condición de rango: $\left(\dpa{F}{x},\dpa{F}{y}\right) \neq (0,0)$.

Estamos en el mismo caso anterior. Tenemos 2 posibilidades.

 $\dpa{F}{x} \implies $ Contradicción con el teorema de la función implícita.
 
 $x^2 - (y(x))^2 = 0 \implies y = \abs{x} \notin C^1$
 
 Completarlo se deja como ejercicio para el lector.

\paragraph{8)}

$N = \{(x,y)\in \real^" \tq x^2-y^2 = 0, y>0\}$

La lógica nos dice que este caso si debería ser subvariedad diferencial (ya que la definición de la función es local, y siempre podremos encontrar un entorno que no incluya el 0, que es el punto problemático).

La comprobación se deja como ejercicio para el lector.

\subsection{Subvariedades y parametrizaciones}
\paragraph{Ejemplo} Superficie en $\real^3$ parametrizada: $S = \{\Phi(u,v) = (x(u,v),y(u,v),z(u,v))\}$.

A la hora de trabajar con superficies parametrizadas, nos interesaría poder definir una especie de función inversa que nos permita hacer cambios en el plano y llevarlos a la superficie o al reves, pero... ¡tienen dimensiones distintas! La esperanza que nos queda es que la superficie parametrizada tiene dimensión 2, igual que el plano.


\subsection{Homeomorfismo}
\begin{defn}[Homeomorfismo]
Sea $\appl{\Phi}{\Omega\subset\real^N}{\real^{N+K}}, \Omega$ abierto.

$\Phi$ es un \emph{homeomorfismo} sobre su imagen $\dimplies $ la restricción $\appl{\Phi}{\Omega}{\Phi(\Omega)}$ es continua y tiene una inversa continua,
es decir, \[\exists \appl{\Psi}{\Phi(\Omega)}{\Omega} \tlq 
\left\{ \begin{array}{cc} 
\Psi(\Phi(\gor{u})) = \gor{u}, &\forall \gor{u} \in \Omega\\ 
\Psi(\Phi(\gor{x})) = \gor(x), &\forall \gx \in \Phi(\Omega)
\end{array}\right.\]

\paragraph{Definición 1)}
Dado un $\displaystyle \x_0 \in \Phi(\Omega) \implies \forall \varepsilon >0, \exists \delta>0 \tlq$ si $\begin{array}{lc}
\norm{\gx-\gor{x_0})} < \delta \implies \norm{\Psi(\gx)-\Psi(\gor{x_0})}<\varepsilon\\
\gx \in \Phi(\Omega)
\end{array}$

\paragraph{Definición alternativa de continuidad}
Si $\{X_n\}\subset\Phi(\Omega), \gor{X_n} \rightarrow \gor{x_0}\in\Phi(\Omega) \implies \Psi(\gor{X_n}) \rightarrow \Psi(\gor{x_0})$

\end{defn}

\paragraph{Ejemplo 1}

\[\appl{\sigma}{[0,2\pi)}{\real^2}\]
\[t \rightarrow \sigma(t) = (cos(t),sen(t))\]

Inversa: $\Psi(x,y) = t$ ángulo de la representación en polares.

Vamos a estudiar el problema de la continuidad:

Tomamos $\{(X_n,Y_n)\}$ con $x^2+y^2 = 1 \tlq (x_n,y_n) \convs (1,0)$

Si $\Psi$ es continua, debe ser $\Psi(x_n,y_n) \convs (1,0) = 0$. En este caso no es continua porque:

Si tomamos \begin{align*}
P_n &= \left(cos\left(2\pi - \frac{1}{n}\right), sen\left(2\pi - \frac{1}{n}\right) \right)
P_n &\convs (1,0)
\Psi(P_n) &= 2\pi - \frac{1}{n} \convs 2\pi\neq\Psi(1,0)
\end{align*}

\paragraph{Ejemplo 2}

\[\appl{f}{(0,1)\subset\real}{\real^2}\]
\[t \rightarrow f(t) = (t,g(t)), \text{continua, con inversa continua}\]

Vamos a definir la  inversa:
\[P\in f(0,1) \implies P(x,g(x)) \text{Para algún } x\in(0,1)\]
$P = (x,g(x))$

\[\Psi(P) = t \in (0,1) \tlq f(t) = (x,g(x)) \implies t = x\]
Vamos a estudiar la continuidad:
\[\{P_n\} \subset f(0,1), P_n \rightarrow P \in f(0,1)\]
\[P_i = (x_i,g(x_i)), \text{ para algún } i \in (0,1)\]
\[P_n \convs P_0 \dimplies (x_n,g(x_n)) \rightarrow (x_0,g(x_0)) \implies x_n (= \Psi(P_n)) \rightarrow x_0 (=\Psi(P_0)) \]

\obs ¿La gráfica de una función es homeomorfismo sobre su imagen?
\paragraph{Ejemplo 3}
\[\appl{\sigma_3}{(0,4\pi)}{\real^2}\]
\[t \rightarrow \sigma(t) = (cos(t),sen(t))\]
No es inyectiva $\implies \nexists \Psi$.

\paragraph{Ejemplo 4}
\[\appl{\sigma_4)}{(0,2\pi)}{\real^2}\]
\[t \rightarrow \sigma(t) = (cos(t),sen(t))\]
La diferencia con el ejemplo 1, es que es cerrado.

Hay que percatarse de que la $tg$ no es inyectiva, entonces... la inversa es algo más complicada que $arctg$
\[\Psi(x,y) = arctg\left(\frac{y}{x}\right)\in \left(\frac{-\pi}{2},\frac{\pi}{2}\right) (x\neq 0)\]

Vamos a definirla a trozos:

Dejuan: Guille, hazte una circunferencia y marca los trozos
\[
\begin{cases}
arctg\left(\frac{y}{x}\right) & (x,y)\in 1\\
arctg\left(\frac{y}{x}\right) + \pi & (x,y) \in 2\\
arctg\left(\frac{y}{x}\right)+2\pi& (x,y) \in 3
\end{cases}
\]

Hay que estudiar la continuidad en $(0,-1)$ y en $(0,1)$.

\paragraph{(0,1)}

Tomamos $\{P_n\} \rightarrow (0,1), P_n \in S_1$

Queremos probar que $\Psi(P_n) \rightarrow \Psi(0,1) = \frac{\pi}{2}$.

Ejercicio para el lector: 
Sucesiones que se acercan por la derecha o por la izquierda y comprobar que vale lo que tiene que valer.		
