% -*- root: ../GeoTopo17.tex -*-
\section{Hoja 1}
\begin{problem}[1]Responde brevemente a las siguientes preguntas:
	\ppart Si $T=T(\overline{x},\overline{y})$ y $S=S(\overline{x},\overline{y})$ son tensores, ¿lo es $T(\overline{x},\overline{y})\cdot S(\overline{x},\overline{y})$?¿y $T(\overline{x},\overline{y})+S(\overline{x},\overline{y})$?
	\ppart ¿Es $T(\overline{x},\overline{y})=\overline{x}+\overline{y}$ una aplicación bilineal?
	\ppart ¿Cuántas componentes tiene un tensor (r,s) con $V=ℝ^{m}$?
	\ppart ¿Es un tensor la aplicación que dados dos vectores de $ℝ^{3}$ les asigna la primera coordenada de su producto vectorial?
	\ppart ¿Es un tensor la aplicación que a cada par de vectores de $ℝ^{2}$ con la base canónica les asigna el área del paralelogramo que determinan?
	
	\solution
	\textit{Hecho por Jose, se aceptan correcciones}\\
	\spart Tenemos $$\appl{T}{ℝ^{n}×ℝ^{n}}{ℝ};\tab\appl{S}{ℝ^{n}×ℝ^{n}}{ℝ};\tab\text{ambos multilineales}$$\indent Es fácil observar que $T\cdot S(\overline{x},\overline{y})=T(\overline{x},\overline{y})\cdot S(\overline{x},\overline{y})$ no es multilineal , ya que $$T\cdot S(\alpha\cdot\overline{x},\overline{y})=\alpha^2\cdot T\cdot S(\overline{x},\overline{y})$$ \indent luego no es tensor.\newline
	\indent Si ahora nos fijamos en $T+S(\overline{x},\overline{y})=T(\overline{x},\overline{y})+S(\overline{x},\overline{y})$ es inmediato comprobar que es \indent un tensor 2 veces covariante:
	$$T+S(\alpha\cdot\overline{x},\overline{y})=T(\alpha\overline{x},\overline{y})+S(\alpha\overline{x},\overline{y})=\alpha\cdot(T+S(\overline{x},\overline{y}))$$
	$$T+S(\overline{x}_1+\overline{x}_2,\overline{y})=T(\overline{x}_1,\overline{y})+S(\overline{x}_1,\overline{y})+T(\overline{x}_2,\overline{y})+S(\overline{x}_2,\overline{y})=(T+S(\overline{x}_1,\overline{y}))+(T+S(\overline{x}_2,\overline{y}))$$
	\spart \indent Inmediato comprobar que no es bilineal multiplicando una variable por un escalar: $$T(\alpha\overline{x},\overline{y})=\alpha\overline{x}+\overline{y}\neq\alpha(\overline{x}+\overline{y})$$
	\newpage
	\spart $$\appl{T}{\underbrace{(ℝ^{m})^{*}×\cdots×(ℝ^{m})^{*}}_{\text{r veces}}×\underbrace{ℝ^{m}×\cdots×ℝ^{m}}_{\text{s veces}}}{ℝ}$$ \indent luego habrá $m^{r+s}$ componentes.
	
	\spart  Hay dos formas, una es considerar:
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{x_2\cdot y_3-x_3\cdot y_2}
	\end{align*}
 	y comprobar que efectivamente se cumplen las condiciones de multilinealidad. \\
 	La segunda es considerar:
 	\begin{align*}
 		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
 		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{(\overline{x}×\overline{y})\cdot\overline{e}_1=\begin{vmatrix}
 				1 & 0 &  0 \\ 
 				x_1 & x_2 & x_3 \\ 
 				y_1 & y_2 & y_3 \\ 
 		\end{vmatrix}}
 	\end{align*}
	y como vimos que el determinante es multilineal, pues ya está demostrado porque es un determinante.
	
	\spart 
		\begin{align*}
		\appl{T}{ℝ^{2}×ℝ^{2}&}{ℝ} \\
		T(\overline{x},\overline{y}) &\longmapsto{A=\text{área}}
	\end{align*}
\indent El área siempre es $\geq 0$, luego si multiplico por $\lambda=-1$ tenemos $T(\lambda\overline{x},\overline{y})\neq\lambda T(\overline{x},\overline{y})$
	
\end{problem}
\begin{problem}[2] Demuestra que, fijada una base, todo tensor dos veces covariante es de la forma $T(\overline{x},\overline{y})=\overline{x}^TA\overline{y}$ con A una matriz cuadrada.
	
	\solution SOLUCION
\end{problem}
\begin{problem}[3] Halla cuántas componentes nulas y cuántas componentes no nulas tiene el tensor determinante en $ℝ^{n}$. Estudia cuántas son positivas.
	
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\
	Sea el tensor n veces covariante en $ℝ^{n}$ y la base canónica $\base = \{ \overline{e}_1,...,\overline{e}_n \}$ de $ℝ^{n}$:
	
\begin{align*}
	\appl{D}{\underbrace{(ℝ^{n})×\cdots×(ℝ^{n})}_{\text{n veces}}&}{ℝ} \\
	D(\overline{x}_1,\cdots,\overline{x}_n) &\longmapsto{\begin{vmatrix}
							\overline{x}_1 & \cdots &  \overline{x}_n \\ 
						\end{vmatrix}}
\end{align*}
		El tensor tienen $n^n$ componentes:
		$$D_{1\space1\cdots1}=\begin{vmatrix}
		1 & 1 &\cdots & 1 \\ 
		0& 0 &\cdots & 0 \\ 
		\vdots & \vdots &\ddots & \vdots \\ 
		0& 0 &\cdots & 0 \\ 
		\end{vmatrix}$$
	En cuanto el determinante contenga a dos $\overline{e}_i$ que tengan la misma $i$ ya da 0 (por ser determinante de elementos linealmente dependientes). Luego para que no sea nulo ha de tener todas los índices distintos. Esto nos dice que el número de componentes no nulas son las permutaciones de $n$ elementos ($n!$), y las nulas serían entonces $n^n - n!$.\\
	Ahora, de las que no son nulas vamos a ver cuales son positivas. Probando descubrimos que con esta base hay dos valores posibles del determinante que son $1$ y $-1$. Las componentes positivas son aquellas que valen $1$ y esto ocurre cuando hay un número par de $\overline{e}_i$ cambiadas de posición (recordemos que todas las $i$ son ahora distintas porque estamos en el caso no nulo). \\
	La conclusión es que la cantidad de las que valen $1$ es la cantidad de permutaciones pares de n elementos, que es $\frac{n!}{2}$.
\end{problem}\newpage
\begin{problem}[4] \ppart Si multiplicamos tensorialmente unos cuantos elementos de $\mathcal{B}$ y otros de $\mathcal{B}^*$, halla cuántas componentes no nulas tiene el tensor resultante. Explica por qué todo tensor se puede escribir como combinación lineal de estos productos tensoriales y \ppart hazlo para el tensor que corresponde a la rotación de ángulo $\frac{\pi}{2}$ escogiendo $\mathcal{B}=\{\overline{e}_1+\overline{e}_2,\overline{e}_2\}$ siendo los $\overline{e}_i$ los vectores canónicos habituales.
	
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\ \spart Sean $\mathcal{B}=\{\overline{e}_1,\cdots\overline{e}_n\}$ y $\mathcal{B}^*=\{\tilde{\phi}^1,\cdots\tilde{\phi}^n\}$ donde los $\overline{e}_i$ son tensores de tipo (1,0) y los $\tilde{\phi}^i$ son tensores de tipo (0,1). Tenemos. por la propiedad de la base dual, que $$\overline{e}_i(\tilde{\phi^{j}})=\tilde{\phi}^j(\overline{e}_i)=\delta^i_j=\begin{cases}0\tab i\neq j\\1\tab i=j
	\end{cases}$$ Si cogemos ahora $m$ de esos tensores $(1,0)$ y k de esos tensores $(0,1)$ y los multiplicamos tensorialmente, por definición nos queda un tensor de tipo $(m,k)$ cuyas componentes son:	$$\overline{e}_{i_1}\otimes\cdots\otimes\overline{e}_{i_m}\otimes\tilde{\phi^{j_1}}\otimes\cdots\otimes\tilde{\phi^{j_k}}(\tilde{\phi^{s_1}},\cdots,\tilde{\phi^{s_m}},\overline{e}_{r_1},\cdots,\overline{e}_{r_k})=\overline{e}_{i_1}(\tilde{\phi^{s_1}})\cdots\overline{e}_{i_m}(\tilde{\phi^{s_m}})\cdot\tilde{\phi^{j_1}}(\overline{e}_{r_1})\cdots\tilde{\phi^{j_k}}(\overline{e}_{r_k})=$$ $$=\delta_{i_1}^{s_1}\cdots\delta_{i_m}^{s_m}\cdot\delta_{j_1}^{r_1}\cdots\delta_{j_k}^{r_k}=\begin{cases}1\tab \text{si los }\delta^A_B\text{ valen todos 1}\\0\tab \text{en otro caso}
	\end{cases}$$
	La descomposición es de la siguiente manera:
	$$T(\tilde{x}^1,\cdots,\tilde{x}^m,\overline{y}_1,\cdots,\overline{y}_k)=T(x^1_{i_1}\phi^{i_1},\cdots,x^m_{i_m}\phi^{i_m},\overline{y}_1^{j_1}\overline{e}_{j_1},\cdots,\overline{y}_k^{j_k}\overline{e}_{j_k})=x^i_{i_1}\cdots x^m_{i_m}y_1^{j_1}\cdots y_k^{j_k};$$
	$$T^{i_1\cdots i_m}_{j_1\cdots j_k}=x^1_{h_1}\delta^{h_1}_{i_1}\cdots x^m_{h_m}\delta^{h_m}_{i_m}y_1^{h_1}\delta^{j_1}_{h_1}\cdots y_k^{h_k}\delta^{j_k}_{h_k};$$
	\spart Tenemos una aplicación lineal, luego se corresponde unívocamente con un tensor $G$ de tipo $(1,1)$, y siendo $f(\overline{x})$ la aplicación lineal con matriz $A$ en dicha base aplicada a $\overline{x}$:
	\begin{align*}
	\appl{G}{(ℝ^2)^*×ℝ^2&}{ℝ} \\
	G(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}(f(\overline{x}))=\tilde{\phi}(A(\overline{x}))}
	\end{align*}
	Tenemos la base $\mathcal{B}_R=\{\overline{e}_1+\overline{e}_2,\overline{e}_2\}=\{\begin{pmatrix}1\\1\end{pmatrix},\begin{pmatrix}0\\1\end{pmatrix}\}$, buscamos su base dual y tenemos $\mathcal{B}^*_R=\{\begin{pmatrix}1&0\end{pmatrix},\begin{pmatrix}-1&1\end{pmatrix}\}$.\\
	Ahora, aplicando a los elementos de la base por el giro sabemos que $A\cdot(\overline{e}_1+\overline{e}_2)=-\overline{e}_1+\overline{e}_2$ y que $A\cdot\overline{e}_2=-\overline{e}_1$ y calculamos las componentes:$$\begin{cases}
	T(\tilde{\phi^{1}},\overline{e}_1+\overline{e}_2)=\tilde{\phi^{1}}(A\cdot(\overline{e}_1+\overline{e}_2))=-1\\
	T(\tilde{\phi^{1}},\overline{e}_2)=-1\\
	T(\tilde{\phi^{2}},\overline{e}_1+\overline{e}_2)=2\\
	T(\tilde{\phi^{2}},\overline{e}_2)=1
	\end{cases}$$\newpage
	Ahora sabemos que como es un tensor tipo $(1,1)$ se puede escribir como producto tensorial de un tensor $(1,0)$ (fijando un vector $\overline{v}_1$) y otro $(0,1)$ (fijando un elemento del dual $\tilde{\phi}^1$):
\begin{align*}
	\appl{T}{V^*&}{ℝ}&\appl{S}{V&}{ℝ}\\
	T(\tilde{\phi}) &\longmapsto{\tilde{\phi}(\overline{v}_1)}&S(\overline{v}) &\longmapsto{\tilde{\phi}^1(\overline{v})}
\end{align*}
\begin{align*}
	\appl{T\otimes S}{V^*×V&}{ℝ} \\
	T\otimes S(\tilde{\phi},\overline{v}) &\longmapsto{\tilde{\phi}(\overline{v}_1)\cdot\tilde{\phi}^1(\overline{v})}
\end{align*}
\end{problem}
\begin{problem}[5] Para $V=ℝ^3$ consideremos un tensor de tipo $(0,3)$, otro de tipo $(1,2)$ y otro de tipo $(2,1)$, cuyas componentes, digamos $\epsilon_{ijk}$, $\epsilon^i_{jk}$ y $\epsilon^{ij}_k$ en la base canónica son: 0 si $i,j,k$ no es una reordenación de $1,2,3$; 1 si  $i,j,k$ es una permutación par de $1,2,3$ y -1 si  $i,j,k$ es una permutación impar de $1,2,3$. Dados $\overline{u},\overline{v},\overline{w}\inℝ^3$ y $\overline{F}=(F^1,F^2,F^3)$, explica qué objetos matemáticos bien reconocidos representan las siguientes cantidades: $\epsilon^{ij}_k\pdv{F^k}{x^j}$,$\epsilon^i_{jk}v^jw^k$ y $\epsilon_{ijk}u^iv^jw^k$
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\ \begin{wraptable}{l}{5.5cm}
	\begin{tabular}{| c | c | c | c | c |}
		\hline
		TIPO & i & j & k & VALOR\\ \hline
		par & 1 & 2 & 3 & 1\\ \hline
		impar & 1 & 3 & 2  & -1\\ \hline
		par & 2 & 3 & 1 & 1\\ \hline
		impar & 2 & 1 & 3 & -1\\ \hline
		par & 3 & 2 & 1  & 1\\ \hline
		impar & 3 & 1 & 2 & -1\\ \hline
	\end{tabular}
\end{wraptable}
En primer lugar vemos que los tensores tienen $3^3=27$ componentes, pero de ellas solo tenemos que no son nulas las reordenaciones de $(1,2,3)$, que son $3!=6$ componentes no nulas con valores dependiendo de la permutación como se ve en la tabla. Conociendo ahora los valores de cada componente y recordando el criterio de Einstein vamos a ver caso a caso de qué pueden tratar esas expresiones:\\
\begin{itemize}
	\item $\epsilon^{ij}_k\pdv{F^k}{x^j}=(\pdv{F^3}{x^2}-\pdv{F^2}{x^3},\pdv{F^1}{x^3}-\pdv{F^3}{x^1},\pdv{F^2}{x^1}-\pdv{F^1}{x^2})=\begin{vmatrix}
	\overline{e}_1 & \overline{e}_2 &  \overline{e}_3 \\ 
	\pdv{x^1} & \pdv{x^2} & \pdv{x^3} \\ 
	F^1 & F^2 & F^3 \\ 
	\end{vmatrix}=\overline{rot}(\overline{F})$
	\item $\epsilon^i_{jk}v^jw^k=(v^2w^3-v^3w^2,v^3w^1-v^1w^3,v^1w^2-v^2w^1)=\begin{vmatrix}
	\overline{e}_1 & \overline{e}_2 &  \overline{e}_3 \\ 
	v^1 & v^2 & v^3 \\ 
	w^1 & w^2 & w^3 \\ 
	\end{vmatrix}=\overline{v}×\overline{w}$
	\item $\epsilon_{ijk}u^iv^jw^k=u^1(v^2w^3-v^3w^2)-u^2(v^1w^3-v^3w^1)+u^3(v^1w^2-v^2w^1)=\begin{vmatrix}
	u^1 & u^2 &  u^3 \\ 
	v^1 & v^2 & v^3 \\ 
	w^1 & w^2 & w^3 \\ 
	\end{vmatrix}=\overline{u}\cdot(\overline{v}×\overline{w})$
\end{itemize}
\newpage
\end{problem}
\begin{problem}[6] Demuestra que el "tensor identidad" $\appl{T_{\text{id}}}{(ℝ^2)^*×ℝ^2}{ℝ}$ que tiene componentes $\delta_j^i$ en la base canónica conserva las componentes en cualquier otra base.
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\ Estamos en $(ℝ^2)^*×ℝ^2$. Tenemos las bases canónicas $\mathcal{B}=\{\overline{e}_1,\overline{e}_2\}$, $\mathcal{B^*}=\{\tilde{\phi}^1,\tilde{\phi}^2\}$ y el tensor definido como:
		\begin{align*}
		\appl{T}{(ℝ^2)^*×ℝ^2&}{ℝ} \\
		T(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}f(\overline{x})=\tilde{\phi}A\overline{x}}
	\end{align*}
donde en este caso, como $f$ es la identidad, tenemos que $A$ es la matriz identidad y nos queda:
\begin{align*}
	\appl{\tilde{T}}{(ℝ^2)^*×ℝ^2&}{ℝ} \\
	\tilde{T}(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}\overline{x}}
\end{align*}
Es claro comprobar que las componentes de $T$ se corresponden con las $\delta_j^i$ (recordar la propiedad de la base dual). Si cambiamos de bases, digamos a otras $\tilde{\mathcal{B}}=\{\overline{v}_1,\overline{v}_2\}$, $\tilde{\mathcal{B}}^*=\{\tilde{\psi}^1,\tilde{\psi}^2\}$, estas siguen cumpliendo la propiedad $v_j\psi^i=\delta_j^i$, luego las componentes de $\tilde{T}$ se mantienen igual debido a que es el tensor identidad:
	$$\tilde{T}^i_j=\tilde{T}(\tilde{\psi}^i,\overline{v}_j)=\tilde{\psi}^i\overline{v}_j=\delta_j^i=T(\tilde{\phi}^i,\overline{e}_j)=T^i_j$$


\end{problem}
\begin{problem}[7] El "tensor de Minkowski" $\appl{M}{ℝ^2×ℝ^2}{ℝ}$ tiene componentes $-M_{1\space 1}=M_{2\space 2}=1;\space M_{1\space 2}=M_{2\space 1}=0$ en la base canónica. Encuentra un cambio de base no trivial (que no consista en cambios de signo) que deje invariantes todas las componentes.
	\solution Sabemos por el ejercicio 2 que todo tensor dos veces covariante puede escribirse como: $$T(\overline{x},\overline{y})=\overline{x}^TA\overline{y}$$ Ahora hallamos la matriz $A$ que se corresponde con este tensor.$$\begin{cases}T_{1\space 1}=\overline{e}_1^TA\overline{e}_1=\begin{pmatrix}1&0\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}1\\0\end{pmatrix}
	=a=-1\\T_{2\space 2}=\overline{e}_2^TA\overline{e}_2=\begin{pmatrix}c&d\end{pmatrix}\begin{pmatrix}0\\1\end{pmatrix}=d=1;\\b=c=0;\end{cases}$$
	Buscamos ahora $\tilde{\alpha}=\begin{pmatrix}\alpha_1\\\alpha_2\end{pmatrix}$, $\tilde{\mu}=\begin{pmatrix}\mu_1\\\mu_2\end{pmatrix}$ tales que $\mathcal{B}=\{\tilde{\alpha},\tilde{\mu}\}$ es una base y se conservan las $M_{i\space j}$, luego tenemos el sistema:
	$$\begin{cases}M(\tilde{\alpha},\tilde{\alpha})=\begin{pmatrix}\alpha_1&\alpha_2\end{pmatrix}\begin{pmatrix}-1&0\\0&1\end{pmatrix}\begin{pmatrix}\alpha_1\\\alpha_2\end{pmatrix}=-1\longrightarrow-\alpha_1^2+\alpha_2^2=-1\\
	M(\tilde{\mu},\tilde{\mu})=1\longrightarrow-\mu_1^2+\mu_2^2=1\\
	M(\tilde{\alpha},\tilde{\mu})=0\longrightarrow-\mu_1\alpha_1+\mu_2\alpha_2=0\\
	M(\tilde{\mu},\tilde{\alpha})=0\longrightarrow-\mu_1\alpha_1+\mu_2\alpha_2=0\\
	\end{cases}$$
	y ya solo hay que coger una solución (no hay una única), como por ejemplo $\mathcal{B}=\{\begin{pmatrix}2\\\sqrt{3}\end{pmatrix},\begin{pmatrix}\sqrt{3}\\2\end{pmatrix}\}$.
\end{problem}
\begin{problem}[9] El espín de un electrón es una especie de imán asociado a él y se representa con un vector unitario $a\overline{e}_1+b\overline{e}_2\in\mathbb{C}^2$ donde $\abs{a}^2$ y $\abs{b}^2$ indican las probabilidades de que al hacer un experimento notemos el polo norte arriba o abajo, respectivamente. Para dos electrones se representa como un tensor $(2,0)$ complejo $a^{i\space j}\overline{e}_i\otimes\overline{e}_j$ donde $\abs{a^{i\space j}}^2$ son las probabilidades de cada medición (por ejemplo $\abs{a^{1\space 2}}^2$ es arriba-abajo). Si $a^{i\space j}\overline{e}_i\otimes\overline{e}_j=\overline{v}\otimes\overline{w}$ los electrones son de alguna manera independientes y se dice que no están entrelazados. Prueba que esto ocurre si y sólo si $det(a^{i\space j})\neq0$. Nota: Para tres electrones el tensor es tipo $(3,0)$ y no existe una caracterización sencilla.
	
	\solution\textit{Hecho por Jose, se aceptan correcciones}\\ El espín es un vector $\overline{v}=a_1\overline{e}_1+a_2\overline{e}_2$ para $a_1,a_2\in\mathbb{C}$. Queremos demostrar:$$Independencia\iff det(a^{i\space j})\neq0$$
	$(\rightarrow)$ Cuando $T$ es un tensor de tipo $(0,2)$ es igual a $\overline{v}\otimes\overline{w}$ para dos $\overline{v}=b^i\overline{e}_i,\overline{w}=c^i\overline{e}_i$ de tipo $(1,0)$. Entonces tenemos $\overline{v}\otimes\overline{w}=b^ic^i\overline{e}_i\otimes\overline{e}_j$
	$$\begin{vmatrix}
	b^1c^1&b^1c^2\\
	b^2c^1&b^2c^2
	\end{vmatrix}=b^1b^2c^1c^2\cdot\begin{vmatrix}
	1&1\\
	1&1
	\end{vmatrix}=0\qed$$
	$(\leftarrow)$ Partimos de las hipótesis $T=a^{i\space j}\overline{e}_i\otimes\overline{e}_j;\tab\begin{vmatrix}
	a^{1\space1}&a^{1\space2}\\
	a^{2\space1}&a^{2\space2}
	\end{vmatrix};\tab\sum_{i,j=1}^{(2,2)}\abs{a^{i\space j}}^2=1$, luego $\begin{cases}
	a^{1\space 2}=\lambda a^{1\space 1};\\
	a^{2\space 2}=\lambda a^{2\space 1};\\
	\lambda=\frac{a^{1\space 2}}{a^{1\space 1}}
	\end{cases}$ Ahora vamos a escribir el tensor como un producto tensorial:
	$$T=a^{i\space j}\overline{e}_i\otimes\overline{e}_j=a^{1\space 1}\overline{e}_1\otimes(\overline{e}_1+\lambda\overline{e}_2)+a^{2\space 1}(\overline{e}_1+\lambda\overline{e}_2)=(\underbrace{a^{1\space 1}\overline{e}_1+a^{2\space 1}\overline{e}_2}_{\overline{v}})\otimes(\underbrace{\overline{e}_1+\lambda\overline{e}_2}_{\overline{w}})\qed$$ Queda para el lector comprobar que al normalizar $\overline{v}$, se normaliza automáticamente $\overline{w}$, aunque no se pide.
\end{problem}

