% -*- root: ../GeoTopo17.tex -*-
\section{Hoja 1}
\begin{problem}[1]Responde brevemente a las siguientes preguntas:
	\ppart Si $T=T(\overline{x},\overline{y})$ y $S=S(\overline{x},\overline{y})$ son tensores, ¿lo es $T(\overline{x},\overline{y})\cdot S(\overline{x},\overline{y})$?¿y $T(\overline{x},\overline{y})+S(\overline{x},\overline{y})$?
	\ppart ¿Es $T(\overline{x},\overline{y})=\overline{x}+\overline{y}$ una aplicación bilineal?
	\ppart ¿Cuántas componentes tiene un tensor (r,s) con $V=ℝ^{m}$?
	\ppart ¿Es un tensor la aplicación que dados dos vectores de $ℝ^{3}$ les asigna la primera coordenada de su producto vectorial?
	\ppart ¿Es un tensor la aplicación que a cada par de vectores de $ℝ^{2}$ con la base canónica les asigna el área del paralelogramo que determinan?
	
	\solution
	\textit{Hecho por Jose, se aceptan correcciones}\\
	\spart Tenemos $$\appl{T}{ℝ^{n}×ℝ^{n}}{ℝ};\tab\appl{S}{ℝ^{n}×ℝ^{n}}{ℝ};\tab\text{ambos multilineales}$$\indent Es fácil observar que $T\cdot S(\overline{x},\overline{y})=T(\overline{x},\overline{y})\cdot S(\overline{x},\overline{y})$ no es multilineal , ya que $$T\cdot S(\alpha\cdot\overline{x},\overline{y})=\alpha^2\cdot T\cdot S(\overline{x},\overline{y})$$ \indent luego no es tensor.\newline
	\indent Si ahora nos fijamos en $T+S(\overline{x},\overline{y})=T(\overline{x},\overline{y})+S(\overline{x},\overline{y})$ es inmediato comprobar que es \indent un tensor 2 veces covariante:
	$$T+S(\alpha\cdot\overline{x},\overline{y})=T(\alpha\overline{x},\overline{y})+S(\alpha\overline{x},\overline{y})=\alpha\cdot(T+S(\overline{x},\overline{y}))$$
	$$T+S(\overline{x}_1+\overline{x}_2,\overline{y})=T(\overline{x}_1,\overline{y})+S(\overline{x}_1,\overline{y})+T(\overline{x}_2,\overline{y})+S(\overline{x}_2,\overline{y})=(T+S(\overline{x}_1,\overline{y}))+(T+S(\overline{x}_2,\overline{y}))$$
	\spart \indent Inmediato comprobar que no es bilineal multiplicando una variable por un escalar: $$T(\alpha\overline{x},\overline{y})=\alpha\overline{x}+\overline{y}\neq\alpha(\overline{x}+\overline{y})$$
	\newpage
	\spart $$\appl{T}{\underbrace{(ℝ^{m})^{*}×\cdots×(ℝ^{m})^{*}}_{\text{r veces}}×\underbrace{ℝ^{m}×\cdots×ℝ^{m}}_{\text{s veces}}}{ℝ}$$ \indent luego habrá $m^{r+s}$ componentes.
	
	\spart  Hay dos formas, una es considerar:
	\begin{align*}
		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{x_2\cdot y_3-x_3\cdot y_2}
	\end{align*}
 	y comprobar que efectivamente se cumplen las condiciones de multilinealidad. \\
 	La segunda es considerar:
 	\begin{align*}
 		\appl{T}{ℝ^{3}×ℝ^{3}&}{ℝ} \\
 		T\left(\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix},\begin{pmatrix}y_1\\y_2\\y_3\end{pmatrix}\right) &\longmapsto{(\overline{x}×\overline{y})\cdot\overline{e}_1=\begin{vmatrix}
 				1 & 0 &  0 \\ 
 				x_1 & x_2 & x_3 \\ 
 				y_1 & y_2 & y_3 \\ 
 		\end{vmatrix}}
 	\end{align*}
	y como vimos que el determinante es multilineal, pues ya está demostrado porque es un determinante.
	
	\spart 
		\begin{align*}
		\appl{T}{ℝ^{2}×ℝ^{2}&}{ℝ} \\
		T(\overline{x},\overline{y}) &\longmapsto{A=\text{área}}
	\end{align*}
\indent El área siempre es $\geq 0$, luego si multiplico por $\lambda=-1$ tenemos $T(\lambda\overline{x},\overline{y})\neq\lambda T(\overline{x},\overline{y})$
	
\end{problem}
\begin{problem}[2] Demuestra que, fijada una base, todo tensor dos veces covariante es de la forma $T(\overline{x},\overline{y})=\overline{x}^TA\overline{y}$ con A una matriz cuadrada.
	
	\solution Tenemos una base cualquiera, luego si llamamos $\overline{e}_i$ a los vectores de dicha base tenemos que $\overline{x}$,$\overline{y}$ son de la forma $\begin{cases}\overline{x}=x^i\overline{e}_i\\\overline{y}=y^i\overline{e}_i\end{cases}$ y por tanto tenemos: $$T(\overline{x},\overline{y})=x^iy^j\underbrace{T(\overline{e}_i,\overline{e}_j)}_{a_{ij}}=x^ia_{ij}y^j=\begin{pmatrix}x^1&\cdots&x^n\end{pmatrix}\begin{pmatrix}a_{11}&\cdots&a_{1n}\\\vdots&\ddots&\vdots\\a_{n1}&\cdots&a_{nn}\end{pmatrix}\begin{pmatrix}y^1\\\vdots\\y^n\end{pmatrix}\qed$$
\end{problem}
\begin{problem}[3] Halla cuántas componentes nulas y cuántas componentes no nulas tiene el tensor determinante en $ℝ^{n}$. Estudia cuántas son positivas.
	
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\
	Sea el tensor n veces covariante en $ℝ^{n}$ y la base canónica $\base = \{ \overline{e}_1,...,\overline{e}_n \}$ de $ℝ^{n}$:
	
\begin{align*}
	\appl{D}{\underbrace{(ℝ^{n})×\cdots×(ℝ^{n})}_{\text{n veces}}&}{ℝ} \\
	D(\overline{x}_1,\cdots,\overline{x}_n) &\longmapsto{\begin{vmatrix}
							\overline{x}_1 & \cdots &  \overline{x}_n \\ 
						\end{vmatrix}}
\end{align*}
		El tensor tienen $n^n$ componentes:
		$$D_{1\space1\cdots1}=\begin{vmatrix}
		1 & 1 &\cdots & 1 \\ 
		0& 0 &\cdots & 0 \\ 
		\vdots & \vdots &\ddots & \vdots \\ 
		0& 0 &\cdots & 0 \\ 
		\end{vmatrix}$$
	En cuanto el determinante contenga a dos $\overline{e}_i$ que tengan la misma $i$ ya da 0 (por ser determinante de elementos linealmente dependientes). Luego para que no sea nulo ha de tener todas los índices distintos. Esto nos dice que el número de componentes no nulas son las permutaciones de $n$ elementos ($n!$), y las nulas serían entonces $n^n - n!$.\\
	Ahora, de las que no son nulas vamos a ver cuales son positivas. Probando descubrimos que con esta base hay dos valores posibles del determinante que son $1$ y $-1$. Las componentes positivas son aquellas que valen $1$ y esto ocurre cuando hay un número par de $\overline{e}_i$ cambiadas de posición (recordemos que todas las $i$ son ahora distintas porque estamos en el caso no nulo). \\
	La conclusión es que la cantidad de las que valen $1$ es la cantidad de permutaciones pares de n elementos, que es $\frac{n!}{2}$.
\end{problem}\newpage
\begin{problem}[4] \ppart Si multiplicamos tensorialmente unos cuantos elementos de $\mathcal{B}$ y otros de $\mathcal{B}^*$, halla cuántas componentes no nulas tiene el tensor resultante. Explica por qué todo tensor se puede escribir como combinación lineal de estos productos tensoriales y \ppart hazlo para el tensor que corresponde a la rotación de ángulo $\frac{\pi}{2}$ escogiendo $\mathcal{B}=\{\overline{e}_1+\overline{e}_2,\overline{e}_2\}$ siendo los $\overline{e}_i$ los vectores canónicos habituales.
	
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\ \spart Sean $\mathcal{B}=\{\overline{e}_1,\cdots\overline{e}_n\}$ y $\mathcal{B}^*=\{\tilde{\phi}^1,\cdots\tilde{\phi}^n\}$ donde los $\overline{e}_i$ son tensores de tipo (1,0) y los $\tilde{\phi}^i$ son tensores de tipo (0,1). Tenemos. por la propiedad de la base dual, que $$\overline{e}_i(\tilde{\phi^{j}})=\tilde{\phi}^j(\overline{e}_i)=\delta^i_j=\begin{cases}0\tab i\neq j\\1\tab i=j
	\end{cases}$$ Si cogemos ahora $m$ de esos tensores $(1,0)$ y k de esos tensores $(0,1)$ y los multiplicamos tensorialmente, por definición nos queda un tensor de tipo $(m,k)$ cuyas componentes son:	$$\overline{e}_{i_1}\otimes\cdots\otimes\overline{e}_{i_m}\otimes\tilde{\phi^{j_1}}\otimes\cdots\otimes\tilde{\phi^{j_k}}(\tilde{\phi^{s_1}},\cdots,\tilde{\phi^{s_m}},\overline{e}_{r_1},\cdots,\overline{e}_{r_k})=\overline{e}_{i_1}(\tilde{\phi^{s_1}})\cdots\overline{e}_{i_m}(\tilde{\phi^{s_m}})\cdot\tilde{\phi^{j_1}}(\overline{e}_{r_1})\cdots\tilde{\phi^{j_k}}(\overline{e}_{r_k})=$$ $$=\delta_{i_1}^{s_1}\cdots\delta_{i_m}^{s_m}\cdot\delta_{j_1}^{r_1}\cdots\delta_{j_k}^{r_k}=\begin{cases}1\tab \text{si los }\delta^A_B\text{ valen todos 1}\\0\tab \text{en otro caso}
	\end{cases}$$
	La descomposición es de la siguiente manera:
	$$T(\tilde{x}^1,\cdots,\tilde{x}^m,\overline{y}_1,\cdots,\overline{y}_k)=T(x^1_{i_1}\phi^{i_1},\cdots,x^m_{i_m}\phi^{i_m},\overline{y}_1^{j_1}\overline{e}_{j_1},\cdots,\overline{y}_k^{j_k}\overline{e}_{j_k})=x^i_{i_1}\cdots x^m_{i_m}y_1^{j_1}\cdots y_k^{j_k};$$
	$$T^{i_1\cdots i_m}_{j_1\cdots j_k}=x^1_{h_1}\delta^{h_1}_{i_1}\cdots x^m_{h_m}\delta^{h_m}_{i_m}y_1^{h_1}\delta^{j_1}_{h_1}\cdots y_k^{h_k}\delta^{j_k}_{h_k};$$
	\spart Tenemos una aplicación lineal, luego se corresponde unívocamente con un tensor $G$ de tipo $(1,1)$, y siendo $f(\overline{x})$ la aplicación lineal con matriz $A$ en dicha base aplicada a $\overline{x}$:
	\begin{align*}
	\appl{G}{(ℝ^2)^*×ℝ^2&}{ℝ} \\
	G(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}(f(\overline{x}))=\tilde{\phi}(A(\overline{x}))}
	\end{align*}
	Tenemos la base $\mathcal{B}_R=\{\overline{e}_1+\overline{e}_2,\overline{e}_2\}=\{\begin{pmatrix}1\\1\end{pmatrix},\begin{pmatrix}0\\1\end{pmatrix}\}$, buscamos su base dual y tenemos $\mathcal{B}^*_R=\{\begin{pmatrix}1&0\end{pmatrix},\begin{pmatrix}-1&1\end{pmatrix}\}$.\\
	Ahora, aplicando a los elementos de la base por el giro sabemos que $A\cdot(\overline{e}_1+\overline{e}_2)=-\overline{e}_1+\overline{e}_2$ y que $A\cdot\overline{e}_2=-\overline{e}_1$ y calculamos las componentes:$$\begin{cases}
	T(\tilde{\phi^{1}},\overline{e}_1+\overline{e}_2)=\tilde{\phi^{1}}(A\cdot(\overline{e}_1+\overline{e}_2))=-1\\
	T(\tilde{\phi^{1}},\overline{e}_2)=-1\\
	T(\tilde{\phi^{2}},\overline{e}_1+\overline{e}_2)=2\\
	T(\tilde{\phi^{2}},\overline{e}_2)=1
	\end{cases}$$\newpage
	Ahora sabemos que como es un tensor tipo $(1,1)$ se puede escribir como producto tensorial de un tensor $(1,0)$ (fijando un vector $\overline{v}_1$) y otro $(0,1)$ (fijando un elemento del dual $\tilde{\phi}^1$):
\begin{align*}
	\appl{T}{V^*&}{ℝ}&\appl{S}{V&}{ℝ}\\
	T(\tilde{\phi}) &\longmapsto{\tilde{\phi}(\overline{v}_1)}&S(\overline{v}) &\longmapsto{\tilde{\phi}^1(\overline{v})}
\end{align*}
\begin{align*}
	\appl{T\otimes S}{V^*×V&}{ℝ} \\
	T\otimes S(\tilde{\phi},\overline{v}) &\longmapsto{\tilde{\phi}(\overline{v}_1)\cdot\tilde{\phi}^1(\overline{v})}
\end{align*}
\end{problem}
\begin{problem}[5] Para $V=ℝ^3$ consideremos un tensor de tipo $(0,3)$, otro de tipo $(1,2)$ y otro de tipo $(2,1)$, cuyas componentes, digamos $\epsilon_{ijk}$, $\epsilon^i_{jk}$ y $\epsilon^{ij}_k$ en la base canónica son: 0 si $i,j,k$ no es una reordenación de $1,2,3$; 1 si  $i,j,k$ es una permutación par de $1,2,3$ y -1 si  $i,j,k$ es una permutación impar de $1,2,3$. Dados $\overline{u},\overline{v},\overline{w}\inℝ^3$ y $\overline{F}=(F^1,F^2,F^3)$, explica qué objetos matemáticos bien reconocidos representan las siguientes cantidades: $\epsilon^{ij}_k\pdv{F^k}{x^j}$,$\epsilon^i_{jk}v^jw^k$ y $\epsilon_{ijk}u^iv^jw^k$
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\ \begin{wraptable}{l}{5.5cm}
	\begin{tabular}{| c | c | c | c | c |}
		\hline
		TIPO & i & j & k & VALOR\\ \hline
		par & 1 & 2 & 3 & 1\\ \hline
		impar & 1 & 3 & 2  & -1\\ \hline
		par & 2 & 3 & 1 & 1\\ \hline
		impar & 2 & 1 & 3 & -1\\ \hline
		par & 3 & 2 & 1  & 1\\ \hline
		impar & 3 & 1 & 2 & -1\\ \hline
	\end{tabular}
\end{wraptable}
En primer lugar vemos que los tensores tienen $3^3=27$ componentes, pero de ellas solo tenemos que no son nulas las reordenaciones de $(1,2,3)$, que son $3!=6$ componentes no nulas con valores dependiendo de la permutación como se ve en la tabla. Conociendo ahora los valores de cada componente y recordando el criterio de Einstein vamos a ver caso a caso de qué pueden tratar esas expresiones:\\
\begin{itemize}
	\item $\epsilon^{ij}_k\pdv{F^k}{x^j}=(\pdv{F^3}{x^2}-\pdv{F^2}{x^3},\pdv{F^1}{x^3}-\pdv{F^3}{x^1},\pdv{F^2}{x^1}-\pdv{F^1}{x^2})=\begin{vmatrix}
	\overline{e}_1 & \overline{e}_2 &  \overline{e}_3 \\ 
	\pdv{x^1} & \pdv{x^2} & \pdv{x^3} \\ 
	F^1 & F^2 & F^3 \\ 
	\end{vmatrix}=\overline{rot}(\overline{F})$
	\item $\epsilon^i_{jk}v^jw^k=(v^2w^3-v^3w^2,v^3w^1-v^1w^3,v^1w^2-v^2w^1)=\begin{vmatrix}
	\overline{e}_1 & \overline{e}_2 &  \overline{e}_3 \\ 
	v^1 & v^2 & v^3 \\ 
	w^1 & w^2 & w^3 \\ 
	\end{vmatrix}=\overline{v}×\overline{w}$
	\item $\epsilon_{ijk}u^iv^jw^k=u^1(v^2w^3-v^3w^2)-u^2(v^1w^3-v^3w^1)+u^3(v^1w^2-v^2w^1)=\begin{vmatrix}
	u^1 & u^2 &  u^3 \\ 
	v^1 & v^2 & v^3 \\ 
	w^1 & w^2 & w^3 \\ 
	\end{vmatrix}=\overline{u}\cdot(\overline{v}×\overline{w})$
\end{itemize}
\newpage
\end{problem}
\begin{problem}[6] Demuestra que el "tensor identidad" $\appl{T_{\text{id}}}{(ℝ^2)^*×ℝ^2}{ℝ}$ que tiene componentes $\delta_j^i$ en la base canónica conserva las componentes en cualquier otra base.
	\solution \textit{Hecho por Jose, se aceptan correcciones}\\ Estamos en $(ℝ^2)^*×ℝ^2$. Tenemos las bases canónicas $\mathcal{B}=\{\overline{e}_1,\overline{e}_2\}$, $\mathcal{B^*}=\{\tilde{\phi}^1,\tilde{\phi}^2\}$ y el tensor definido como:
		\begin{align*}
		\appl{T}{(ℝ^2)^*×ℝ^2&}{ℝ} \\
		T(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}f(\overline{x})=\tilde{\phi}A\overline{x}}
	\end{align*}
donde en este caso, como $f$ es la identidad, tenemos que $A$ es la matriz identidad y nos queda:
\begin{align*}
	\appl{T}{(ℝ^2)^*×ℝ^2&}{ℝ} \\
	T(\tilde{\phi},\overline{x}) &\longmapsto{\tilde{\phi}\overline{x}}
\end{align*}
Es claro comprobar que las componentes de $T$ se corresponden con las $\delta_j^i$ (recordar la propiedad de la base dual). Si cambiamos de bases, digamos a otras $\tilde{\mathcal{B}}=\{\overline{v}_1,\overline{v}_2\}$, $\tilde{\mathcal{B}}^*=\{\tilde{\psi}^1,\tilde{\psi}^2\}$, estas siguen cumpliendo la propiedad $v_j\psi^i=\delta_j^i$, luego las componentes del "nuevo tensor" $\tilde{T}$ se mantienen igual debido a que es el tensor identidad:
	$$\tilde{T}^i_j=\tilde{T}(\tilde{\psi}^i,\overline{v}_j)=\tilde{\psi}^i\overline{v}_j=\delta_j^i=T(\tilde{\phi}^i,\overline{e}_j)=T^i_j$$


\end{problem}
\begin{problem}[7] El "tensor de Minkowski" $\appl{M}{ℝ^2×ℝ^2}{ℝ}$ tiene componentes $-M_{1\space 1}=M_{2\space 2}=1;\space M_{1\space 2}=M_{2\space 1}=0$ en la base canónica. Encuentra un cambio de base no trivial (que no consista en cambios de signo) que deje invariantes todas las componentes.
	\solution Sabemos por el ejercicio 2 que todo tensor dos veces covariante puede escribirse como: $$T(\overline{x},\overline{y})=\overline{x}^TA\overline{y}$$ Ahora hallamos la matriz $A$ que se corresponde con este tensor.$$\begin{cases}T_{1\space 1}=\overline{e}_1^TA\overline{e}_1=\begin{pmatrix}1&0\end{pmatrix}\begin{pmatrix}a&b\\c&d\end{pmatrix}\begin{pmatrix}1\\0\end{pmatrix}
	=a=-1\\T_{2\space 2}=\overline{e}_2^TA\overline{e}_2=\begin{pmatrix}c&d\end{pmatrix}\begin{pmatrix}0\\1\end{pmatrix}=d=1;\\b=c=0;\end{cases}$$
	Buscamos ahora $\tilde{\alpha}=\begin{pmatrix}\alpha_1\\\alpha_2\end{pmatrix}$, $\tilde{\mu}=\begin{pmatrix}\mu_1\\\mu_2\end{pmatrix}$ tales que $\mathcal{B}=\{\tilde{\alpha},\tilde{\mu}\}$ es una base y se conservan las $M_{i\space j}$, luego tenemos el sistema:
	$$\begin{cases}M(\tilde{\alpha},\tilde{\alpha})=\begin{pmatrix}\alpha_1&\alpha_2\end{pmatrix}\begin{pmatrix}-1&0\\0&1\end{pmatrix}\begin{pmatrix}\alpha_1\\\alpha_2\end{pmatrix}=-1\longrightarrow-\alpha_1^2+\alpha_2^2=-1\\
	M(\tilde{\mu},\tilde{\mu})=1\longrightarrow-\mu_1^2+\mu_2^2=1\\
	M(\tilde{\alpha},\tilde{\mu})=0\longrightarrow-\mu_1\alpha_1+\mu_2\alpha_2=0\\
	M(\tilde{\mu},\tilde{\alpha})=0\longrightarrow-\mu_1\alpha_1+\mu_2\alpha_2=0\\
	\end{cases}$$
	y ya solo hay que coger una solución (no hay una única), como por ejemplo $\mathcal{B}=\{\begin{pmatrix}2\\\sqrt{3}\end{pmatrix},\begin{pmatrix}\sqrt{3}\\2\end{pmatrix}\}$.
\end{problem}
\begin{problem}[9] El espín de un electrón es una especie de imán asociado a él y se representa con un vector unitario $a\overline{e}_1+b\overline{e}_2\in\mathbb{C}^2$ donde $\abs{a}^2$ y $\abs{b}^2$ indican las probabilidades de que al hacer un experimento notemos el polo norte arriba o abajo, respectivamente. Para dos electrones se representa como un tensor $(2,0)$ complejo $a^{i\space j}\overline{e}_i\otimes\overline{e}_j$ donde $\abs{a^{i\space j}}^2$ son las probabilidades de cada medición (por ejemplo $\abs{a^{1\space 2}}^2$ es arriba-abajo). Si $a^{i\space j}\overline{e}_i\otimes\overline{e}_j=\overline{v}\otimes\overline{w}$ los electrones son de alguna manera independientes y se dice que no están entrelazados. Prueba que esto ocurre si y sólo si $det(a^{i\space j})\neq0$. Nota: Para tres electrones el tensor es tipo $(3,0)$ y no existe una caracterización sencilla.
	
	\solution\textit{Hecho por Jose, se aceptan correcciones}\\ El espín es un vector $\overline{v}=a_1\overline{e}_1+a_2\overline{e}_2$ para $a_1,a_2\in\mathbb{C}$. Queremos demostrar:$$Independencia\iff det(a^{i\space j})\neq0$$
	$(\rightarrow)$ Cuando $T$ es un tensor de tipo $(0,2)$ es igual a $\overline{v}\otimes\overline{w}$ para dos $\overline{v}=b^i\overline{e}_i,\overline{w}=c^i\overline{e}_i$ de tipo $(1,0)$. Entonces tenemos $\overline{v}\otimes\overline{w}=b^ic^i\overline{e}_i\otimes\overline{e}_j$
	$$\begin{vmatrix}
	b^1c^1&b^1c^2\\
	b^2c^1&b^2c^2
	\end{vmatrix}=b^1b^2c^1c^2\cdot\begin{vmatrix}
	1&1\\
	1&1
	\end{vmatrix}=0\qed$$
	$(\leftarrow)$ Partimos de las hipótesis $T=a^{i\space j}\overline{e}_i\otimes\overline{e}_j;\tab\begin{vmatrix}
	a^{1\space1}&a^{1\space2}\\
	a^{2\space1}&a^{2\space2}
	\end{vmatrix};\tab\sum_{i,j=1}^{(2,2)}\abs{a^{i\space j}}^2=1$, luego $\begin{cases}
	a^{1\space 2}=\lambda a^{1\space 1};\\
	a^{2\space 2}=\lambda a^{2\space 1};\\
	\lambda=\frac{a^{1\space 2}}{a^{1\space 1}}
	\end{cases}$ Ahora vamos a escribir el tensor como un producto tensorial:
	$$T=a^{i\space j}\overline{e}_i\otimes\overline{e}_j=a^{1\space 1}\overline{e}_1\otimes(\overline{e}_1+\lambda\overline{e}_2)+a^{2\space 1}(\overline{e}_1+\lambda\overline{e}_2)=(\underbrace{a^{1\space 1}\overline{e}_1+a^{2\space 1}\overline{e}_2}_{\overline{v}})\otimes(\underbrace{\overline{e}_1+\lambda\overline{e}_2}_{\overline{w}})\qed$$ Queda para el lector comprobar que al normalizar $\overline{v}$, se normaliza automáticamente $\overline{w}$, aunque no se pide.
\end{problem}
\newpage
\begin{problem}[10] Dado un sólido $V\subset ℝ^3$ de densidad $\rho$ se define su tensor de inercia $I$ como un tensor $(0,2)$ cuyas componentes son $I_{ij}=\rho\int_{V}(\delta_{ij}(x^2_1+x^2_2+x^2_3)-x_ix_j)$ donde $x_1,x_2,x_3$ son las variables $x,y,z$. En física, se prueba que el trabajo que cuesta girar $V$ alrededor del origen es $\frac{1}{2}I(\overline{\omega},\overline{\omega})$, con $\overline{\omega}$ la velocidad angular: el vector que tiene como dirección la del eje de giro y como longitud el número de radianes por segundo. Considera el disco $x^2+y^2\leq1$ con un grosor muy pequeño, ¿qué es más fácil, girarlo por el eje X o girarlo por el eje Z?
	
	\solution\textit{Hecho por Jose, se aceptan correcciones}\\ 
\begin{wrapfigure}{l}{0.22\textwidth}
\begin{tikzpicture}[tdplot_rotated_coords,
scale=1,
length/.style={<->,thick,line cap=round},
axis/.style={->,c3,ultra thick,line cap=round},
textlabel/.style={fill opacity=.7,text opacity=1,fill=white,rounded corners}]
\draw[axis] (0,0,0) -- (2,0,0) node[textlabel,anchor=east]{$x$};
\draw[axis] (0,0,0) -- (0,2,0) node[textlabel,anchor=south]{$z$};
\draw[axis] (0,0,0) -- (0,0,2) node[textlabel,anchor=west]{$y$};
\begin{scope}[canvas is zx plane at y=0]
\draw[yellow,fill=yellow, opacity=0.2] (0,0) circle (1cm);
\end{scope}
\draw[->, thick, purple] (0,0,0) -- (1.2,0,0) node [midway,above] {$\overline{\omega}_A$};
\draw[->, thick, purple] (0,0,0) -- (0,1.2,0) node [midway,left] {$\overline{\omega}_B$};
\end{tikzpicture}
\end{wrapfigure}
\indent Fijando nuestros objetivos, queremos hallar $\frac{1}{2}I(\overline{\omega}_A,\overline{\omega}_A)$, $\frac{1}{2}I(\overline{\omega}_B,\overline{\omega}_B)$, que son los trabajos respectivos que cuesta girar $V$ con respecto el eje $X$ y con respecto al eje $Z$, y el que salga menor será el más "fácil". El valor de la velocidad angular nos da igual, es una constante que multiplica al vector y lo que nos interesa es su dirección. Si llamamos a esta constante $\omega$ (escalar, sin barra), tenemos: $$\begin{cases}\overline{\omega}_A=\omega\begin{pmatrix}1&0&0\end{pmatrix}^T=\omega\overline{u}_x\\\overline{\omega}_B=\omega\begin{pmatrix}0&0&1\end{pmatrix}^T=\omega\overline{u}_z\end{cases}$$
Como tenemos un tensor $(0,2)$, sabemos que se aplica a los vectores de esta forma:
\begin{align*}
\appl{I}{ℝ^2×ℝ^2&}{ℝ} \\
I(\overline{x},\overline{y}) &\longmapsto{\overline{x}^TM_I\overline{y}}
\end{align*}
donde  $M_I$ es la matriz de componentes del tensor, cuya expresión se nos indica en el enunciado. Si seguimos el convenio de Einstein, escribimos la matriz de la siguiente manera: $$M_I=(I_{ij})=\begin{pmatrix}
\rho\int_{V}(y^2+z^2)&\rho\int_{V}-yx&\rho\int_{V}-xz\\
\rho\int_{V}-xy&\rho\int_{V}(x^2+z^2)&\rho\int_{V}-yz\\
\rho\int_{V}-xz&\rho\int_{V}-yz&\rho\int_{V}(x^2+y^2)\\
\end{pmatrix}$$
Ya tenemos todo lo que necesitamos así que procedemos (las constantes como $\frac{1}{2},\rho,\omega^2...$ se irán acumulando en el producto de constantes $K$):
\begin{itemize}
	\item$\frac{1}{2}I(\overline{\omega}_A,\overline{\omega}_A)=K\cdot I(\overline{u}_x,\overline{u}_x)=K\cdot\overline{u}_x^TM_I\overline{u}_x=K\int_{V}(y^2+z^2)dxdydz\xrightarrow{z=0\text{ en }V}\frac{K\pi}{4}$
	\item$\frac{1}{2}I(\overline{\omega}_B,\overline{\omega}_B)=K\cdot I(\overline{u}_z,\overline{u}_z)=K\cdot\overline{u}_z^TM_I\overline{u}_z=K\int_{V}(x^2+y^2)dxdydz=\frac{K\pi}{2}$
\end{itemize}
Luego concluyendo, es más fácil girar respecto al eje X, y esto tiene sentido si nos fijamos, ya que si giramos con respecto al eje Z sólo queda una partícula del sólido sin trasladarse con el giro (la partícula donde intersecan el eje y el disco, que es el origen), mientras que de la otra manera nos evitamos trasladar todo un segmento de partículas (las que se corresponden con la intersección del disco con el eje X), luego nos costará menos este último giro.
\end{problem}
\newpage
\begin{problem}[14] Consideramos en $ℝ^2-{(0,0)}$ las coordenadas cartesianas y las coordenadas polares. \ppart Expresa $\pdv{x}$ y $\pdv{y}$ en términos de $\pdv{r}$ y $\pdv{\theta}$. \ppart Deduce de las relaciones $dx(\pdv{x})=1$, $dx(\pdv{y})=0$ fórmulas para $dx(\pdv{r})$ y $dx(\pdv{\theta})$ \ppart y de ahí una expresión para $dx$ en términos de $dr$, $d\theta$.\ppart¿Se te ocurre como podías haber llegado al resultado final sin hacer apenas cálculos?
	
	\solution\textit{Hecho por Jose, se aceptan correcciones}\\ En primer lugar escribimos las coordenadas que tenemos:
	$$\begin{cases}x=rcos(\theta)\\y=rsen(\theta)\end{cases}\longmapsto\begin{cases}r=\sqrt{x^2+y^2}\\\theta=arctan(\frac{y}{x})\end{cases}$$
	\spart Vamos a escribir $\pdv{y}$ en función de los términos que se pide mediante la regla de la cadena:
	$$\pdv{y}=\pdv{r}{y}\pdv{r}+\pdv{\theta}{y}\pdv{\theta}=\frac{y}{\sqrt{x^2+y^2}}\pdv{r}+\frac{1}{1+\frac{y^2}{x^2}}\frac{1}{x}\pdv{\theta}=sen(\theta)\pdv{r}+\frac{cos(\theta)}{r}\pdv{\theta};$$
	Análogamente:
	$$\pdv{x}=cos(\theta)\pdv{r}-\frac{sen(\theta)}{r}\pdv{\theta};$$
	\spart Partiendo de la definición de base dual (esas son las relaciones de las que habla el enunciado) tenemos:
	$$\begin{cases}dx(\pdv{x})=1\\dx(\pdv{y})=0\end{cases}\longmapsto\begin{cases}1=cos(\theta)dx(\pdv{r})-\frac{sen(\theta)}{r}dx(\pdv{\theta})\\0=sen(\theta)dx(\pdv{r})+\frac{cos(\theta)}{r}dx(\pdv{\theta})\end{cases}\longmapsto\begin{cases}dx(\pdv{r})=cos(\theta)\\dx(\pdv{\theta})=-rsen(\theta)\end{cases}$$
	\spart Por el apartado anterior y por la dualidad $\begin{cases}dr(\pdv{r})=1\\dr(\pdv{\theta})=0\\\vdots\end{cases}$ tenemos: $$dx=Adr+Bd\theta=\cdots=cos(\theta)dr-rsen(\theta)d\theta$$
	\spart Si hubiésemos considerado la aplicación tangente de la coordenada x:
	$$x=rcos(\theta)\xrightarrow{df}dx=cos(\theta)dr-rsen(\theta)d\theta$$
\end{problem}
\section{Hoja 2}
\begin{problem}[10] Demuestra que 
	$r=(\cos\theta+\sen\theta)^{-1}$ con $\theta=\arctan \frac{t}{\sqrt{2}-t}$ define una geodésica en$ℝ^2$ con la métrica en polares $dr^2+r^2d\theta^2$.
	{\sf Indicación:} No es necesario siquiera escribir la ecuación de las geodésicas, la métrica es una bien conocida de $ℝ^2$. 
	
	\solution\textit{Hecho por Fernando Chamizo, ¿se aceptan correcciones?}\\ Se tiene $r\cos\theta+r\sen\theta=1$ y $\tan\theta= {t}/({\sqrt{2}-t})$ que en cartesianas se escribe como $x+y=1$, ${y}/x={t}/({\sqrt{2}-t})$. Despejando, $\big(x(t),y(t)\big)=\big(1-t/\sqrt{2},t/\sqrt{2}\big)$ que es  una recta en $ℝ^2$ parametrizada por longitud de arco, así pues una geodésica con la métrica usual y, como vimos en clase, $dr^2+r^2d\theta^2$ es la métrica usual en la carta en polares. 
\end{problem}
\begin{problem}[11] Con lo que has aprendido este curso, explica por qué la generatriz de una superficie de revolución (parametrizada por lonngitud de arco) es una geodésica.
	
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ Sea la generatriz $(r(u),0,h(u))$, por tanto la superficie es: $$\Phi(u,v)=(r(u)cos(v),r(u)sen(v),h(u))$$ Viendo los coeficientes de la métrica con la primera forma fundamental llegamos a que: $$\begin{cases}g_{11}=<\Phi_u,\Phi_u>=1;\tab\text{(por ser parametrización por longitud de arco)}\\g_{12}=g_{21}=<\Phi_u,\Phi_v>=0;\\g_{22}=<\Phi_v,\Phi_v>=(r(u))^2;\end{cases}$$ Eligiendo como carta $\phi=\Phi^{-1}(x^1,x^2)$ se tiene para cada generatriz que $x^2=cte$. Por tanto, mirando las ecuaciones de Euler-Lagrange (\refeq{eq:Euler-Lagrange}) tenemos el lagrangiano $L=((x^1)')^2+r^2(x^1)((x^2)')^2$ y que:
	$$\begin{cases}\dv{t}(2(x^1)')=2r(x^1)r'(x^1)((x^2)')^2\\\dv{t}(r(x^1)2(x^2)')=0\end{cases}$$ Aplicando $x^2=cte$ tenemos que $(x^1)'=cte\longrightarrow x^1=Ct+D$. La D la podemos tomar como 0 porque nos da igual en que punto comenzamos, y como está parametrizada por longutid de arco tomamos que $C=1\longrightarrow x^1=t\longrightarrow\phi=(t,0)\longrightarrow\Phi(t,0)=(r(t),0,h(t))$, que es la generatriz.\qed
\end{problem}

\begin{problem}[12] Calcula los símbolos de Christoffel
	para la métrica $dr^2+4\senh^2r\; d\theta^2
	$ y halla alguna de 
	las geodésicas.
	
	
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ Tras hacer el primer apartado queda $$\ddot{\theta}+\frac{2cosh(r)}{senh(r)}\dot{r}\dot{\theta}=0.$$Ahora si elegimos $\theta(t)=cte\longrightarrow r(t)+At=B$ y este caso cuando podemos resolver con $\dot{theta}=0$ recibe el nombre de métrica semigeodésica
	
\end{problem}
\begin{problem}[13] Calcula los símbolos de Christoffel y las fórmulas para las geodésicas de $ℝ^2$ cuando se le dota con la
	métrica
	$
	du^2+4vdudv+8v^2dv^2.
	$
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ La métrica que se considera es $du^2+4vdvdu+8vdv^2$. Tenemos entonces que el Lagrangiano es $L=\dot{u}^2+4v\dot{u}\dot{v}+8v^2\dot{v}^2$y por tanto: $$\pdv{L}{\dot{u}}=2\dot{u}+4v\dot{v}$$ $$\pdv{L}{u}=0$$ $$0=2\ddot{u}+4\dot{v}^2+4v\ddot{v}$$ $$\vdots$$ $$0=\ddot{u}+4\dot{v}^2+4v\ddot{v}$$ No se leen directamente los símbolos de Christoffel $\Gamma^k_{ij}$ . Para poder verlos tenemos que despejar en una de ellas $\ddot{v}$ o $\ddot{u}$ y despejar en la otra. En este caso, nuestras ecuaciones de Euler-Lagrange son equivalentes al sistema: $$\begin{cases}
	\ddot{u}=0\\
	\ddot{v}+\frac{\dot{v}^2}{v}=0\\
	\end{cases}$$ Dividimos por $\dot{v}$ para resolver la segunda ecuación y nos queda $$\frac{\ddot{v}}{\dot{v}}+\frac{\dot{v}}{v}=0$$ Integramos y tenemos que $$\begin{cases}
	\dot{v}v=cte\longrightarrow v^2=At+B\longrightarrow v=\pm\sqrt{At+B}\\u=Ct+D\\
	\end{cases}$$
\end{problem}
\begin{problem}[14] En $ℝ^+×ℝ^+$ tomamos la métrica $(x+y)dx^2+(x+y)dy^2$: \ppart Demuestra que a lo largo de cualquier geodésica, $(\dot{x}-\dot{y})/(\dot{x}^2+\dot{y}^2)$ es constante.\ppart Prueba que es posible parametrizar la (semi)recta $\{y=x\}$ de forma que sea una geodésica y que esto es imposible para $\{y=2x\}$
	
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ \spart Queremos ver que $\frac{\dot{x}-\dot{y}}{\dot{x}^2+\dot{y}^2}$ es constante a lo largo de las geodésicas. Por ser longitud de arco tenemos que $(x+y)(\dot{x}^2+\dot{y}^2)=cte$ y ahora despejando $(\dot{x}^2+\dot{y}^2)$ y sustituyendo en la primera expresión tenemos que $(\dot{x}-\dot{y})(x+y)=cte$. Si tomamos derivadas en ambos extremos llegamos a que $(\ddot{x}-\ddot{y})(x+y)+(x'-y')(x'+y')=0\longrightarrow-(\ddot{x}-\ddot{y})=\frac{\dot{x}^2-\dot{y}^2}{x+y}(\textbf{*})$\\
	\indent Ahora, por las ecuaciones de Euler-Lagrange (\refeq{eq:Euler-Lagrange}) tenemos que: $$2\ddot{x}(x+y)+2\dot{x}+ 2\dot{x}(\dot{x}+\dot{y})=\dot{x}^2+\dot{y}^2$$ y por simetría sería igual en $y$. Por tanto: $$\ddot{x}+\frac{\dot{x}^2+2\dot{x}\dot{y}-\dot{y}^2}{2(x+y)}=0$$ y los símbolos de Christoffel son: $$\begin{cases}\Gamma^x=\begin{pmatrix}1&1\\1&-1\end{pmatrix}\frac{1}{2(x+y)}\\\Gamma^y=\begin{pmatrix}-1&1\\1&1\end{pmatrix}\frac{1}{2(x+y)}
	\end{cases}$$ Por útimo, haciendo la operación (\textbf{*}) llegamos a lo buscado.\\
	\spart Sea $\{y=x\}$ por tanto, necesitamos que $(x+y)(\dot{x}^2+\dot{y}^2)=1$. Parametrizamos de tal modo que $\phi(t)=(x(t),x(t))$ y la métrica nos queda $4x\dot{x}^2=1$. Resolvemos la EDO y queda $$4xdx^2=dt^2\longrightarrow2\sqrt{x}dx=dt\longrightarrow2\frac{2}{3}x^{\frac{3}{2}}=t\longrightarrow x(t)=\left(\frac{3t}{4}\right)^{\frac{2}{3}}$$ Si aplicamos las ecuaciones de Euler-Lagrange calculadas antes vemos que efectivamente es una geodésica.\qed
\end{problem}
\begin{problem}[16] Se llama \textbf{semiplano de Poincaré} a $\mathbb{H}=\{z\in\mathbb{C}\;:\; \text{Im}\; z>0\}$ dotado de la métrica $y^{-2}dx^2+y^{-2}dy^2$ donde $(x,y)$ es la carta dada por la parte real y la parte imaginaria de $z$.\ppart Calcula los símbolos de Christoffel.\ppart Prueba que las rectas verticales $x=x_0$ convenientemente parametrizadas son geodésicas.\ppart Demuestra que la transformación $z\mapsto -1/z$ deja invariante la métrica. 
	
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ \spart \spart \spart Vamos a ver dos formas de hacer el ejercicio. La primera:\\ $$\frac{-1}{z}=\frac{-1}{x+iy}=\frac{-x}{x^2+y^2}+\frac{iy}{x^2+y^2}$$ y la nueva métrica sería: $$\left(\frac{y}{x^2+y^2}\right)^{-2}\left(\left(\frac{(x^2-y^2)dx-2yxdy}{(x^2+y^2)^2}\right)^2+\text{ lo mismo cambiando x por y}\right)=$$
	$$=y^{-2}(x^2+y^2)^{-2}\left([(x^2-y^2)+4y^2x^2]dx^2+[(x^2-y^2)^2+4y^2x^2]dy^2\right)=y^{-2}(dx^2+dy^2)$$\qed\\
	La segunda:\\
	Sabiendo que $Im\left(\frac{-1}{z}\right)=\frac{Im(z)}{\abs{z}^2}$; reescribiendo la métrica con notación compleja tenemos:$$y^{-2}(dx^2+dy^2)=(Im(z))^{-2}dzd\tilde{z}$$Haciendo la transformación y usando lo primero que hemos apuntado llegamos a que: $$(Im(\frac{-1}{z}))^{-2}d\left(\frac{-1}{z}\right)d\left(\frac{-1}{\tilde{z}}\right)=\left(\frac{Im(z)}{\abs{z}^2}\right)^{-2}\frac{dz}{z^2}\frac{d\tilde{z}}{\tilde{z}^2}$$\qed
	
\end{problem}
\section{Hoja 3}
{\footnotesize En esta hoja la conexión es siempre la de Levi-Civita y se abrevia $\frac{\partial}{\partial x^i}$ por $\partial_i$ y  $\nabla_{\partial_j}$ por $\nabla_{j}$.}
\begin{problem}[1] Recuerda (o aprende) que el \emph{corchete de Lie}
	de dos campos de vectores $X=X^i\partial_i$ e $Y=Y^i\partial_i$, es el campo vectores
	$
	[X,Y]= 
	X(Y^j)\partial_j-Y(X^j)\partial_j$.
	Muestra con un cálculo que $[X,Y]= X^i\nabla_iY-Y^i\nabla_iX$.
	
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ $$[X,Y]=X^i\nabla_iY-Y^i\nabla_iX=X^i(\partial_iY^j+\Gamma^j_{ik}Y^k)\partial_j-Y^i(\partial_iX^j+\Gamma^j_{ik}X^k)\partial_j=X^i\partial_iY^j\partial_j-Y^i\partial_iX^j\partial_j$$
	
\end{problem}
\begin{problem}[3] Halla todas las métricas en  $ℝ$ para las que $\Gamma_{11}^1=1$ y caracteriza todos los campos de vectores y todas las 1-formas con derivada covariante nula. 
	
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ Sea $G=a(x)dx^2\longrightarrow L=a(x)\dot{x}^2\longrightarrow2\ddot{x}a+2\dot{x}^2\dot{a}=\dot{a}\dot{x}^2\longrightarrow\ddot{x}+\frac{\dot{a}}{2a}\dot{x}^2=0\longrightarrow\Gamma^1_{11}=\frac{\dot{a}}{2a}=1\longrightarrow a(x)=Ke^{2x}$. Un campo tiene la forma $V =V(x)\partial_x$ y las 1-formas $w = f (x)dx$. Entonces, teniendo en cuenta que sólo hay una dirección: $$\nabla_1V^1=\partial_1V^1+\Gamma^1_11V^1,\nabla_1\omega_1=\partial_1\omega_1-\Gamma^1_{11}\omega_1\longrightarrow$$ $$\nabla_1V^1=V'+V=0\longrightarrow V(x)=Ke^{-x}$$ $$\nabla_1\omega_1=f'-f=0\longrightarrow f(x)=Ke^{x}$$
	
\end{problem}
\begin{problem}[5]Consideremos el semiplano de Poincaré con su métrica $y^{-2}(dx^2+dy^2)$. Por un ejercicio anterior, los únicos símbolos de Christoffel no nulos son $\Gamma_{12}^1=\Gamma_{21}^1=\Gamma_{22}^2=
	-\Gamma_{11}^2=-y^{-1}$. Calcula la derivada covariante de $V=f(y)\partial_1$ y halla $f\ne 0$ de modo que  sea un transporte paralelo cuando se restringe a la curva $c(t)=(0,1+t)$.
	¿Sabrías deducir que $h(x,y)\big(\partial_1+y\partial_2)$ con $h\ne 0$ no es un transporte paralelo a lo largo de $c$ sin repetir las cuentas? 
	\textbf{Indicación}: 
	Recuerda que $G(V,V)$ y $G(V,W)$ son constantes por transportes paralelos. 
	
	\solution\textit{Hecho en clase, se aceptan correcciones}\\ Tenemos la métrica $G=y^{-2}(dx^2+dy^2)$ con $\Gamma^1_{12}=\Gamma^1_{21}=\Gamma^2_{22}=-\Gamma^2_{11}=-y^{-1}$. Sea $V=f(y)\partial_1$. Entonces: $$\nabla_kV^1=\partial_kV^1+\Gamma^1_{kl}V^l\longrightarrow$$Para $k=1$:$$\nabla_1V^1=\partial_1f(y)+\Gamma^1_{11}f(y)=0$$Para $k=2$:$$\nabla_2V^1=\partial_2f(y)+\Gamma^1_{21}f(y)=f'-\frac{f}{y}$$ Veamos ahora $\nabla_kV^2$, entonces si $k=1$: $$\nabla_1V^2=0+\Gamma^2_{11}V^1=\frac{f}{y}$$ Para $k=2$: $$\nabla_2V^2=0+\Gamma^2_{22}V^2=0$$ Por tanto, $\dv{V}{t}=\nabla_kV\dv{x^k}{t}=\nabla_2V=(f'-y^{-1}f)=0$. Si ahora resolvemos la EDO tenemos $f(y)=ky$. Si $W=h(\partial_1+y\partial_2)$ fuera un transporte paralelo, entonces $G(W,W)=cte$.Si $V=ky\partial_1$,como sabemos que es transporte paralelo tenemos que $G(V,W)=cte$. Entonces: $$cte=G(W,W)=h^2y^{-2}(1+y^2)=h^2(t+1)^{-2}(1+(t+1)^2)$$

	
\end{problem}
\begin{problem}[6]Comprueba que si $V$ y $W$ son campos de vectores
	$\nabla(V\otimes W)=(\nabla V)\otimes W+V\otimes
	\nabla W$.
	
	\solution\textit{Hecho por Fernando}\\ Las componentes de $T = V\otimes W$ son $T^{ij}=V^iW^j$. Utilizando la fórmula para la derivada covariante de un tensor de tipo $(2,0)$:
	\begin{eqnarray*}
		\nabla_k T^{ij}
		&=&
		\partial_k(V^iW^j)
		+
		\Gamma_{kl}^i V^lW^j
		+
		\Gamma_{kl}^j V^iW^l
		\\
		&=&
		\Big( \partial_k V^i + \Gamma_{kl}^i V^l \Big)W^j
		+
		V^i
		\Big( \partial_k W^j + \Gamma_{kl}^j W^l \Big)
		\\
		&=&
		\Big(\nabla_k V^i\big)W^j
		+
		V^i\Big(\nabla_k W^j\big)
	\end{eqnarray*}
	y la utlima expresión son las componentes de $(\nabla V)\otimes W+V\otimes
	\nabla W$.
\qed	
\end{problem}
\begin{problem}[7]Si $C$ es la matriz $(\nabla_j V^i)$ con $V$ un campo en $\mathbb{R}^2$ (con
	la métrica usual) cuando se usan coordenadas cartesianas y $P$ es
	la matriz correspondiente cuando se emplean coordenadas polares,
	demuestra que $P=J^{-1}CJ$ donde $J$ es la matriz jacobiana de $x=x(r,\theta)$,  $y=y(r,\theta)$.
	
	\solution\textit{Hecho por Fernando}\\ Llamemos $c_j^i$ y $p^i_j$ a los elementos de $C$ y $P$, y escribamos $(x^1,x^2)=(x,y)$, $(z^1,z^2)=(r,\theta)$. Por la tensorialidad de $\nabla V$, al cambiar de coordenadas (carta) se tiene 
	\[
	p^i_j
	=
	\frac{\partial z^i}{\partial x^k}
	\frac{\partial x^l}{\partial z^j}
	c_l^k
	=
	\frac{\partial z^i}{\partial x^k}
	c_l^k
	\frac{\partial x^l}{\partial z^j}.
	\]
	Como ${\partial x^l}/{\partial z^j}$ son los elementos de la matriz jacobiana y ${\partial z^i}/{\partial x^k}$ los de su inversa, basta recordar que el producto de matrices $ABC$ se podía escribir en componentes como $a^i_kb^k_lc^l_j$. \qed
	
	
\end{problem}
\begin{problem}[8]En los textos básicos de geometría de superficies en $ℝ^3$ se trabaja con parametrizaciones $\Phi:\mathcal{U}\subset ℝ^2\longrightarrow ℝ^3$, se definen los símbolos de Christoffel como las funciones $\Gamma_{ij}^k$ tales que $\Gamma_{ij}^k\partial_k\Phi$ es la proyección de $\partial_i\partial_j\Phi$ en el plano tangente $\Pi$  y se definen las componentes de la derivada covariante de un campo $V(t)$ a lo largo de una curva como $c^i$ con $c^i\partial_i\Phi$ la proyección de  $V'(t)$ sobre $\Pi$. Explica con detalle por qué esto es coherente con lo visto en este curso.  
	
	\solution\textit{Hecho por Fernando}\\ La base del plano tangente es $\{\partial_1\Phi,\partial_2\Phi\}$, por tanto los campos de vectores son de la forma $V=V^i\partial_i\Phi$. Si particularizamos en una curva, por la regla de la cadena 
	\[
	V'(t)=
	\Big(
	\frac{\partial V^i}{\partial x^j}
	\partial_i\Phi
	+V^i\partial_j\partial_i\Phi
	\Big)
	\frac{dx^j}{dt}.
	\]
	Por la definición del enunciado, $\partial_j\partial_i\Phi=\Gamma_{ij}^k\partial_k\Phi+\text{\sf un vector normal}$, así pues la proyección de $V'(t)$ sobre $\Pi$ es
	\[
	\Big(
	\frac{\partial V^i}{\partial x^j}
	\partial_i\Phi
	+V^i\Gamma_{ij}^k\partial_k\Phi
	\Big)
	\frac{dx^j}{dt}
	=\frac{dV^k}{dt}
	\partial_k\Phi
	+\Gamma_{ij}^k
	V^i
	\frac{dx^j}{dt}
	\partial_k\Phi
	\]
	y en este curso usamos $\partial_k$ en vez de $\partial_k\Phi$, por tanto la definición de derivada covariante es equivalente.  
	
	Los símbolos de Christoffel del curso también coinciden con los de los cursos de geometría de superficies porque la definición dada en estos, $\partial_j\partial_i\Phi=\Gamma_{ij}^k\partial_k\Phi+\text{\sf un vector normal}$, implica
	\begin{eqnarray*}
		\partial_i g_{jl}
		=\partial_i\langle\partial_j\Phi, \partial_l\Phi\rangle 
		&=&
		\langle\partial_i\partial_j\Phi, \partial_l\Phi\rangle 
		+\langle\partial_j\Phi, \partial_i\partial_l\Phi\rangle 
		\\
		&=&
		\langle\Gamma_{ij}^k\partial_k\Phi, \partial_l\Phi\rangle 
		+\langle\partial_j\Phi, \Gamma_{il}^k\partial_k\Phi\rangle 
		=
		\Gamma_{ij}^kg_{kl}
		+
		\Gamma_{il}^kg_{kj}
	\end{eqnarray*}
	y esta es la relación de la que en este curso obtuvimos la fórmula para $\Gamma_{ij}^k$ en términos de la métrica (\refeq{eq:Christoffel-metrica}).
	
	
	
\end{problem}
\begin{problem}[9]Explica por qué 
	\[
	\dfrac{\partial g'_{bc}}{\partial y^a}=
	\Big(
	\dfrac{\partial^2x^j}{\partial y^a\partial y^b}
	\dfrac{\partial x^k}{\partial y^c}
	+\dfrac{\partial^2x^j}{\partial y^a\partial y^c}
	\dfrac{\partial x^k}{\partial y^b}
	\Big)
	g_{jk}
	+
	\dfrac{\partial x^j}{\partial y^b}
	\dfrac{\partial x^k}{\partial y^c}
	\dfrac{\partial x^l}{\partial y^a}
	\dfrac{\partial g_{jk}}{\partial x^l}
	\]
	se sigue de la tensorialidad, donde $g_{bc}$ y $g'_{bc}$ son las componentes de la métrica con las coordenadas $x^i$ e $y^i$ respectivamente.  Permutando indices deduce que la ley de transformación de 
	$[ab,c]=g_{cl}\Gamma_{ab}^l$, a veces llamados \emph{símbolos de Christoffel de primera especie}, 
	es
	$[ab,c]'=[ij,k]
	\partial_ax^i
	\partial_bx^j
	\partial_cx^k
	+g_{jk}\partial_c x^k\partial_a\partial_b x^j$
	donde las $\partial_i$ son derivadas con respecto a $y^i$. 
	Concluye finalmente la ley de transformación
	de los símbolos de Christoffel habituales:
	\[
	{\Gamma'}_{ab}^c=
	\frac{\partial y^c}{\partial x^k}
	\frac{\partial x^i}{\partial y^a}
	\frac{\partial x^j}{\partial y^b}
	\Gamma_{ij}^k+
	\frac{\partial y^c}{\partial x^k}
	\frac{\partial^2x^k}{\partial y^a\partial y^b}.
	\]
	
	
	
	\solution\textit{Hecho por Fernando}\\Derivando con respecto a $y^a$ la relación
	\[
	g_{bc}'=
	\frac{\partial x^j}{\partial y^b}
	\frac{\partial x^k}{\partial y^c}
	g_jk
	\qquad\text{y sustituyendo }\quad
	\frac{\partial g_{jk}}{\partial y^a}
	=
	\frac{\partial g_{jk}}{\partial x^l}
	\frac{\partial x^l}{\partial y^a}
	\]
	se sigue la primera fórmula del enunciado. 
	
	Por la expresión de $\Gamma_{ab}^l$ en términos de las componentes de la métrica se deduce
	\[
	[ab,c]'=g_{cl}\Gamma_{ab}^l
	=
	\frac{1}{2}
	\big(
	\partial_b g_{ca}'
	+\partial_a g_{bc}'
	-\partial_c g_{ab}'
	\big).
	\]
	Empleando la primera fórmula del enunciado, el paréntesis con derivadas segundas para $\partial_b g_{ca}'$ es $\partial_a\partial_b x^j\partial_cx^k+\partial_a x^j\partial_b\partial_cx^k$. Permutando indices para 
	$\partial_a g_{bc}'$
	y para $-\partial_c g_{ab}'$ se obtienen respectivamente
	$\partial_b\partial_a x^j\partial_cx^k+\partial_b x^j\partial_a\partial_cx^k$
	y
	$-\partial_b\partial_c x^j\partial_ax^k-\partial_b x^j\partial_c\partial_ax^k$. 
	Al sumar los resultados se sigue
	\[
	[ab,c]'=[lj,k]
	\partial_bx^j
	\partial_cx^k
	\partial_ax^l
	+g_{jk}\partial_c x^k\partial_a\partial_b x^j,
	\]
	que es lo que afirma el enunciado. Ahora basta multiplicar en ambos miembros por
	\[
	g'^{cl}
	=
	\frac{\partial y^c}{\partial x^r}
	\frac{\partial y^l}{\partial x^m}
	g^{rm}
	\qquad\text{y usar }\quad
	\frac{\partial x^k}{\partial y^c}
	\frac{\partial y^c}{\partial x^r}
	=\delta_r^k
	\]
	para conseguir la fórmula final. 
	
	
\end{problem}
\begin{problem}[10] Un campo de vectores en una variedad riemanniana se dice que es un \textbf{campo de Killing} si verifica $V^k\partial_k g_{ij}+g_{kj}\partial_i V^k+ g_{ik}\partial_jV^k=0$ (en un problema especial veremos la motivación para esta extraña definición). 
	Demuestra que esto es equivalente a  
	$\nabla_j \xi_i+\nabla_i \xi_j=0$ donde $\xi_k=g_{km}V^m$.
	Indicación:  
	Usa $\nabla_k g_{mn}=0$ y que
	$g_{ik}\Gamma_{jr}^k+g_{jk}\Gamma_{ir}^k$ se simplifica mucho. 
	
	\solution\textit{Hecho por Fernando.}\\ La derivada covariante de la métrica es nula, por tanto
	\begin{eqnarray*}
		\nabla_j(g_{im}V^m)
		+
		\nabla_i(g_{jm}V^m)
		&=&
		g_{im}\nabla_j V^m 
		+
		g_{jm}\nabla_i V^m \text{ (porque }\nabla_lg_{ij}=0 )
		\\
		&=&
		g_{im}\big( \partial_j V^m+ \Gamma_{jl}^mV^l) 
		+
		g_{jm}\big( \partial_i V^m+ \Gamma_{il}^mV^l).
		\\
		&=&
		g_{im}\partial_j V^m+g_{jm} \partial_i V^m  
		+\big( g_{im}\Gamma_{jl}^m  + g_{jm}\Gamma_{il}^m)V^l.
	\end{eqnarray*}
	Queda demostrar que $g_{im}\Gamma^m_{jl}+g_{jm}\Gamma^m_{il}=\partial_lg_{ij}$. Esto es lo mismo que demostrar la indicación $\nabla_lg_{ij}=0$. No se pide demostrar (por eso se da como indicación) pero lo hacemos:\\
	Por la expresión de los símbolos de Christoffel en términos de la métrica,
	\[
	g_{im}\Gamma_{jl}^m
	=
	\frac{1}{2}g_{im}g^{mr}
	(\partial_l g_{rj}+\partial_j g_{lr}-\partial_r g_{jl})
	=
	\frac{1}{2}
	(\partial_l g_{ij}+\partial_j g_{li}-\partial_i g_{jl})
	\]
	Cambiando Indices, se obtiene la formula similar para 
	$g_{jk}\Gamma_{ir}^k$ y de ahí $g_{im}\Gamma_{jl}^m  + g_{jm}\Gamma_{il}^m=\partial_l g_{ij}$.\qed
	
	
\end{problem}