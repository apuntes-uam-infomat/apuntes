	\documentclass{apuntes}

\usepackage{hyperref}

\usepackage{tikztools}
\usepackage{fastbuild}
\usepackage{tikz-3dplot}

\usepackage{tikz}
\usepackage{graphicx}
\usepackage{latexsym, amsfonts, amsmath, amssymb, amscd, epsfig,amsthm}
\input xy 
\xyoption{all} %%!!
\usetikzlibrary{calc, intersections}
\author{Alberto Parramon}
\date{2014/2015 2º cuatrimestre}

\renewcommand*{\arraystretch}{1.5}

\title{Probabilidad II}
\precompileTikz

\begin{document}

\pagestyle{plain}
\maketitle

\tableofcontents
\newpage
\chapter{Evaluación y conocimientos previos (TIM y más)}

%Los diagramas de Venn que aparecen los he hecho en la siguiente web:
%https://www.gliffy.com/go/html5/launch?app=1b5094b0-6042-11e2-bcfd-0800200c9a66

\section{Sobre los apuntes}
Apuntes realizados durante el curso 2014/2015 de Probabilidad II, de la Universidad Autónoma de Madrid, segundo cuatrimestre. 

La asignatura la impartía Jesús Munárriz y estos apuntes se basan en copiar todo lo que decía en clase y tratar de explicar aquellos conceptos que pudieran no quedar claros.

Estos apuntes NO ESTÁN EXENTOS DE ERRORES. Están pseudo-revisados por algunos compañeros más del curso. Se anima al lector a que si encuentra errores escriba sobre el mismo a $alberto.parramon@esudiante.uam.es$.


\section{Evaluación}
P = parcial 26 de Marzo.

F = final Mayo.

NOTA=$max(0.3P+0.7F,F)$ 

\section{El profe}
Jesús Munarriz

jesus.munarriz@uam.es

Despacho 205 módulo 8.

Tutorías: L-X-J de 14:30 a 15:30 y también a otras horas mediante cita previa.

\section{Nociones básicas aleatorias}
\begin{itemize}
\item Leyes de Morgan y manejo de conjuntos (se utilizarán en muchas demostraciones):
\begin{enumerate}
\item $(\bigcup_{n=1}^{\infty}A_n)^c = \bigcap_{n=1}^{\infty}A_n^c$
\item $(\bigcap_{n=1}^{\infty}A_n)^c = \bigcup_{n=1}^{\infty}A_n^c$
\item $A \backslash B = A \cap B^c$

\end{enumerate}
\item Sobre funciones indicatrices:\\
$\ind_A(w)=1$ si $w \in A$\\
$\ind_A(w)=0$ si $w \in A^c$

\item $f_+ = max(f,0)$ y $f_- = max(-f,0)$. Y por tanto, $f=f_+ -f_-$ y $\abs{f}=f_+ +f_-$

\item Tma Fundamental del calculo: Dada una función f(x) continua en el intervalo [a,b] y sea F(x) cualquier función primitiva de f, es decir $F '(x) = f(x)$. Entonces:

\[
\int_a^b f(x)dx = F(b)-F(a)
\]
\item Función convexa (o cóncava hacia arriba), si cumple que: $f(tx+(1-t)y) \leq tf(x)+(1-t)f(y)$. Una parábola con las ramas hacia arriba es convexa.
\item Función cóncava: f es cóncava $\Leftrightarrow$ -f es convexa.
\end{itemize}

\section{Conceptos de TIM}
Este apartado está dedicado a teoremas y definiciones que se dan en TIM y que se usan en muchas demostraciones y ejercicios:

\begin{defn}[Función medible]
Sean $(\Omega_1, \algb{M})$, $(\Omega_2, \algb{N})$, dos espacios medibles, una aplicación $f:\Omega_1 \rightarrow \Omega_2$ es $(\algb{M}, \algb{N})$-medible (también se dice $\algb{M}$-medible o medible a secas) cuando $\forall N \algb{N}$ se verifica que $F^{-1}(N) \in \algb{M}$. Siendo $\algb{M}$ y $\algb{N}$ $\salgb$.
\end{defn}

\begin{defn}[Medida\IS $\sfin$]\label{defSigmaFinita}
Dado un espacio de medida $(X, \algb{M}, µ)$, decimos que una medida es $\sfin$ si el conjunto $X$ puede expresarse como una unión de elementos de la $\salgb$ de medida finita. Es decir, si \[X=\bigcup_{n=1}^{\infty}E_n, \ E_n \in \algb{M} \text{ y }µ(E_n)< \infty\]
\end{defn}

\begin{defn}[Integrar respecto a una medida una función indicatriz]
La integral con respecto a una medida de una función indicatriz evaluada sobre un subconjunto $E \in \Omega$ medible (perteneciente a la $\salgb$) es la medida de dicho subconjunto E:

\[\int_{\Omega} \ind_{E}d\mu = \mu(E)\]
\end{defn}

\begin{defn}[Función simple]
Combinación lineal finita de funciones indicatrices.

\[
s(x) = \sum_{i=1}^{n}(c_i \cdot \ind_{B_i}(x))
\]
\end{defn}

\begin{defn}[Integrar respecto a una medida una función simple]
Sea $(\Omega,\algb{M},\mu)$ un espacio de medida:

\[\int_{\Omega} sd\mu = \sum_{i=1}^{n}(c_i \int \ind_{B_i} d\mu) = \sum_{i=1}^{n}(c_i \mu(B_i))\]
\end{defn}

\begin{defn}[Función $L^+$]
$f \in L^+ \Leftrightarrow f:X\rightarrow [0, \infty]$
\end{defn}

\begin{defn}[Función $L^1$]
$f \in L^1 \Leftrightarrow \int \abs{f} < \infty $
\end{defn}

\begin{defn}[Teorema de aproximación de funciones simples]
Si $f:X \rightarrow [0, \infty]$ es una función medible, entonces existe una sucesión crecientes de funciones simples $s_n$, $0 \leq s_1 \leq s_2 \leq ... \leq f$ tal que $\forall x  \in X, s(x) \rightarrow f(x)$. Además la convergencia es uniforme sobre conjuntos en los que |f| es acotada.
\end{defn}

\begin{defn}[Teorema de la convergencia monótona: TCM]
Si $f_n$ es una sucesión creciente de funciones $L^+$ y $f(x)=sup_n\{f_n(x)\}=lim_nf_n(x)$ entonces:
\[
\int f = \lim_n \int f_n
\]
\end{defn}

\begin{defn}[Teorema de la convergencia dominada: TCD]
Sea $f_n$ una sucesión de $L^1(\mu)$ que converge para casi todo punto. Sea $g \in L^1(\mu)$ tal que $\abs{f_n} \leq q$ para casi todo punto. Entonces $f=\lim_{n \rightarrow \infty} f_n \in L^1(\mu)$ y además $\lim \int f_n = \int f$. 
\end{defn}


\chapter{Espacios de probabilidad}
\section{Formación de un espacio de probabilidad}
En primer lugar vamos a definir y estudiar los elementos por los que está formado un espacio de probabilidad:

\begin{defn}[Algebra de conjuntos]Sea $\Omega$ un espacio muestral (un conjunto), y sea $\algb{M}$ una colección de subconjuntos (eventos $w$) de $\Omega$. $\algb{M}$ es un álgebra si:
\begin{enumerate}
\item $\Omega \in \algb{M}$.
\item $A ∈ \algb{M}$ $\Rightarrow$ $A^c ∈ \algb{M}$. ($A^c = \Omega \setminus A = \{w \in \Omega : w \notin A\} $)
\item $A \in \algb{M}$ y $B \in \algb{M}$ $\Rightarrow$ $A \cup B \in \algb{M}$.  (la unión finita pertenece al álgebra)

\end{enumerate}
\end{defn}

Propiedades:
\begin{enumerate}
\item[3'] $A \in \algb{M}$ y $B \in \algb{M}$ $\Rightarrow$ $A \cap B \in \algb{M}$. (la intersección finita pertenece al álgebra)
\begin{proof}

$3 \Rightarrow 3')$ $A,B \in \algb{M} \stackrel{2}{\Leftrightarrow} A^c, B^c \in \algb{M} \stackrel{3}{\Rightarrow} A^c \cup B^c \in \algb{M} \Leftrightarrow (A \cap B)^c \in \algb{M} \stackrel{2}{\Leftrightarrow} A \cap B \algb{M}$

$3' \Rightarrow 3)$ $A,B \in \algb{M} \stackrel{2}{\Leftrightarrow} A^c, B^c \in \algb{M} \stackrel{3'}{\Rightarrow} A^c \cap B^c \in \algb{M} \Leftrightarrow (A \cup B)^c \in \algb{M} \stackrel{2}{\Leftrightarrow} A \cup B \in \algb{M}$
\end{proof}
\end{enumerate}

\begin{defn}[{σ}-álgebra]Sea $\Omega$ un espacio muestral (un conjunto), y sea $\algb{M}$ una colección de subconjuntos (eventos $w$) de $\Omega$. $\algb{M}$ es una $\salgb$ si:
\begin{enumerate}
\item $\Omega \in \algb{M}$.
\item $A ∈ \algb{M}$ $\Rightarrow$ $A^c ∈ \algb{M}$. ($A^c = \Omega \setminus A = \{w \in \Omega : w \notin A\} $)
\item $A_1, A_2,..., A_n \in \algb{M} \Rightarrow \bigcup_{n=0}^{\infty}A_n \in \algb{M}$ (la unión numerable pertenece a la $\salgb$).
\end{enumerate}
\end{defn}

\obs: $\algb{M}$ es una $\salgb$ si es un álgebra y además la unión numerable de elementos de $\algb{M}$ pertenece a $\algb{M}$. 

Propiedades:
\begin{enumerate}
\item[3']$A_1, A_2,..., A_n \in \algb{M} \Rightarrow \bigcap_{n=0}^{\infty}A_n \in \algb{M}$ (la intersección numerable pertenece a la $\salgb$.)
\begin{proof}
Se demuestra de la misma manera que para la intersección finita realizada anteriormente.
\end{proof}
\end{enumerate}


\begin{defn}[Función de probabilidad] P:$\algb{M} \rightarrow [0,1]$ es una función definida en ($\Omega,\algb{M}$). Siendo $\Omega$ un conjunto. 

Si $\algb{M}$ es un álgebra entonces P es finitamente aditiva y cumple:
\begin{enumerate}
\item $P(\Omega) = 1$.
\item $A,B ∈ \algb{M}$ y $A \cap B = \emptyset$ $\Rightarrow$ $P(A \cup B) = P(A) + P(B)$ (\textbf{aditividad finita}).
\end{enumerate}

Si $\algb{M}$ es una $\salgb$ entonces P es numerablemente aditiva y cumple:
\begin{enumerate}
\item $P(\Omega) = 1$.
\item $A_1,A_2,...,A_n ∈ \algb{M}$ y son disjuntos 2 a 2 $\Rightarrow$ $P(\bigcup_{i=0}^{\infty}) = \sum_{i=0}^{\infty}P(A_i)$ (\textbf{aditividad numerable}).
\end{enumerate}
\end{defn}

\obs No hay probabilidad numerablemente aditiva en $\mathbb{N}={0,1,2,...}$ que sea uniforme, es decir, que para cualquier $i,j \in \mathbb{N}, i \neq j, P({i}) = P({j})$. 

\begin{proof}
Lo probamos usando la propiedad de la aditividad numerable y cogiendo $\Omega = \mathbb{N}$
\begin{itemize}
\item Si $P({i})=0$ $\Rightarrow$ $1=P(\mathbb{N})= \sum_{i=0}^{\infty}P({i})= \sum_{i=0}^{\infty}0=0$  contradicción. 
\item Si $P({i})=k>0$ $\Rightarrow$ $1=P(\mathbb{N})= \sum_{i=0}^{\infty}P({i})=\sum_{i=0}^{\infty}k = \infty$  contradiccion. 
\end{itemize}
Sin embargo, sí existen probabilidades finitamente aditivas en $\mathbb{N}$ que satisfacen $P({i}) \neq 0$.
\end{proof}

Una vez estudiados sus elementos, podemos dar una definición de qué es un espacio de probabilidad:

\begin{defn}[Espacio de probabilidad] Es la tripla $(\Omega, \algb{M}, P)$. siendo $\Omega$ un conjunto, $\algb{M}$ una $\salgb$ y P una función de probabilidad.
\end{defn}

Propiedades:
\begin{enumerate}
\item $P(A^c) = 1-P(A)$
\begin{proof}
$1=P(\Omega)=P(A \cup A^c) = P(A) + P(A^c)$ 

Hemos usado la propiedad de la aditividad numerable de las funciones de probabilidad, por ser $A$ y $A^c$ disjuntos.
\end{proof} 
\item $P(A \cup B) = P(A) + P(B) - P(A \cap B)$
\begin{proof}

Por un lado (volvemos a usar la aditividad numerable):\\
$A \cup B = A \cup (B \backslash A) \Rightarrow P(A \cup B) = P(A \cup (B \backslash A)) = P(A) + P(B \backslash A)$\\

Por otro lado:\\
$P(B) = P(B \cap A) + P(B \cap A^c)$\\
$P(B \cap A^c) = P(B \backslash A) = P(B) - P(B \cap A)$ \\

Juntando los dos resultados obtenemos la expresión que queríamos demostrar.
\end{proof}

\item Continuidad inferior: Sean $A_1 \subset A_2 \subset A_3 \subset ...$ una sucesión creciente de conjuntos medibles, es decir, pertenecientes a $\algb{M}$ entonces:
\[ P(\bigcup_{n=1}^{\infty}A_n) = \lim_{n \rightarrow \infty} P(A_n)
\]


\begin{proof}
Vamos a usar la propiedad de aditividad numerable.

Definimos:

$D_1=A_1$\\
$D_2=A_2 \backslash A_1$\\
$D_{n+1}=A_{n+1} \backslash \bigcup_{n=1}^{\infty}A_n=A_{n+1} \backslash \bigcup_{n=1}^{\infty}D_n=A_{n+1} \backslash A_n$

Entonces: 
\[P(\lim_{n \rightarrow \infty}A_n)=P(\bigcup_{n=1}^{\infty}A_n)=P(\bigcup_{n=1}^{\infty}D_n)=\sum_{n=1}^{\infty}P(D_n)=\lim_{n \rightarrow \infty}\sum_{i=1}^{n}P(D_i)=\lim_{n \rightarrow \infty}P(\bigcup_{i=1}^{n}D_i) =
\]
\[
=\lim_{n \rightarrow \infty}P(A_n)
\]
\end{proof} 

\obs De esta propiedad podemos afirmar lo siguiente: \[ \bigcup_{n=1}^{\infty}A_n = \lim_{n \rightarrow \infty} A_n \Rightarrow P(\lim_{n \rightarrow \infty} A_n) = \lim_{n \rightarrow \infty} P(A_n)
\]
\obs Si $A_1 \subset A_2 \subset A_3 \subset...$ entonces tenemos una convergencia puntual:
\[
\lim_{n \Rightarrow \infty}\ind_{A_n}(w) = \ind_{\bigcup_{i=1}^{\infty}A_i}(w)
\]

\item Continuidad superior: Sean $A_1 \supset A_2 \supset A_3 \supset ...$ una sucesión decreciente de conjuntos medibles, es decir, pertenecientes a $\algb{M}$ entonces 
\[ P(\bigcap_{n=1}^{\infty}A_n) = \lim_{n \rightarrow \infty} P(A_n)
\]

\begin{proof}
\[P(\bigcap_{i=1}^{\infty}A_i) = 1-P\left((\bigcap_{i=1}^{\infty}A_i)^c\right)=1-P(\bigcup_{i=1}^{\infty}A^c) \stackrel{3)}{=} 1-\lim_{n \rightarrow \infty}P(A_n^c)=\lim_{n \rightarrow \infty}(1-P(A_n^c)) = 
\]
\[
\lim_{n \rightarrow \infty}P(A_n)
\]
\end{proof}

\obs Si $A_1 \supset A_2 \supset A_3 \supset...$ entonces tenemos una convergencia puntual:
\[
\lim_{n \Rightarrow \infty}\ind_{A_n}(w) = \ind_{\bigcap_{i=1}^{\infty}A_i}(w)
\]
\end{enumerate}


\begin{defn}[Espacio de medida]
 Es la tripla $(\Omega, \algb{M}, P)$. siendo $\Omega$ un conjunto, $\algb{M}$ una $\salgb$ y $\mu$ una función de medida.
\end{defn}

La diferencia con espacio de probabilidad, es que aquí definimos $\mu$ como una función: $\mu: X \rightarrow [0,\infty)$  (o incluyendo el $\infty$). En lugar de P que era una función: $P: X \rightarrow [0,1]$. Ambas trabajan con conjuntos pertencientes a $\algb{M}$, es decir, medibles.


\section{Conceptos básicos de Probabilidad}
Incorporamos al modelo nueva información relevante que condiciona los nuevos valores asignados.

\begin{defn}[Probabilidad condicionada]
Supongamos un conjunto $\Omega$ y dos conjuntos A y B pertenecientes a la $\salgb$ $\algb{M}$ de $\Omega$. Suponemos también que $P(B)>0$, y definimos una nueva función de probabilidad:

\[ P_B(A) = P(A | B) = \frac{P(A \cap B)}{P(B)}\]

$P_B$ es una probabilidad en B. $P_B(A)$ es la probabilidad de A condicionada a B. Dicho de otra forma, es la probabilidad de A sabiendo que se ha dado el suceso B.
\end{defn}

\begin{center}
\includegraphics[scale=0.75]{img/Dvenn1.png}
\end{center}

\begin{defn}[Regla del producto]
Sean $\{A_1, A_2,...,A_n\}$ eventos con $P(A_i)>0$ entonces

\[
P(\bigcap_{i=1}^{\infty}A_i) = P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)...P(A_n|A_1\cap A_2\cap ... \cap A_{n-1})
\]
(Suponiendo que $P(A_n|A_1\cap A_2\cap ... \cap A_{n-1})>0$)
\begin{proof}
\[
P(A_1)P(A_2|A_1)P(A_3|A_1\cap A_2)...P(A_n|A_1\cap A_2\cap ... \cap A_{n-1})=
\]
\[
=P(A_1)\frac{P(A_2\cap A_1)}{P(A_1)}\frac{P(A_3\cap A_2\cap A_1)}{P(A_2\cap A_1)}...\frac{P(\bigcap_{i=1}^{n-1}A_i)}{P(\bigcap_{i=1}^{n-2}A_i)}\frac{P(\bigcap_{i=1}^{n}A_i)}{P(\bigcap_{i=1}^{n-1}A_i)} = P(\bigcap_{i=1}^{n}A_i)
\]
\end{proof}
\end{defn}
\begin{example}
Caja con 10 bolas blancas y 10 bolas negras. Se extrae 1 bola y sin devolverla a la caja se extra otra segunda. ¿Cuál es la probabiidad de que las dos sean blancas?

P(2 blancas)=$\frac{10}{20}\frac{9}{19}$
\end{example}

\begin{defn}[Regla de la probabilidad total]
Sea  $\{A_1, A_2,...,A_n\}$ una partición de $\Omega$ con $P(A_i)>0 \forall i=1,2,...,n$. Entonces, $\forall B \subset \Omega$ medible (perteneciente a $\algb{M}$):
\[
P(B)=\sum_{i=1}^{n}P(B\cap A_i)=\sum_{i=1}^{n}P(B|A_i)P(A_i)
\]
(Se obtiene de despejar de la formula de la probabilidad condicionada: $P(A|B)=\frac{P(A \cap B)}{P(B)}$)
\end{defn}

\begin{figure}[h]
\centering
\includegraphics[page=1,scale=0.745]{img/Dvenn2.png}
\caption{Ejemplo de partición con n=16}
\end{figure}

\begin{defn}[Teorema de Bayes]
Modeliza la noción de "causa-efecto", donde $A_1, A_2,...,A_n$ son posibles causas del efecto B:
\[
P(A_i|B)= \frac{P(A_i\cap B)}{P(B)}= \frac{P(B|A_i)P(A_i)}{\sum_{k=1}^{n}P(B|A_k)P(A_k)}
\]

(Combina la regla de la probabilidad condicionada con la regla de la probabilidad total)
\end{defn}

\begin{defn}[Independencia]
\[
A,B \text{ son independientes} \Leftrightarrow P(A \cap B)=P(A)P(B)
\]

\obs Si un suceso A es independiente de otro suceso B (de modo que B no proporciona información útil sobre A) entonces $P(A|B)=P(A)$.
\obs Dada una sucesión finita $\{A_i\}_{i=1}^{n}$ o infinita $\{A_i\}_{i=1}^\infty$ de eventos, decimos que estos son independientes si toda subsucesión $A_{i_1}, A_{i_2},..., A_{i_n}$ con $(2 \leq n < \infty)$ finita, saisface:
\[
P(\bigcap_{i=1}^nA_{i_j})=\prod_{i=1}^{n}(P(A_{i_j}))
\]

\obs Los conjuntos $A_1, A_2,...,A_n$ son independientes 2 a 2 si $\forall$ par \{i,j\} con $i \neq j$, tenemos que $A_i$ y $A_j$ son independientes.

\begin{example}
Supongamos que A es independiente de A. Entonces tenemos que: $P(A\cap A)=P(A)=P(A)P(A) \Leftrightarrow P(A)=0$ ó $P(A)=1$
\end{example}
\end{defn}



\begin{example}
Sean A,B,C $\subset [0,1]$ con los borelianos (la $\salgb$ generada por los abiertos) y la medida de Lebesgue $\lambda$. Observamos que este espacio de medida coincide con un espacio de probabilidad con función de probabilidad uniforme P.

Es decir, tenemos 3 conjuntos que son uniones numerables o complementarios de intervalos en $[0,1]$. Estos conjuntos no son independientes. Vamos a definir una nueva probabilidad de manera que tengamos independencia con conjuntos semejantes a estos:

\~{A} $= A\times[0,1]^2 \subset [0,1]^3$

\~{B} $= [0,1]\times B \times[0,1]$

\~{C} $= C \times[0,1]^2$

Por tanto \~{A}, \~{B} y \~{C} son independientes y \~{A} $\cap$ \~{B} = $\{x \in [0,1]^3, x=(x_1, x_2, x_3) | x_1 \in A, x_2 \in B, x_3 \in [0,1]\}$.

Y podemos definir \~{P}(\~{A}$\cap$ \~{B})=$P(A)P(B)P([0,1])$ (por definición de medida producto)

Siendo \~{P} en $[0,1]^3$ la probabilidad producto.

Además \~{P}(\~{A}$\cap$\~{C}) = \~{P}(\~{A})\~{P}(\~{C})=$P(A)P(C)$ etcetera etcetera...

Unos dibujitos aclaratorios, para hacerlo más fácil consideramos que estamos en $[0,1]^2$ y:

$A1 = A\times[0,1]$

$B1 = [0,1]\times B$

\begin{figure}[h]
\centering
\includegraphics[page=1,scale=0.545]{img/Dvenn3.png}
\caption{A = [0,1/2], B=[0,1/2]}
\end{figure}

\end{example}

\begin{defn}[Independencia de conjuntos respecto a otro conjunto] Sea $P(C)>0 \Rightarrow$ A y B son condicionalmente independientes con respecto a C si: 
\[
P(A\cap B|C)=P(A|C)P(B|C)
\]

Es decir, A y B son independientes entre ellos tomando como $\Omega$ el conjunto C.

Entonces si $P(B\cap C)>0$, se cumple que $P(A|B\cap C)=P(A|C)$
\end{defn}

\begin{defn} [Variable aleatoria]
Dado ($\Omega_1$,$\algb{M}$) y ($\Omega_2$,$\algb{B}$):
\[
X: \Omega_1 \rightarrow \Omega_2 \text{es una variable aleatoria} \Leftrightarrow \forall B \in \algb{B}, X^{-1}(B) \in \algb{M}
\]

En este curso usaremos como $\Omega_2$ conjuntos como $\mathbb{R}$ o $\mathbb{R} \cup \{\pm \infty\}$ o $\mathbb{C}$. Si $\Omega_2 = \mathbb{R}^d$, decimos que la función medible $X: \Omega_1 \rightarrow \mathbb{R}^d$ es un vector medible.
\end{defn}
\obs \textbf{IMPORTANTE. }Una variable aleatoria es una función medible.

\textcolor{red}{Las definiciones de variable aleatoria discreta y continua no aportan nada nuevo de lo que ya sabemos de otros años.}

\begin{defn}[Variable aleatoria discreta]
Una variable aleatoria X es discreta $\Leftrightarrow$ $P_X$ es discreta. Es decir, si toma valores en un conjunto numerable. Se caracteriza por tener una función de masa o de probabilidad, y una función de distribución.

Otras definiciones:

Recordemos que X es una función. $X: \Omega \rightarrow \mathbb{R}$. X es discreta si existe un conjunto numerable $x_1, x_2,...,x_n \in \mathbb{R}$ (siendo $x_i=X(w_i)$) tal que $P(\bigcup_{i=1}^{\infty}x_i=1)$.

$P_X$ es discreta si $P_X(\mathbb{R})=\sum_{i=1}^{\infty}P(X=x_i)$ (es decir, se puede expresar como un sumatorio numerable).
\end{defn}

\begin{defn}[Variable aleatoria continua]
Una variable aleatoria es continua si toma valores en un conjunto no numerable. Tiene asociada una función de densidad o de probabilidad, y una función de distribución.

X es una variable aleatoria continua $\Leftrightarrow$ $P_x$ es absolutamente continua con respecto a la medida de Lebesgue ($\lambda$) (se escribe $P_X << \lambda$) $\Leftrightarrow F_X$ es una función absolutamente continua $\Leftrightarrow$ $f_X=F_X'$ satisface que $F_X(t)=\int_{-\infty}^{t}f_X(x)dx$.
\end{defn}

\begin{defn}[Función de distribución]
\[
F_X(t)=P(X^{-1}(-\infty,t])=P_X(X \leq t)
\]

Así tenemos que: $P_X((a,b])=F_X(b)-F_X(a)$

La función de distribución cumple:
\begin{itemize}
\item $\lim_{n \rightarrow \infty}F(x)=1$
\item $\lim_{n \rightarrow -\infty}F(x)=0$
\item $F(t)=\int_{-\infty}^{t}f(x)dx$
\end{itemize}

\end{defn}

\begin{defn}[ley de X]
Dado el espacio de probabilidad ($\Omega, \algb{M}, P$) y la variable aleatoria $X: \Omega \rightarrow \mathbb{R}$, la ley de X es la probabilidad en $\mathbb{R}$ definida mediante:
\[
P_x(B)=P(X^{-1}(B)) \text{ } \forall B \in Borel(\mathbb{R})
\]

Notación: $P_x(B) = P(X^{-1}(B)) = P(\{w \in \Omega : X(w) \in B\})=P(X \in B)$

Notación: $Borel(\mathbb{R})$ es el conjunto de intervalos en $\mathbb{R}$, (los borelianos de toda la vida).


\end{defn}


\begin{example}

\textbf{ PARA ACLARAR LO QUE ES UNA FUNCIÓN MEDIBLE }Supongamos un dado de 6 caras. Tomamos dos situaciones:
\begin{enumerate}
\item  $\Omega = \{1,2,3,4,5,6\}$ y $\algb{M}=\mathbb{P}(\Omega)$.

Entonces la función X se define:

$X: \Omega \rightarrow \mathbb{R}$

Todas las funciones X son medibles ya que tenemos $(\Omega,\algb{M})$ y $(\mathbb{R}, Borel(\mathbb{R}))$, y entonces $\forall A \in Borel(\mathbb{R})$ tenemos que $X^{-1}(Borel(\mathbb{R})) \in \algb{M}$

Una vez definidos cuales son los medibles en los conjuntos de salida $(\Omega,\algb{M})$ y de llegada $(\mathbb{R}, Borel(\mathbb{R}))$. Podemos definir la siguiente variable aleatoria X.

$X(w) = 1$ si $w=3$ 

$X(w) = 0$ si $w\neq3$

Siendo $w \in \Omega$, esta variable aleatoria es equivalente a $X(w) = \ind_{\{3\}}$.

De esta manera podemos ver que: $X^{-1}(\{1\}) = \{3\}$, $X^{-1}(\{0\}) = \{1,2,4,5,6\}$, $X^{-1}((1/2,\infty)) = \{3\}$, y $X^{-1}((-2,\infty)) = \Omega$ entre otros ejemplos.


\item $\Omega = \{1,2,3,4,5,6\}$ y $\algb{B} = \{\Omega, \emptyset, \{1,3,5\}, \{2,4,6\} \}$

Entonces la función X se define:

$X: \Omega \rightarrow \mathbb{R}$

Pero en este caso, las funciones medibles ($\algb{B}-medibles$) son aquellas que son constantes en $\{1,3,5\}$ y en $\{2,4,6\}$. Ya que por ejemplo si tengo una función del tipo: $X(\{1\})=1$, $X(\{2\})=2$, $X(\{3\})=3$, $X(\{4\})=4$, $X(\{5\})=5$, $X(\{6\})=6$. Y calculo $X^{-1}((1/2, 3/2))=\{1\}$, que no pertenece a $\algb{B}$ y no es medible, por tanto X no sería medible y no sería una variable aleatoria.
\end{enumerate}

\obs Dada una función $X:(\Omega, \algb{M}) \rightarrow (\mathbb{R}, Borel(\mathbb{R}))$, para comprobar que es una función medible, y por tanto que es una variable aleatoria (es decir, que $\forall B \in Borel(\mathbb{R}) \rightarrow X^{-1}(B) \in \algb{M}$), basta comprobarlo para cualquier clase que genere a los borelianos (a $Borel(\mathbb{R})$).

Puesto que $Borel(\mathbb{R})=\{(r,\infty): r\in \mathbb{Q}\}$, para ver que X es una variable aleatoria basta comprobar que $\forall r \in \mathbb{Q}, X^{-1}((r, \infty)) \in \algb{M}$.

\end{example}

\begin{defn}[Esperanza o media]
Sea un espacio de probabilidad $\{\Omega, \algb{M},P\}$, la media o esperanza de una variable aleatoria X es:
\[
E(X)=E_p(X)=\int_{\Omega}X(w)dP(w)
\]

Si la variable aleatoria es continua:

\[
E(X)=E_p(X)=\int_{\Omega}X(w)dP(w) = \int_{-\infty}^{\infty}x\cdot dP_X(x)= \int_{-\infty}^{\infty}x\cdot dF_X(x) = \int_{-\infty}^{\infty}x\cdot f_P(x) dx
\]

Donde $F_X(t)=P(X \leq t)$ es la función de distribución de X y $f(t)=F'_X(t)$ la de densidad.

Si es discreta:

\[
E(X)=\sum_{n=1}^{\infty}X(w_n)P(w_n)
\]


\obs \textbf{Breve explicación del concepto de integrar respecto a una medida}(Desde aquí hasta la definición de varianza hay una explicación, posiblemente obvia para muchos lectores,  de lo que es derivar con respecto a una medida, además esta escrita con mis palabras con lo que puede que os liéis, si es así, os recomiendo borrarla de la cabeza, aunque también puede servir) Derivar con respecto a P(w), es derivar con respecto a una medida, que tal y como hemos visto en TIM es equivalente a derivar la función de distribución de dicha medida e integrar con respecto a x. O lo que es lo mismo, multiplicar por la función de densidad. 

El concepto es natural en este caso, si se piensa que la integral es una suma infinita, y si derivas con respecto a una medida lo que quieres es obtener la medida de cada $w \in \Omega$. En este caso se suele hacer un cambio de variable, e integrar en $\mathbb{R}$ en lugar de en $\Omega$, por tanto ahora integras las x=X(w), y pones la función de densidad, que asigna a cada valor X(w) su probabilidad (sabemos que al hacer la integral estamos considerando que la variable aleatoria es continua, y no discreta, y que por tanto la probabilidad de un evento es igual a la probabilidad de un punto, que es 0 ya que el area bajo un punto es 0), que es lo equivalente a la función de probabilidad, de manera que queda:

\[
E(X)=E_p(X)=\int_{\Omega}X(w)dP(w) = \int_{\mathbb{R}}x\cdot dP_X(x)= \int_{\mathbb{R}}x\cdot dF(x) = \int_{\mathbb{R}}x\cdot f(x) dx
\]

Siendo $f(x)$ la función de densidad asociada a esa probabilidad (a esa función de distribución P), que aplicando el Tma. Fundamental del Calculo (ver capitulo 1):

\[
F(x) = \int_{-\infty}^{x}f(x)dx  \rightarrow \frac{dF(x)}{dx}= f(x) \rightarrow dF(x) = f(x)dx
\]

Por tanto, dada una integral con respecto a una medida $\mu$, primero obtenemos la función de distribución asociada a $\mu$ y posteriormente derivamos esa función de distribución obteniendo la función de densidad y la integral con respecto a x, que sí sabemos resolver.

Cuando la variable aleatoria es discreta la esperanza se calculará como una suma finita por la medida (probabilidad) de cada evento $w \in \Omega$.

%\obs $P(a \leq w \leq b)= \int_{b}^{a} f(x)dx$, por tanto: $dP(a \leq w \leq b) = f(b)-f(a).
\end{defn}


\begin{defn}[Varianza]
Sea un espacio de probabilidad $\{\Omega, \algb{M},P\}$, la varianza de una una variable aleatoria X es:
\[
var(X)=E[(X-E(X))^2] = E(X^2)-E(X)^2
\]

\obs Si $X(w)=c$  $\forall w$, entonces $E(X)=c$
\obs E(E(X))=E(X)
\end{defn}

\begin{defn}[Formula del cambio de variable]
Sea $X: \Omega \rightarrow \mathbb{R}$ una variable aleatoria, y sea $g:\mathbb{R} \rightarrow \mathbb{R}$ una función de Borel. Entonces:

\[
\mathbb{E}(g(X))=\int_{\Omega}g(X(w))dP(w)=\int_{\mathbb{R}}g(x)dP_X(x)
\]

Recordatorio: $P_X(A)=P(X\in A)=P(X^{-1}(A))$
\end{defn}


\begin{proof}
\textbf{De la fórmula del cambio de variable} Esta demostración puede servir para aclarar algunos conceptos de TIM, lo hacemos despacio:

\begin{enumerate}
\item Primero vamos a ver que es cierto para funciones $g=\ind_{B}$, con $B \in Borel(\mathbb{R})$. De manera que por ser una función indicatriz se cumple que: $\ind_{B}(X(w))=1 \Leftrightarrow X(w) \in B$. 

En este caso tendríamos (Usamos la definición de integrar respecto a una medida una función indicatriz):
\[
\mathbb{E}(g(X(w))) = \mathbb{E}(g(X)) = \mathbb{E}(\ind_{B}(X))=\int_{\Omega}\ind_{B}(X(w))dP(w) =
\]
\[
= P(X(w)\in B) = P(X^{-1}(B))=P_X(B)=\int_{\Omega}\ind_{B}(x)dP_X(x)
\] 

Breve explicación: 
\begin{itemize}
\item Poner o no la 'w' al poner X(w) no es más que notación, se sobreentiende que esa w siempre esta ahí, ya que X es una variable aleatoria, y por tanto una función que depende de w.
\item Estamos integrando sobre un espacio $\Omega$, sin embargo la indicatriz esta evaluada sobre un espacio de Borel que no tiene por que pertenecer a $\Omega$. Por eso, el resultado de la integral no es P(B) que es lo que sería aplicando la definición anterior (si ocurriera que $B\in \Omega$). En este caso, el resultado sera la medida P de todos los $w \in \Omega$ que provocan que $X(w) \in B$.
\item La última igualdad sale por definición de integrar respecto a una medida una función indicatriz.
\end{itemize}
\item Si $g \geq 0$ (es decir, $g \in L^+$), entonces, por el teorema de la aproximación de funciones simples, existe una sucesión $s_n\nearrow g$ (converge a g en todo punto y la sucesión es monótona creciente). Así podemos escribir:

\[
\int g dP = \int \lim_{n \rightarrow \infty}s_n dP \stackrel{TCM}{=} \lim_{n \rightarrow \infty}\int s_n dP
\]

Y dicha integral la sabemos resolver aplicando la definición de integral sobre funciones simples que hemos visto anteriormente y aplicando el punto 1 de esta demostración.
\item Y el último caso sería una funcion $g:\mathbb{R} \rightarrow \mathbb{R}$, en cuyo caso escribimos $g=g_+-g_-$ (ver capitulo 1.3). Y nos queda $\int gdP = \int g_+dP -\int g_-dP$(por la linealidad de la integral).

Por tanto hemos expresado g como resta de dos funciones $g_+$ y $g_-$, ambas pertenecientes a $L^+$. Entonces podemos hallar $\int g$ aplicando el punto 2 de esta demostración. Debemos tener en cuenta que $\int g$ existirá si: $\int g_+dP < \infty$ ó $\int g_-dP < \infty$

\end{enumerate}
\end{proof}


\begin{example}
\begin{itemize}
\item $\mathbb{E}(X)$ no esá bien definida si $\int_{\mathbb{R}}X_+ dP_X=\infty$ y $\int_{\mathbb{R}}X_- dP_X=\infty$.

\item $\mathbb{E}(X^2)$ siempre esta bien definida ya que $(X^2)_-=0$.
\item Si $X \geq 0$, $\mathbb{E}(X)$ está bien definida.
\item Sea una variable aleatoria de Bernoulli de parámetro p. Entonces $P(X=1)=p$ y $P(X=0)=1-p$. Llamamos función de masa a $P(X=i)$.

$\mathbb{E}(X)$ está bien definida porque X(w) es siempre $\geq 0$. 

\[
\mathbb{E}(X)=0\cdot P(X=0)+1\cdot P(X=1)=0\cdot(1-p)+1\cdot p=p
\]
\[
\mathbb{E}(X^2)=0^2\cdot P(X=0)+1^2\cdot P(X=1)=0^2\cdot(1-p)+1^2\cdot p=p
\]
\[
\mathbb{V}(X)=\mathbb{E}(X^2)-\mathbb{E}(X)^2=p-p^2=p(1-p)
\]
\item Sea $S_n=X_1+X_2+...+X_n$, con $X_i=Bernoulli(p)$, entonces $S_n ~ Binomial=B(n,p)$.
\[
\mathbb{E}(S_n)=\mathbb{E}(\sum_{i=1}^{n}X_i)\stackrel{linealidad integral}{=}\sum_{i=1}^{n}(\mathbb{E}(X_i))=np
\]
\item $X\sim N(0,1)$
Sabemos que $f_X(x)=\frac{e^{-x^2/2}}{\sqrt{2\pi}}$, por tanto:

\[
\mathbb{E}(g(X))=\int_{-\infty}^{\infty}g(x)\frac{e^{-x^2/2}}{\sqrt{2\pi}}dx
\]
\end{itemize}
\end{example}

\chapter{Esperanza condicionada}

Empezamos definiendo una serie de conceptos que usaremos más adelante:

\begin{defn}[Norma y convergencia]
Sea $(X, \algb{M}, \mu)$ un espacio de medida. Para $0<p<\infty$, definimos $L^p=L^p(X,\algb{M},\mu)=\{f:X\rightarrow \mathbb{R}$ ó $\mathbb{C} | \int_X \abs{f}^p d\mu < \infty\}$

\begin{itemize}
\item Si $p \geq 1$, entonces $\norm{f}_p = (\int_X {\abs{f}^p d\mu)}^{\frac{1}{p}}$ es una norma. Algo es una si cumple estas tres propiedades:
\begin{enumerate}
\item Positividad: $\norm{f}\geq 0$ y $\norm{f} = 0 \Leftrightarrow f=0$.
\item Proporcionalidad: $\norm{\lambda f} = \abs{\lambda}\norm{f}$.
\item Desigualdad triangular: $\norm{u+v} \leq \norm{u}+\norm{v}$     
\end{enumerate}
\item Y decimos que una función converge en $L_p$:

\[
f_n \stackrel{L_p (n\rightarrow \infty)}{\rightarrow} g \Leftrightarrow \norm{f_n -g}_p  \rightarrow 0 \Leftrightarrow \int{\abs{f_n -g}^pd\mu} \rightarrow 0
\]
\end{itemize}

\obs En los ejercicios se toma como $\mu$ la probabilidad P, y como X, se toma $\Omega$, de al manera que estás integrando sobre un espacio que mide como mucho 1. Lo que significa que por ejemplo sea f=1, entonces: $\int_{\Omega}fdP = 1$, mientras que $\int_{\mathbb{R}}fdx = \infty$

\obs Definimos la norma infinito de f como el supremo esencial de f, visualmente:

\textcolor{red}{PONER DIBUJO}

\end{defn}

\begin{defn}[medida absolutamente continua con respecto a otra $\mu << \nu$]
$\mu << \nu$ si $\mu(A)=0 \Rightarrow \nu(A)=0$

\begin{example}
Sea $f \geq 0$ medible y sea $\mu(A)=0$, entonces $\int_Afd\mu=0$ (se ve fácil con la fórmula del cambio de variable). Si defino $\nu(B)=\int_B fd\nu$, entonces tenemos que $\mu << \nu$.
\end{example}
\end{defn}

\begin{defn}[medida con signo]
Sea $f:\mathbb{R}\rightarrow \mathbb{R}$, entonces $\nu(B)=\int_B fd\nu$ es una medida con signo (y además $\mu << \nu$). Es una medida con signo ya que al ser una medida que depende de una función que va de $[-\infty, \infty]$, puede adquirir valores negativos.
\end{defn}

\begin{defn}
X es una variable aleatoria continua $\Leftrightarrow$ $P_x$ es absolutamente continua con respecto a la medida de Lebesgue ($\lambda$) (se escribe $P_X << \lambda$)
\end{defn}

\begin{theorem}[Teorema de Radon-Nikodyn]
Sea $\nu << \mu$ una medida con signo ($\mu \geq 0$, $\mu$ y $\nu$ son $\sfin$, y $\nu_+(X) < \infty$ ó $\nu_-(X) < \infty$). Entonces existe una funcion f medible tal que $f:X \rightarrow \mathbb{R}$ que cumple que $\forall B$ medible $\subset X$ se cumple $\nu(B)=\int_Bfd\mu$. Escribimos $f=\frac{d\nu}{d\mu}$, la derivada de Radon-Nikodyn. 
\end{theorem}


\begin{defn}[sigma-álgebra generada por una función]
Sea $Y: \Omega \rightarrow \mathbb{R}$, entonces $\sigma(Y)$ es la $\salgb$ más pequeña que hace que Y sea medible, es decir: $\{Y^{-1}(B):B \in Borel(\mathbb{R})\}$
\end{defn}

\obs También podemos escribir $\sigma(Z)$ siendo Z un conjunto de elementos (por ejemplo una parición) de $\Omega$. Y se referirá a la $\salgb$ generada por ese conjunto de elementos.

\begin{example}
Sea una función $Y:\mathbb{R} \rightarrow \mathbb{R}$ definida mediante $Y=\ind_{[0,\infty]}$, entonces $\sigma(Y)=\{\emptyset, (-\infty, 0), [0, \infty), \Omega \}$.

\begin{expla}
Y es una función que vale 0 en el intervalo $(-\infty, 0)$ y 1 en el intervalo $[0, \infty)$, por tanto para que Y sea medible (sea una variable aleatoria) tiene que cumplir que la imagen de los elementos pertenecientes al conjunto de salida ($\mathbb{R}$), sean constantes en el de llegada ($\mathbb{R}$). Como el conjunto de llegada consta de dos intervalos constantes ( vale 0 en el intervalo $(-\infty, 0)$ y 1 en el intervalo $[0, \infty)$); concluimos que la mínima $\salgb$ generada por la función Y es $\sigma(Y)=\{\emptyset, (-\infty, 0), [0, \infty), \Omega \}$.
\end{expla}
 
\end{example}

\begin{defn}[Esperanza condicionada]

Sabemos que si $P(B)>0$, entonces definimos $P_B(A)=\frac{P(A \cap B)}{P(B)}=P(A|B)$

Entonces definimos la esperanza condicionada como:

\[
E_{P_B}(X)=\frac{1}{P(B)}\int_{B}X(w)dP(w)=E(X|B)
\]
\end{defn}

\obs También se escribe $\mathbb{E}(X|Y)$ siendo Y una variable aleatoria. Además $\mathbb{E}(X|Y)$ = $\mathbb{E}(X|\sigma(Y))$ (es sólo notación, queremos decir lo mismo de las dos maneras)


\begin{defn}[Esperanza condicionada (como función de una sub-$\salgb$)]
Dado el espacio de probabilidad $(\Omega, \algb{M}, P)$ y la sub-$\salgb$ $\mathbb{B}\subset\algb{M}$ generada a partir de una partición de $\Omega$ (más adelante veremos que no es necesario que esté generada por una partición, sino que valdrá cualquier  sub-$\salgb$), la esperanza condicionada $\mathbb{E}(X|\algb{B})$ es:
\begin{enumerate}
\item $\algb{B}$-medible
\item $\forall B \in \algb{B}$, $\int_{B}\mathbb{E}(X|\algb{B})dP=\int_{B}XdP$

Estas dos propiedades determinan $\mathbb{E}(X|\algb{B})$ de modo único.
\end{enumerate}
\end{defn}

\obs Cuando definimos $\mathbb{E}(X|\algb{B})$, esto es una función que para cada elemento de la sub-$\salgb$ $\mathbb{B}$ se obtiene un valor dado por la fórmula de la esperanza condicionada vista anteriormente.

\obs Sea $\algb{B}=\sigma(\{A_i\}_{i=1}^{\infty})$, siendo $\{A_i\}_{i=1}^{\infty}$ una partición de $\Omega$ con $P(A_i)>0$. Entonces:
\[
\mathbb{E}(X|\algb{B})(w)=\sum_{i=1}^{\infty}\left( \frac{1}{P(A_i)}\int X(w)dP(w)\right)\ind_{A_i(w)}=\sum_{i=1}^{\infty}\mathbb{E}(X|A_i) \ind_{A_i}
\]

\obs $\norm{Y}_p^p = \mathbb{E}(\abs{Y}^p)$
\begin{proof}
\[
\norm{Y}_p = \int \abs{Y}^pdP =\mathbb{E}(\abs{Y}^p)
\]
\end{proof}



\begin{example}
Sea X e Y variables aleatorias. Dado $(\Omega, \algb{M}, P)$, siendo $\Omega$ la población de un lugar, y siendo $\algb{M}$ una $\salgb$.

X = estatura de una población, tal que $X(w)=x \forall w \in \Omega$

Y = sexo de esa misma población, tal que $Y(w)=1$ si w es mujer, e $Y(w)=0$ si w es hombre.

Definimos la sub-$\salgb$ $\algb{B}=\{\emptyset, \Omega, \{Y=1\}, \{Y=0\}\}$, de manera que $\algb{B} \subset \algb{M}$, y por tanto contiene menos información.
\end{example}

De esta manera, hemos visto que es posible definir la esperanza condicionada ($\mathbb{E}(X|\algb(B))$) cuando $\algb(B)$ esta generada por una partición de $\Omega$. Sin embargo no toda sub-$\salgb$ va a estar generada por una partición. Por ejemplo $Borel(0,1)$ no esta generado por ninguna partición.

Por tanto vamos a definir la esperanza condicionada de otra forma:

\section{Esperanza condicionada como proyección ortogonal en $L^2$}
Recordemos que:

Sea $(\Omega, \algb{M}, \mu)$ un espacio de medida. Para $0<p<\infty$, definimos $L^p=L^p(\Omega,\algb{M},\mu)=\{f:\Omega\rightarrow \mathbb{R}$ ó $\mathbb{C} | \int_X \abs{f}^p d\mu < \infty\}$

En otras palabras: 
$$
\text{si } 0<p<\infty =
  \left\lbrace
  \begin{array}{l}
     f\in L^p(\Omega,\algb{M},\mu) \Leftrightarrow \int \abs{f}^p < \infty \\
     f\in L^{\infty}(\Omega,\algb{M},\mu) \Leftrightarrow \text{supremo esencial } \abs{f} < \infty) \\
  \end{array}
  \right.
$$

El supremo esencial de una función f es:

$supEsencial(f)=sup\{c\geq0:\mu\{\abs{f}\geq c\}>0\}$

Es decir, el valor mayor de f. Por ejemplo, si $f=\frac{1}{x}$ en el intervalo (0,1), $supEsencial(f)=\infty$.

Vamos a definir $\mathbb{E}(X|\algb{B})$ para $X\in  L^2(\Omega,\algb{M},P)$. Utilizamos $L^2$ ya que es un espacio vectorial normado con norma $\norm{X}_2 = (\int_\Omega {X^2 dP})^{\frac{1}{p}}$, y producto escalar que cumple:

$<X,Y> = \int_{\Omega}XYdP$

$\norm{X}=(<X,X>)^{\frac{1}{2}}$

Resumiendo, queremos definir la esperanza condicionada ($\mathbb{E}(X|\algb{B})$), y para ello hemos definido un espacio vectorial $L^2(\Omega,\algb{M},P)$, que esta formado por vectores (las variables aleaorias), por una operación interna (la suma) y por una externa (el producto escalar):
\begin{itemize}
\item Vectores: las variables aleatorias X conformarán los elementos de nuestro espacio vectorial.
\item Producto escalar: $<X,Y> = \int_{\Omega}XYdP$
\end{itemize}

De esto se deduce la norma de un vector, que será: $\norm{X}=(<X,X>)^{\frac{1}{2}}$

Ahora vamos a comprobar que podemos extender la definición a $L^1$, ya que $L^2(P) \subset L^1(P)$. Lo demostramos:

\begin{proof}
Si $f \in L^2(P) \Rightarrow \int f^2 < \infty$.

Escribimos: 
\[
\int \abs{f} = \int \abs{f}\ind_{\{\abs{f}\leq 1\}} + \int \abs{f}\ind_{\{\abs{f}> 1\}}
\]

El primer sumando es menor o igual que 1 ya que estamos integrando una función sobre $\Omega$ y con respecto a P, y P es una medida de probabilidad, que asigna a cada valor un número entre 0 y 1. Por tanto, sabiendo $\int_{\Omega}dP = 1$ (por definición de integral con respecto a una medida y sabiendo que P es una función de probabilidad y que $P(\Omega)=1$), si cogemos los valores de f, que son menores que 1, nos dará un numero menor o igual que 1, que multiplica como mucho a 1:
\[
\int_{\Omega} \abs{f}\ind_{\{\abs{f}\leq 1\}}dP \leq 1
\]

Y el segundo sumando se ve claro que es menor que infinito ya que:
\[
 \int_{\Omega} \abs{f}\ind_{\{\abs{f}> 1\}}dP \leq  \int_{\Omega} f^2 dP < \infty
\]

Por tanto nos queda que:
\[
\int \abs{f} < \infty
\]

Que es precisamente lo que significa que $f\in L^1$
\end{proof}

%\textcolor{red}{Extender el resultado a $L^1$ lo hacemos por que??¿?¿?¿?¿¿, por que así nos basta con funciones $L^1$.}

A partir de ahora nos referiremos con $L^2(\algb{M})$ a $L^2(\Omega,\algb{M},P)$.
Si a partir de ahora empieza a resultar lioso, lo intento explicar con un dibujillo y tal al final.

Ahora vamos a definir la sub-$\salgb$ $\algb{B} \subset \algb{M}$, la cual va a formar un subespacio vectorial $L^2(\Omega,\algb{B},P) \subset L^2(\Omega,\algb{M},P)$. Este subespacio vectorial es cerrado, es decir, una sucesión de elementos dentro del subespacio converge a un elemento dentro del subespacio:
\[
\text{Si} g_n \in L^2(\algb{B}) y \lim_{n \rightarrow \infty} \norm{g_n -f}_2 = 0 \Rightarrow f \in L^2(\algb{B}) 
\]

Definimos ahora la proyección ortogonal de un elemento de $L^2(\algb{M})$ en otro de $L^2(\algb{B})$.
\[
T: L^2(\algb{M}) \rightarrow L^2(\algb{B})
\]
Por tanto, si $X\in L^2(\algb{M})$, tenemos que $X-T(X) \perp L^2(\algb{B})$, o lo que es lo mismo, si $Y \in L^2(\algb{B})$, entonces $<X-T(X),Y>=\int(X-T(X))Y = 0$.

Una vez hemos definido bien T como la proyección ortogonal de un elemento (una variable aleatoria X) del espacio de vectorial $L^2(\algb{M})$ al subespacio vectorial $L^2(\algb{B})$, ahora vamos a demostrar que T es la esperanza condicionada de X con respecto de $\algb{B}$.

Para ello debe cumplir las dos propiedades:
\begin{enumerate}
\item T(X) es $\algb{B}$-medible. Es obvio ya que $T(X) \in L^2(\algb{B})$

\item $\int_B X =\int_B T(X)$  $\forall B \in \algb{B}$

Lo demostramos usando la ortogonalidad: Escogemos un elemento $B \in \algb{B}$, entonces $\ind_{\algb{B}} \in L^2(\algb{B})$. Esto es obvio ya que:
\[
\norm{\ind_B}_2=(\int_{\Omega}\ind_B^2)^{\frac{1}{2}}=\sqrt{P(B)}<\infty 
\]

Y por tanto tenemos que:
\[
0=<X-T(X),\ind_B> = \int_{\Omega}(X-T(X))\ind_B dP= \int_B(X-T(X)) dP= \int_B X dP - \int_B T(X) dP \Rightarrow
\]
\[
\Rightarrow \int_B X dP = \int_B T(X) dP
\]
\end{enumerate}

Vemos que T(X) cumple las condiciones que debe cumplir una función para ser considerada esperanza condicionada. Por tanto, la proyección ortogonal de $L^2(\algb{M})$ en $L^2(\algb{B})$ es $\mathbb{E}(X|\algb{B})$ $\forall X \in \algb{M}$.

Y lo que es más importante, esto se cumple para toda sub-$\salgb$ de $\algb{M}$ y no solo para aquellas que están generadas a partir de una partición.

Además, $\mathbb{E}(X|\algb{B})$ es lineal en $L^2(\algb{M})$ y se cumple que:
\[
\mathbb{E}(aX+Y|\algb{B})=a\cdot\mathbb{E}(X|\algb{B})+\mathbb{E}(Y|\algb{B})
\]

El dibujito prometido, todo lo que se ve es ele spacio vectorial $L^2(\Omega,\algb{M},P)$. La recta azul es el subespacio vectorial $L^2(\Omega,\algb{B},P)$, que como todo subespacio vectorial debe contener al (0,0). Y la recta roja representa la proyección ortogonal de la variable aleatoria X sobre el subespacio vectorial $L^2(\Omega,\algb{B},P)$. Ahora sólo hay que trabajar con los vectores y el producto escalar que hemos definido.
\begin{figure}[h]
\centering
\includegraphics[page=1,scale=0.745]{img/graf1.png}
\end{figure}

\section{Esperanza condicionada usando el Teorema de Radon-Nikodyn}
Teorema de Radon-Nikodyn (caso especial): Sea $(\Omega, \algb{M})$ un espacio medible. Sea P una probabilidad en $\algb{M}$, y sea $\nu$ una medida con signo finita. Entonces, si $\nu<<P$, existe una función medible en $\frac{d\nu}{dP} \in L^1(\Omega, \algb{M}, P)$ tal que $\forall A \in \algb{M}$, $\nu(A)=\int \frac{
d\nu}{dP} dP$.

Así pues vamos a usar este teorema para probar la existencia de la esperanza condicionada ($\mathbb{E}(X|\algb{B})$) para $X \in L^1(\Omega, \algb{M}, P)$ aplicado a $L^1(\Omega, \algb{B}, P)$. Definimos $\nu$ en $\algb{B} \subset \algb{M}$ como $\nu(B)=\int_B XdP$

Recordemos que si $P(B)=0$, entonces $\nu(B)=0$. Que, en ese caso, esto ocurre si y solo si $\nu << P|_{\algb{B}}$. Por el teorema de Radon-Nikodyn existe $\frac{d\nu}{dP} \in L^1(\Omega, \algb{B}, P)$ tal que $\nu(B)=\int_B \frac{d\nu}{dP} dP$ para todo $B \in \algb{B}$. Luego $\mathbb{E}(X|\algb{B})=\frac{d\nu}{dP}$ es la derivada de Radon-Nikodyn y cumple:
\begin{enumerate}
\item es $\algb{B}$-medible.

\item $\int_B X dP =\nu(B) = \int_B \frac{d\nu}{dP} dP$  $\forall B \in \algb{B}$
\end{enumerate}


\subsection{Propiedades}
\begin{enumerate}
\item Linealidad: Si $\alpha$ es una constante $\in \mathbb{R}$ y $X,Y:\Omega \rightarrow \mathbb{R}$ con $X,Y \in L^1(\algb{M})$, entonces $\mathbb{E}(\alpha X + Y|\algb{B})=\alpha\mathbb{E}(X|\algb{B})+\mathbb{E}(Y|\algb{B})$

\begin{proof}
Ambos lados son $\algb{B}$-medibles (por definición de esperanza condicionada). Para demostrarlo vamos a utilizar la linealidad de la integral y la definición de esperanza condicionada(el punto 2: $\forall B \in \algb{B}$, $\int_{B}\mathbb{E}(X|\algb{B})dP=\int_{B}XdP$), entonces:
\[
\int_B \mathbb{E}(\alpha X + Y|\algb{B})dP= \int_B(\alpha X+Y)dP=\alpha\int_B XdP + \int_B YdP= 
\]
\[
=\alpha\int_B \mathbb{E}(X|\algb{B})dP + \int_B \mathbb{E}(Y|\algb{B})dP = \int_B \left(\alpha\mathbb{E}(X|\algb{B}) + \mathbb{E}(Y|\algb{B})\right)dP
\] 
\end{proof}
\item Positividad: Si $X \geq 0 \Rightarrow \mathbb{E}(X|\algb{B})\geq 0$. Equivalentemente si  $X \geq Y \Rightarrow \mathbb{E}(X|\algb{B})\geq \mathbb{E}(Y|\algb{B})$
\begin{proof}
Partimos de una variable aleatoria X que es positiva.

Sea $B=\{\mathbb{E}(X|\algb{B}) < 0\} \in \algb{B}$ (NOTACIÓN: son los w que cumplen eso)

Entonces:
\[
0 \geq  \int_B \mathbb{E}(X|\algb{B})dP = \int_B XdP \geq 0
\]

Y además tenemos que como $\mathbb{E}(X|\algb{B})<0$ en B, entonces $\int_B \mathbb{E}(X|\algb{B})dP=0$, lo que quiere decir que $P(B)=0$.
\end{proof}
\item $\abs{\mathbb{E}(X|\algb{B})} \leq \mathbb{E}(\abs{X}|\algb{B})$

\begin{proof}
Sabemos que podemos descomponer $X=X_+ - X_-$ y $\abs{X}=X_++X_-$, por tanto, aplicando la propiedad de la linealidad, la de $\abs{a-b} \leq |a|+|b|$ y la positividad de la esperanza nos queda que:
\[
\abs{\mathbb{E}(X|\algb{B})}=\abs{\left( \mathbb{E}(X_+|\algb{B}) - \mathbb{E}(X_-|\algb{B}) \right)} \leq \mathbb{E}(X_+|\algb{B})+\mathbb{E}(X_-|\algb{B})= \mathbb{E}(\abs{X}|\algb{B})
\]
 
\end{proof} 
\item $\mathbb{E}(*|\algb{B})$ es una contracción en $L^1(\Omega, \algb{M},P)$, es decir, $\forall X \in L^1(\algb{M})$ se cumple que $\norm{\mathbb{E}(X|\algb{B})}_1 \leq \norm{X}_1$

\obs Se demuestra que esto también se cumple para $L^p$ con $p>1$ más adelante.

\begin{proof}

Recordemos que $\norm{Y}_1 = \mathbb{E}(\abs{Y})$

Usamos la propiedad 3:
\[\norm{\mathbb{E}(X|\algb{B})}_1=
\mathbb{E}(\abs{\mathbb{E}(X|\algb{B})}) \leq \mathbb{E}(\mathbb{E}(\abs{X}|\algb{B})) = \mathbb{E}(\abs{X}) = \norm{X}_1
\]
\end{proof}
\item Teorema de la Convergencia Monótona(TCM) para $\mathbb{E}(X|\algb{B})$:
\[
\text{Si} 0\leq X_n \nearrow X \in L^1 \Rightarrow \lim_{n \rightarrow \infty} \mathbb{E}(X_n|\algb{B}) = \mathbb{E}(X|\algb{B})
\]
En casi todo punto y en $L^1$.

\begin{proof}
Vamos a usar el Teorema de la Convergencia Monótona (TCM) y el Teorema de la Convergencia Dominada (TCD) para integrales (ver anexo).

Sea $Y_n=X-X_n \geq 0$, usando la linealidad de la esperanza vemos que basta probar que $\lim_{n \rightarrow \infty} \mathbb{E}(Y_n|\algb{B})= \lim_{n \rightarrow \infty} \mathbb{E}(X-X_n|\algb{B}) = 0$ casi seguro y en $L^1$.

Por positividad (propiedad 2) tenemos que $Y_n \geq Y_{n+1} \Rightarrow \mathbb{E}(Y_n|\algb{B}) \geq \mathbb{E}(Y_{n+1}|\algb{B})$ luego el límite existe casi seguro porque van disminuyendo hasta 0 como mucho.

Así, sea $Z=\lim_{n \rightarrow \infty} \mathbb{E}(Y_n|\algb{B})$. Veamos que Z=0. Sea $B \in \algb{B}$, entonces:

\[
\int_B ZdP= \int_B \lim_{n \rightarrow \infty}\mathbb{E}(Y_n|\algb{B})dP= \lim_{n \rightarrow \infty}\int_B \mathbb{E}(Y_n|\algb{B})dP = 
\]

El último paso es debido al TCD y a la propiedad 2 y 4. Usamos la propiedad 2 para ver que $0 \leq Y_n \leq X \Rightarrow 0 \leq \mathbb{E}(Y_n|\algb{B}) \leq \mathbb{E}(X|\algb{B})$.  Ahora usamos la propiedad 4 para ver que si $X\in L^1 \Rightarrow \mathbb{E}(X|\algb{B})\in L^1$ porque $\mathbb{E}(*|\algb{B})$ es una contracción. Por tanto podemos aplicar el TCD, ya que X nos hace la función de 'g' en dicho teorema.

Para el siguiente paso lo único que hacemos es aplicar la definición de esperanza condicionada (el punto 2: $\forall B \in \algb{B}$, $\int_{B}\mathbb{E}(X|\algb{B})dP=\int_{B}XdP$):

\[
\lim_{n \rightarrow \infty}\int_B Y_ndP \leq \lim_{n \rightarrow \infty}\int_{\Omega} Y_ndP =
\]

Y otra vez usamos el TCD:
\[
= \int_B \lim_{n \rightarrow \infty} Y_ndP = 0
\]

Ya que $0 \leq X_n \nearrow X$ y por tanto $Y_n = X-X_n \searrow 0 $. Y con esto lo hemos demostrado en casi todo punto.

Ahora vamos a ver que se cumple en $L^1$, es decir que:
\[
\lim_{n \rightarrow \infty} \mathbb{E}(X_n|\algb{B}) - \mathbb{E}(X|\algb{B}) = \lim_{n \rightarrow \infty} \mathbb{E}(X-X_n|\algb{B}) = 0 \text{ en } L^1
\]

Por tanto:
\[
 \lim_{n \rightarrow \infty} \norm{\mathbb{E}(X-X_n|\algb{B})}_1 = \lim_{n \rightarrow \infty} \norm{\mathbb{E}(X|\algb{B}) - \mathbb{E}(X_n|\algb{B})}_1 =
\]
 
\[
= \lim_{n \rightarrow \infty} \mathbb{E}\abs{\mathbb{E}(Y_n|\algb{B})} = \lim_{n \rightarrow \infty} \mathbb{E}(Y_n) \text{ y por el TCD = }  \mathbb{E}(\lim_{n \rightarrow \infty}Y_n)=0
\]
\end{proof}
\item Si X es $\algb{B}$-medible, entonces $\mathbb{E}(XY|\algb{B}) = X\mathbb{E}(Y|\algb{B})$, suponiendo que $XY,Y \in L^1$. 

\obs Como esta definido para funciones en $L^1$, también funciona para funciones en $L^p$ para $p>1$, ya que $L^p \subset L^1$.
\begin{proof}
Empezamos suponiendo que $X=\ind_B$ con $B \in \algb{B}$. Entonces $\forall C \in \algb{B}$ se cumple que:
\[
\int_C \mathbb{E}(\ind_BY|\algb{B})dP = \int_C \ind_BYdP=\int_{C\cap B} YdP =
\]
\[
 =\int_{C\cap B} \mathbb{E}(Y|\algb{B})dP = \int_C \ind_B\mathbb{E}(Y|\algb{B})dP 
\]

Luego:
\[
\mathbb{E}(\ind_BY|\algb{B}) = \ind_B\mathbb{E}(Y|\algb{B})
\]

Una vez demostrado para las X de esa forma es fácil demostrarlo para X de cualquier forma, sólo debemos ir aumentando poco a poco como en demostraciones anteriores.
\begin{itemize}
\item Si X es función simple, tenemos la misma igualdad por linealidad.
\item Si $X \geq 0$, escogemos $S_n$ sucesión de funciones $\algb{B}$-medibles con $S_n\geq 0$ y $S_n \nearrow X$ en casi todo punto (Teorema de aproximación de funciones medibles) y usamos la convergencia monótona.
\item Si X toma valores reales escribimos $X=X_+ - X_-$ y usamos linealidad de $\mathbb{E}(*|\algb{B})$.

\end{itemize}

\end{proof}
\obs Si X es $\algb{B}$-medible, entonces $\mathbb{E}(X|\algb{B})=X$
\begin{proof}
Tres maneras:
\begin{enumerate}
\item Teníamos que la esperanza condicionada ($\mathbb{E}(X|\algb{B})$) cumple que es $\algb{B}$-medible y que
$\forall B \in \algb{B}$, $\int_{B}\mathbb{E}(X|\algb{B})dP=\int_{B}XdP$, y ambas son $\algb{B}$-medibles, quiere decir que son constantes en los mismos conjuntos y además la integral en esos conjuntos vale lo mismo. Por lo tanto esa constante es la misma en las dos funciones.
\item Aplicando la propiedad 6 de las esperanzas condicionadas:
Si X es $\algb{B}$-medible, entonces $\mathbb{E}(XY|\algb{B}) = X\mathbb{E}(Y|\algb{B})$, suponiendo que $XY,Y \in L^1$.
\item Aplicando la definición de esperanza condicionada como proyección ortogonal. Antes dijimos que dada una sub-$\salgb$ $\algb{B} \subset \algb{M}$ un subespacio vectorial $L^1(\algb{B}) \subset L^1(\algb{B})$, entonces el punto más cercano de una variable aleatoria X en $L^1(\algb{M})$ (es decir, X es M-medible)a $L^1(\algb{B})$ (es decir, a una variable aleatoria que sea B-medible), es la proyección ortogonal de X sobre $L^1(\algb{B})$, y este punto coincide con $\mathbb{E}(X|\algb{B})$.

Por tanto, si X ya pertenece a $L^1(\algb{B})$ (es decir, ya es B-medible), su proyección ortogonal con $L^1(\algb{B})$ será el mismo, y por tanto $X=\mathbb{E}(X|\algb{B})$.
\end{enumerate}
\end{proof}

\item Propiedad de la torre de $\mathbb{E}(*|\algb{B})$. Sean $\algb{C} \subset \algb{B} \subset \algb{M}$ $\salgb$s, si $X \in L^ 1(\algb{M})$ entonces:
\begin{itemize}
\item $\mathbb{E}(\mathbb{E}(X|\algb{C})|\algb{B}) = \mathbb{E}(X|\algb{C})$.
\begin{proof}
Por la propiedad 6:
\[
\mathbb{E}(\mathbb{E}(X|\algb{C})|\algb{B}) = \mathbb{E}(\mathbb{E}(X|\algb{C}) \cdot \ind_{\Omega}|\algb{B}) = \mathbb{E}(X|\algb{C}) \cdot \mathbb{E}(\ind_{\Omega}|\algb{B}) = \mathbb{E}(X|\algb{C}) \cdot 1 = \mathbb{E}(X|\algb{C})
\]
\end{proof}
\item $\mathbb{E}(\mathbb{E}(X|\algb{B})|\algb{C}) = \mathbb{E}(X|\algb{C})$.
\begin{proof}
Ambos lados son $\algb{C}$-medibles, así que basta ver que $\forall C \in \algb{C}$, se cumple que $\int_C \mathbb{E}(\mathbb{E}(X|\algb{B})|\algb{C}) = \int_C \mathbb{E}(X|\algb{C})$, que es cierto, aplicando la definición de esperanza condicionada (el punto 2: $\forall B \in \algb{B}$, $\int_{B}\mathbb{E}(X|\algb{B})dP=\int_{B}XdP$):
\[
\int_C \mathbb{E}(\mathbb{E}(X|\algb{B})|\algb{C}) = \int_C \mathbb{E}(X|\algb{B}) = \int_C X = \int_C \mathbb{E}(X|\algb{C})
\] 

El segundo signo igual se debe a que como la $\salgb$ $\algb{C}$ está contenida en $\algb{B}$, entonces por ser $\mathbb{E}(X|\algb{B})$ B-medible se puede hacer ese paso

\end{proof}
\end{itemize}
\item También cumple las versiones condicionales de las desigualdades de Cauchy-Schwarz, Holder y Jensen.
\end{enumerate}

\begin{defn}[Desigualdad de Jensen]
Sean:
\begin{itemize}
\item $X: \Omega \rightarrow I$ (intervalo) una variable aleatoria en $L^1(\Omega, \algb{M},P)$.
\item $\phi: I \rightarrow \mathbb{R}$ convexa, tal que $\phi(X) \in L^1(\Omega,\algb{M},P)$.
\end{itemize}
Entonces:
\[
\phi(\mathbb{E}(X)) \leq \mathbb{E}(\phi(X))
\]

Observaciones:
\begin{enumerate}
\item Fácil de recordar. Escoges $\phi(t)=t^2$ y te queda que: $\phi(\mathbb{E}(X))=(\mathbb{E}(X))^2$ y que  $\mathbb{E}(\phi(X)) = \mathbb{E}(X^2)$. Y sabemos que:
\[
Var(X) = \mathbb{E}(X^2) - (\mathbb{E}(X))^2 \geq 0
\]

Y por tanto: $\mathbb{E}(X^2) \geq (\mathbb{E}(X))^2$
\item Si $\phi$ es cóncava, entonces $\psi = -\phi$ es convexa.
\end{enumerate}
\end{defn}

\begin{defn}[Desigualdad de Jensen (versión condicionada)]
Sean:
\begin{itemize}
\item $X: \Omega \rightarrow I$ (intervalo) una variable aleatoria en $L^1(\Omega, \algb{M},P)$.
\item $\phi: I \rightarrow \mathbb{R}$ convexa, tal que $\phi(X) \in L^1(\Omega,\algb{M},P)$.
\end{itemize}
Entonces:
\[
\phi(\mathbb{E}(X|\algb{B})) \leq \mathbb{E}(\phi(X)|\algb{B})
\]
\end{defn}

\begin{theorem}
$\mathbb{E}(*|\algb{B})$ es una contracción en $L^p(\Omega, \algb{M}, P)$ para $\algb{B}\subset\algb{M}$ y $1\leq p\leq\infty$
\end{theorem}
\begin{proof}
Para $1\leq p < \infty$ usamos Jensen condicional con $\phi(t)=\abs{t}^p$. Sea $X \in L^p$, entonces:
\[
\norm{\mathbb{E}(X|\algb{B})}_p^p = \mathbb{E}(\abs{\mathbb{E}(X|\algb{B})}^p) \leq  \mathbb{E}(\mathbb{E}(\abs{X}^p|\algb{B})) = \mathbb{E}(\abs{X}^p) = \norm{X}_p^p
\]

En el primer y cuarto paso hemos utilizado que:
\[
\norm{Y}_p = \int \abs{Y}^pdP =\mathbb{E}(\abs{Y}^p)
\]

\textcolor{red}{En el tercer paso hemos usado la segunda propiedad de la definición de esperanza condicionada: $\forall B \in \algb{B}$, $\int_{B}\mathbb{E}(X|\algb{B})dP=\int_{B}XdP$. Con $B=\Omega$:
\[
\int_{\Omega}\mathbb{E}(X|\algb{B})dP=\int_{\Omega}XdP \Leftrightarrow \mathbb{E}(\mathbb{E}(X|\algb{B}))=\mathbb{E}(X)
\]
 }

En el segundo paso hemos usado la desigualdad de Jensen condicionada (con lo que hay dentro de la esperanza) ($\phi(\mathbb{E}(X|\algb{B})) \leq \mathbb{E}(\phi(X)|\algb{B})$), con $\phi(t)=\abs{t}^p$ y $t=\mathbb{E}(X|\algb{B})$, de modo que:
\[
\phi(\mathbb{E}(X|\algb{B})) = \abs{\mathbb{E}(X|\algb{B})}^p
\]
\[
\phi(X) = \abs{X}^p 
\]

Con esto concluimos que: $\norm{\mathbb{E}(X|\algb{B})}_p \leq \norm{X}_p$

Para el caso $p=\infty$ hay que probar que $\norm{\mathbb{E}(X|\algb{B})}_{\infty} \leq \norm{X}_{\infty}$. Supongamos que no es cierto:


\textcolor{red}{Completar con los apuntes de Elena o de alguien.}

Supongamos que no es cierto, sea $B=\{\abs{\mathbb{E}(X|\algb{B})}\geq\norm{X}_{\infty}\}$, entonces $B \in \algb{B}$ y $P(B) > 0$, ya que hemos supuesto lo contrario a $\norm{\mathbb{E}(X|\algb{B})}_{\infty} \leq \norm{X}_{\infty}$.

\[
P(B)\norm{X}_{\infty} < \int_B
\]
\end{proof}





\subsection{Trucos con normas, medidas y teoremas}

Conjunto de trucos, y cosas que se pueden usar en los problemas:

\begin{itemize}
\item Sea $\algb{C} \subset \algb{B}$, entonces, si X es $\algb{C}$-medible, también es $\algb{B}$-medible.

\item Sea $0<r\leq s<\infty$, entonces $L^s \subset L^r$, y esto implica que:
\begin{enumerate}
\item  $X \in L^s \Rightarrow X \in L^r$
\item Sea X e Y, si $X \stackrel{L^s}{\rightarrow} Y$, entonces $X \stackrel{L^r}{\rightarrow} Y$
\item Si algo esta definido para funciones el $L^r$ entonces también esta definido para funciones en $L^s$.
\end{enumerate}

\item Desigualdad de Young (ver ejercicio 3.2): para $t, u \ge 0$, y $p,q > 1$ tales que $1/p + 1/q =1$, tenemos $tu \le t^p/ p + u^q/ q$
\item Desigualdad de Hölder (ver ejercicio 3.3): si $f\in L^p$ y $g\in L^q$, entonces $fg\in L^1$, y $\|fg\|_1 \le \|f\|_p\|g\|_q$.
\item Desigualdad de Jensen:
\begin{itemize}
\item $X: \Omega \rightarrow I$ (intervalo) una variable aleatoria en $L^1(\Omega, \algb{M},P)$.
\item $\phi: I \rightarrow \mathbb{R}$ convexa, tal que $\phi(X) \in L^1(\Omega,\algb{M},P)$.
\begin{enumerate}
\item $\phi(\mathbb{E}(X)) \leq \mathbb{E}(\phi(X))$
\item $\phi(\mathbb{E}(X|\algb{B})) \leq \mathbb{E}(\phi(X)|\algb{B})$

\end{enumerate}


\end{itemize}
\item Para $1<r$:
$$\left(\int \abs{f}\right)^r \leq\int \left( \abs{f} \right)^r$$

Esto se tiene por jensen y también por definición de varianza:
\[
Var(X)=\mathbb{E}[(X-\mathbb{E}(X))^2] = \mathbb{E}(X^2) - \mathbb{E}(X)^2 \geq 0
\]
\end{itemize}




\chapter{Martingalas}
El objetivo es modelizar la evaluación de nuestra fortuna cuando jugamos a un juego justo. Lo llamaremos submartingala si el juego es favorable y supermartingala si es desfavorable.

\begin{defn}[Filtración]
Una sucesión de $\salgb$s $\algb{M}_0 \subset \algb{M}_1 \subset \algb{M}_2 \subset ... \subset \algb{M}$, es una filtración.
\end{defn}

\begin{defn}
Una sucesión de variables aleatorias $\{X_i\}_{i=0}^{\infty}$ se dice adaptada a la filtración $\{\algb{M}_i\}_{i=0}^{\infty}$ si $\forall i = 0,1,...$ se tiene que $X_i$ es $\algb{M}_i$-medible.
\end{defn}

\begin{defn}[Martingala]
Dado $X=\{\{X_n\}_{n=0}^{\infty}, \{\algb{M}_n\}_{n=0}^{\infty}\}$, decimos que X es una martingala si cumple:
\begin{enumerate}
\item $\forall n$, $X_n \in L^1(\Omega, \algb{M}. P)$.
\item $\forall n$, $X_n$ es $\algb{M}_n$-medible.
\item $\forall_n$, $\mathbb{E}(X_{n+1}|\algb{M}_n)=X_n$ c.s.
En el caso de submartingalas: $\forall_n$, $\mathbb{E}(X_{n+1}|\algb{M}_n)\geq X_n$ c.s.
En el caso de supermartingalas: $\forall_n$, $\mathbb{E}(X_{n+1}|\algb{M}_n)\leq X_n$ c.s.
\end{enumerate}
\end{defn}

\begin{example}
$Y_n = 1$ si sale cara en el lanzamiento n

$Y_n=-1$ si sale cruz en el lanzamiento n

$P(Y_n=1)=P(Y_n=-1)=\frac{1}{2}$

Definimos $\Omega = \{1,-1\}^{\mathbb{N}\setminus \{0\}}$. Así, un $w \in \Omega$ sería por ejemplo $w=(-1,-1,-1,1,-1)$, donde $Y_3(w)=-1$.

Vemos que las $Y_n$ son variables aleatorias independientes. Así, las ganancias hasta la partida n son $S_n=\sum_{i=1}^{n}Y_i$.

Vamos a tomar la $\salgb$ generada por cada $Y_n$, por tanto: $\algb{M}_1 = \sigma(Y_1)=\sigma\left\{\{1\}\times\prod_{i=2}^{\infty}\{-1,1\},\{-1\}\times\prod_{i=2}^{\infty}\{-1,1\} \right\}$

Y denotamos $\sigma(Y_1, Y_2,...,Y_n)=\sigma(\{Y_1\}\times\{Y_2\}\times ... \times\{Y_n\}\times \prod_{j=n+1}^{\infty}\{-1,1\} : Y_n= 1 \text{ o } -1, k=1,...,n )$.

En ese ejemplo (con $w=(-1,-1,-1,1,-1)$) tenemos que $S_3(w)=-3$ y $S_4(w)=-2$.

Vamos ahora a comprobar que $S=\{S_n, \sigma(Y_1, Y_2,...,Y_n)\}$ es una martingala.
\begin{enumerate}
\item $S_n \in L^1$. Tenemos que ver que: $\norm{S_n} < \infty$:
\[
\norm{S_n}=\mathbb{E}(\abs{S_n})=\mathbb{E}\left(\abs{\sum_{k=1}^{n} Y_k}\right) \leq \mathbb{E}\left(\sum_{k=1}^{n} \abs{Y_k}\right) = n < \infty
\]
\item $S_n$ es $\algb{M}_n$-medible porque $S_n$ sólo depende de $Y_1,Y_2,...,Y_n$ y $\forall k=1,...,n$ tenemos que $Y_k$ es $\sigma(Y_1,Y_2,...,Y_n)$-medible. ($S_n$ es una suma de funciones $\algb{M}_n$-medibles).
\item Usamos la siguiente igualdad (que aún no hemos demostrado): Si U y W son variables aleatorias independientes, entonces $\mathbb{E}(U|W)=\mathbb{E}(U|\sigma(W))=\mathbb{E}(U)$. Tenemos que probar que $\mathbb{E}(S_{n+1}|\algb{M}_n)=S_n$ c.s.
\begin{proof}
$\mathbb{E}(S_{n+1}|\algb{M}_n)= \mathbb{E}(S_{n} + Y_{n+1}|\algb{M}_n) =  \mathbb{E}(S_{n}|\algb{M}_n) + \mathbb{E}(Y_{n+1}|\algb{M}_n) = S_n + 0 = S_n$

Hemos usado que $\mathbb{E}(Y_{n+1}|\algb{M}_n)=0$ porque son independientes y $\mathbb{E}(Y_{n+1}|\algb{M}_n)=\mathbb{E}(Y_{n+1})=0$.

Y hemos usado que $\mathbb{E}(S_{n}|\algb{M}_n)=S_n$ que es así por definición de esperanza condicionada a una $\salgb$ y porque $S_n$ es $\algb{M}_n$-medible. (Observación de la propiedad 6 de esperanzas condicionadas)





Por ejemplo: $S_3(1,1,-1,...)=1$ y $\mathbb{E}(S_4|\algb{M}_3)=S_3$.

\end{proof}
\end{enumerate}
\end{example}

\begin{defn}[Norma de una martingala X]
Para $1 \leq p \leq \infty$, sea una martingala $X=\{X_n\}_{n=1}^{\infty}$ (Recordemos que X es una maringala, pero los $X_i$ son variables aleatorias):
\[
\norm{X}_p = \sup_n \norm{X_n}_p
\]
\end{defn}

\begin{theorem}
Para $1 \leq p \leq \infty$ $X=\{\{X_n\}_{n=1}^{\infty}, \{\algb{A}_n\}_{n=0}^{\infty}\}$ es una martingala (sub, super) en $L^p$, si $\norm{X}_p = \sup_n \norm{X_n}_p < \infty$. 
\end{theorem}

\begin{example}
Consideramos $(\Omega, \algb{A}, P) = ((0,1), Borel, dx)$

Consideramos la sucesión de variables aleatorias $\{X_n\}_{n=1}^{\infty}$, que cumplen que $X_n = 2^n \ind_{(0, \frac{1}{2^n})}$, donde:

$$\mathbb{E}(\abs{X_n})= \int_{(0,1)} 2^n \ind_{(0, \frac{1}{2^n})} dx=1$$

Y por tanto, sea $X=\{X_n\}_{n=1}^{\infty}$ una martingala, tenemos que:

$$\norm{X}_1 = \sup_n \norm{X_n}_1 = \sup_n \mathbb{E}(\abs{X_n}) = 1 < \infty$$

Por tanto X es una martingala en $L^1$.
\begin{proof}
Propiedades 1 y 2 obvias, la 3:

Consideramos $\algb{A}_n=\sigma(X_1,...,X_n)$, entonces, por ejemplo:

\begin{center}
\includegraphics[scale=0.55]{img/grafica1.png}
\end{center}


$$
\mathbb{E}(X_1|\algb{A}_1)(w)
  \left\lbrace
  \begin{array}{l}
     2 \text{ si } w \in (0,\frac{1}{2}) \\
     0 \text{ si } w \in [\frac{1}{2}, 1) \\
  \end{array}
  \right. \text{   }
\mathbb{E}(X_2|\algb{A}_1)(w)
    \left\lbrace
    \begin{array}{l}
       2 \text{ si } w \in (0,\frac{1}{2}) \\
       0 \text{ si } w \in [\frac{1}{2}, 1) \\
    \end{array}
    \right.
$$
$$
\mathbb{E}(X_2|\algb{A}_1)(w) = \mathbb{E}(X_1|\algb{A}_1)(w) = X_1(w) \text{ por ser } X_2 \text{ } \algb{A}_n\text{-medible}
$$

Se cumple que $\algb{A}_n = \sigma(X_1, X_2,...,X_n)$ es una $\salgb$ generada por una partición, de modo que: $\algb{A}_n=\sigma((0,\frac{1}{2}),[\frac{1}{2}, 1),(0,\frac{1}{4}),[\frac{1}{4}, 1), (0,\frac{1}{2^n}),[\frac{1}{2^n}, 1)) = \sigma((0,\frac{1}{2^n}), [\frac{1}{2^n}, \frac{2}{2^n}),...,[\frac{2^n -1}{2^n},1))$

Y se puede aplicar la definición de esperanzas condicionadas a $\salgb$ generadas por particiones:

\[
\mathbb{E}(X_{n+1}|\algb{A}_n)(w)=\sum_{i=1}^{2^n}\left( \frac{1}{P(A_i)}\int X_{n+1}(w)dP(w)\right)\ind_{A_i(w)}
\]

Siendo $A_i$ el intervalo $(\frac{i-1}{2^n}, \frac{i}{2^n})$ y $X_{n+1}$ una variable aleatoria que vale $2^{n+1}$ en el intervalo $(0, \frac{1}{2^{n+1}})$ y 0 en el resto, tenemos que:

$$
\mathbb{E}(X_{n+1}|\algb{A}_n)(w)
  \left\lbrace
  \begin{array}{l}
     \frac{2^{n+1}}{2}=2^n \text{ si } w \in (0,\frac{1}{2^n}) \\
     0 \text{ si } w \in [\frac{1}{2^n}, 1) \\
  \end{array}
  \right. \text{   }
$$

Por tanto nos queda que: $\mathbb{E}(X_{n+1}|\algb{A}_n)=X_n$, y vemos que se cumple la propiedad 3 de las martingalas.

\end{proof}

Sin embargo X no es una martingala en $L^p$ para $p>1$:
\begin{proof}
Hay que ver si $\norm{X}_p = \sup_{n\geq 0}\left(\mathbb{E}(\abs{X_n}^p) \right)^\frac{1}{p} < \infty$. Sin embargo esto no ocurre:

\[
\left(\mathbb{E}(\abs{X_n}^p) \right)^\frac{1}{p} = \left(\int_{0}^{1} 2^{np} \ind_{(0,\frac{1}{2^n})}^p dx\right)^\frac{1}{p} = 2^n \left(\int_{0}^{1} \ind_{(0,\frac{1}{2^n})} dx\right)^\frac{1}{p} = 
\]

\[
= 2^n \left( \frac{1}{2^n} \right)^\frac{1}{p} = 2^{n(1-\frac{1}{p})} = 2^{\frac{n}{q}} \stackrel{n \rightarrow \infty}{\rightarrow} \infty
\]

Siendo q el conjugado de p (1/p + 1/q = 1). Y tenemos que $\norm{X}_{\infty} = \infty$.
\end{proof}

\end{example}

Para entender bien la siguiente definición y teorema, se recomiendo ver el ejercicio 4.6:

\begin{defn}[Tiempo de parada]
Sea $\{\algb{A}_n \}_{n \geq 0}$ una filtración. $T: \Omega \rightarrow \mathbb{N}\cup \{\infty \}$ es un tiempo de parada si $\forall n \geq 0, \{w \in \Omega \text{ tal que } T(w)=n\} \in \algb{A}_n$.
\end{defn}

\begin{theorem}[Teorema de parada opcional de Doob]

Sea $X=\{\{X_n\}_{n=1}^{\infty}, \{\algb{A}_n\}_{n=0}^{\infty}\}$ una martingala. Entonces $\mathbb{E}(X_0)=\mathbb{E}(X_t)$ si se cumple cualquiera de las condiciones siguientes:
\begin{enumerate}
\item $\exists M >0$ tal que $T \leq M$. (es decir, la función T tiene máximo)
\item $\forall n \geq 0$ y casi todo $w \in \Omega$, $\abs{X_n(w)} \leq M$ con $M >0$ fijo.
\item $\mathbb{E}(T)<\infty$ y $\exists M > 0$ tal que para casi todo w y todo n $\abs{X_{n+1}(w) - X_n(w)} \leq M$.
\end{enumerate}
\end{theorem}

\begin{theorem}[Teorema de la convergencia de las martingalas de Doob]

Sea $X=\{\{X_n\}_{n=1}^{\infty}, \{\algb{A}_n\}_{n=0}^{\infty}\}$ una martingala en $L^1$. Entonces $X_{\infty}=\lim_{n \rightarrow \infty} X_n$ existe casi seguro. Y además $\mathbb{E}(\abs{X_{\infty}})<\infty$, luego $P(\abs{X_{\infty}}=\infty)=0$.

\obs  esto no implica que $X_n$ converja a $X_{\infty}$ en $L^1$.

\end{theorem}


\begin{proof}
No lo vamos a demostrar bien, solo algún comentario. Sabiendo que $X_{\infty}=\lim_{n \rightarrow \infty} X_n$ existe, entonces por Fatou:
\[
\mathbb{E}(\abs{X_{\infty}}) = \mathbb{E}(\abs{\lim_{n \rightarrow \infty} X_n}) \leq \mathbb{E}(\lim_{n \rightarrow \infty} \abs{X_n}) = 
\]

\[
= \mathbb{E}(\liminf_{n \rightarrow \infty} \abs{X_n}) \leq \liminf_{n \rightarrow \infty} \mathbb{E}(\abs{X_n}) \leq \sup_n \mathbb{E}(\abs{X_n}) <\infty
\]

Ya que $X \in L^1$

\end{proof}

Ahora vamos a ver el contraejemplo para la observación:
\begin{proof}
Sea X la martingala que hemos visto anteriormente, con $X_n=  2^n \ind_{(0, \frac{1}{2^n})}$, hemos visto que X pertenece a $L^1$. Y tenemos que $\lim_{n \rightarrow \infty} X_n = X_{\infty} = 0$.

Breve nota de por qué ese es el límite: estamos calculando el límite puntual de las funciones $X_n$ y esta claro que si elijo un $\epsilon >0$, para todo x voy a encontrar un $N_{\epsilon x}$ tal que para todo $m \geq N_{\epsilon x}$, se cumple que $X_m(w)$ es 0. Por ejemplo para $x=\frac{1}{4}$, a partir de $X_2$, ya todas las funciones $X_{n>2}$ son 0, es decir $\lim_{n \rightarrow \infty} X(\frac{1}{4})=0$. Por tanto hay convergencia puntual, pero en este caso no la hay uniforme, ya que no para todo $\epsilon$, $X_n(w)<\epsilon$ para todos los w (siempre va a haber un intervalo pequeño en el origen que va a valer bastante, por ejemplo $X_n$ va a valer $2^n$ en el intervalo $(0, \frac{1}{2^n})$. 

Ahora vamos a ver que  $X_n \stackrel{L^1}{\nrightarrow} X_{\infty}$ ya que se tiene que cumplir que $\int_{\Omega} \abs{X_n - X_{\infty}} \rightarrow 0$, y sin embargo:
\[
\lim_{n \rightarrow \infty} \int_{\Omega} \abs{X_n - X_{\infty}} = \lim_{n \rightarrow \infty} \int_{\Omega} \abs{X_n - 0} = \lim_{n \rightarrow \infty} \mathbb{E}(\abs{X_n}) = \lim_{n \rightarrow \infty} 1 = 1
\]

Vemos que no podemos aplicar el TCM ni TCD y escribir: $\lim_{n \rightarrow \infty} \mathbb{E}(\abs{X_n}) =  \mathbb{E}(\abs{\lim_{n \rightarrow \infty} X_n}) = 0$, ya que $X_n$ no es una sucesión creciente ni existe una $g \in L^1$ tal que $\abs{X_n} \leq g$, y por tanto no cumple las condiciones de ninguno de los teoremas.

\textcolor{red}{Preguntar si esto está bien razonado.}
\end{proof}

\begin{theorem}[Teorema de la convergencia de las martingalas de Doob en $L^p$ para p>1]

Sea $X=\{\{X_n\}_{n=1}^{\infty}, \{\algb{A}_n\}_{n=0}^{\infty}\}$ una martingala en $L^p$ con p>1. Entonces:
\begin{itemize}
\item $X_{\infty}=\lim_{n \rightarrow \infty} X_n$ existe casi seguro.
\item $X_n \stackrel{L^p}{\rightarrow} X_{\infty}$.

\item $X_{\infty}$ es $\algb{A}$-medible y $X_n=\mathbb{E}(X_{\infty}|\algb{A}_n)$ 
\end{itemize}
\obs Si $Y \in L^p$ con $1 \leq p \leq \infty$, entonces: $X_n= \mathbb{E}(Y|\algb{A}_n)$ define una martingala. Lo cual es obvio ya que si $Y \in L^p$, la esperanza, que no es mas que una contracción de Y, también pertenecerá a $L^p$. Y \textcolor{red}{completar} 

\end{theorem}

\begin{theorem}
Sea X una martingala en $L^1$, si $X_n \rightarrow X_{\infty}$ en $L^1$, entonces $\mathbb{E}(X_{\infty}|\algb{A}_n)=X_n$.
\end{theorem}
\begin{proof}
Tenemos dos funciones $\algb{A}_n$-medibles, basta probar que $\forall B \in \algb{A}_n$, se cumple que $\int_B X_n = \int_B \mathbb{E}(X_{\infty}|\algb{A}_n) = \int_B X_{\infty}$.

\[
X_n \stackrel{L^1}{\rightarrow} X_{\infty} \Leftrightarrow \lim_{n \rightarrow \infty} \norm{X_{\infty}-X_n}_1=0 \Leftrightarrow 0= \lim_{n \rightarrow \infty} \int_{\Omega}\abs{X_{\infty}-X_n}dP \geq \lim_{n \rightarrow \infty} \int_B \abs{X_{\infty}-X_n}dP\geq
\]

\[
\geq \lim_{n \rightarrow \infty} \abs{\int_B X_{\infty}dP- \int_B X_n dP} \geq 0
\]


Por tanto nos queda que:
\[
\lim_{n \rightarrow \infty} \int_B X_n = \int_B X_{\infty}
\]

Que es lo mismo que decir que:
\[
\lim_{n \rightarrow \infty} \int_B X_n = \lim_{m \rightarrow \infty} \int_B X_{n+m} = \int_B X_{\infty}
\]

Por otro lado hemos visto que: $\mathbb{E}(X_{n+m}|\algb{B}) = X_n$ (ver ejercicio 6 de la hoja 4). Y esto implica (por definición de esperanza condicionada) que $\forall B \in \algb{B}$:
\[
\int_B \mathbb{E}(X_{n+m}|\algb{A}_n)=\int_B X_{n+m} = \int_B X_n 
\]

Aplicamos límites y  lo anterior tenemos lo que buscábamos:
\[
\lim_{m \rightarrow \infty}\int_B X_{n+m} = \lim_{m \rightarrow \infty}\int_B X_{n} \Leftrightarrow \int_B X_{\infty} = \int_B X_n
\]


\end{proof}

\chapter{Teoremas para examen}
Estos teoremas los van a preguntar tal cual en el examen. Los comentarios que estén en azul, no ace falta ponerlos, son sólo explicaciones.

\section{Teorema de convergencia de martingalas de Doob para p=2}
Probar que $\lim_{n \rightarrow \infty}\norm{X_{\infty}-X_n}_2^2$.


Es decir, probamos que $\forall \epsilon > 0$, $\exists N = N_{\epsilon} > 0$ tal que si $n\geq N$, entonces $\int \abs{X_{\infty}-X_n}^2 < \epsilon$. 

Por hipótesis sabemos $\sup \norm{X_n}_2^2 < \infty$ (\textcolor{red}{Esto es porque X es una martingala}), operando:

\[
\sup_n \norm{X_n}_2^2 = \sup_n \norm{X_0 +\sum_{k=0}^{n-1}(X_{k+1}-X_k)}_2^2 = \sup_n \left( \norm{X_0}_2^2 +\sum_{k=0}^{n-1}\norm{X_{k+1}-X_k}_2^2 \right) =
\]
\[
= \norm{X_0}_2^2 +\sum_{k=0}^{\infty}\norm{X_{k+1}-X_k}_2^2 < \infty
\]

El segundo signo igual es debido a Pitágoras más ortogonalidad de los incrementos.

\textcolor{blue}{El tercer signo igual es debido a que el supremo de una suma es el límite cuando n tiende a infinito de esa suma.}

\textcolor{blue}{Ahora vamos a usar que si una suma infinita converge, entonces a partir del sumando n-esimo, la suma del resto de sumandos tiende a 0}

Por tanto $\exists N = N_{\epsilon}$ tal que $\sum_{k=N}^{\infty} \norm{X_{k+1}-X_k}_2^2 < \epsilon$. Entonces $\forall n \geq N$:

\[
\int \abs{X_{\infty}-X_n}^2 = \int \abs{\lim_{j \rightarrow \infty} X_{n+j}-X_n}^2 \leq \lim_{j \rightarrow \infty} \int \abs{ X_{n+j}-X_n}^2 = \lim_{j \rightarrow \infty} \sum_{k=n}^{n+j-1}\int \abs{X_{k+1}-X_k}^2 < \epsilon
\]

Hemos aplicado Fatou en el '$\leq$' y ortogonalidad más pitágoras en el siguiente paso.

\textcolor{red}{Preguntar por qué damos por hecho que el límite existe.}

\textcolor{blue}{El ultimo pase sale de sustituir $\abs{X_{n+j}}$ por $\abs{X_n + \sum_{k=n}^{n+j-1}(X_{n+k}-X_k)}$}


\section{Ley fuerte de los grandes números para variables aleatorias independientes uniformemente acotadas en $L^4$}
Sea $\{X_n\}_{n=1}^{\infty}$ una sucesión de variables aleatorias independientes en $L^4$ tales que $\exists k>0$ con $\norm{X_n}_4 \leq k$ para todo $n \geq 1$. Entonces, para casi todo $w \in \Omega$:

\[
\lim_{n \rightarrow \infty} \frac{1}{n}\sum_{k=1}^{n}\left( X_k(w) - \mathbb{E}(X_k) \right)= 0
\]

Sin pérdida de generalidad podemos suponer que $\mathbb{E}(X_k)=0$ para todo K. Si no, reemplazamos $X_k$ por $Y_k=X_k-\mathbb{E}(X_k)$.

Entonces las variables aleatorias $Y_k$ son independientes y además:
\[
\norm{Y_k}_4 = \norm{X_k - \mathbb{E}(X_k)}_4 \leq \norm{X_k}_4 - \norm{\mathbb{E}(X_k)}_4 \leq k + \abs{\mathbb{E}(X_k)} \leq k + \mathbb{E}(\abs{X_k}) \leq k + \norm{X_k}_4 \leq 2k
\]

\textcolor{red}{la terminará en clase el lunes...}

%\begin{figure}[h]
%\centering
%\includegraphics[page=1,scale=0.745]{img/Dvenn2.png}
%\caption{Ejemplo de partición con n=16}
%\end{figure}

%\centerline{\includegraphics[page=1,scale=0.745]{img/Dvenn2.png}} % scale obtenido empíricamente para que quepa en la página

%\easyimg{img/Dvenn2.png}{El histograma es una aproximación de la función de densidad real en base a la muestra que hemos obtenido.}{lblDensidad}

%\easyimg{img/DensidadAHistograma.png}{El histograma es una aproximación de la función de densidad real en base a la muestra que hemos obtenido.}{lblDensidad}

%\centerline{\includegraphics[page=1,scale=0.745]{pdf/_Solucion_T1P1.pdf}} % scale obtenido empíricamente para que quepa en la página


%\includepdf[pages=2-]{pdf/_Solucion_T1P1.pdf}



\chapter{Hojas de Ejercicios}
\input{tex/ProbII_ejercicios.tex}

\chapter{Examenes}
\input{tex/ProbII_examenes.tex}


\end{document}

