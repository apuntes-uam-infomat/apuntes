\documentclass[nochap]{apuntes}

%
\author{Guillermo Julián Moreno}
\date{2011/2012 - C1}
\title{Cálculo I}
%

\begin{document}

\maketitle
\newpage

\tableofcontents

\newpage

\section{Fundamentos}

\placeholder{Inducción}

\begin{theorem}[Binomio de Newton][Newton!Binomio]
\[ (a+b)^k=\sum^k_{n=0}\comb{n}{k}a^nb^{n-k} \]
\end{theorem}

\subsection{Conjuntos}

Un conjunto es una colección de elementos. Hay tres formas de definirlo:

\begin{enumerate}
\item Enumerar los elementos: $A=\{a,b,c,...\}$.
\item Operaciones con conjuntos: $A=B\cap C$.
\item A través de una fórmula: $A=\{x\in B \tq P(x)\}$
\end{enumerate}

\begin{defn}[Par ordenado]
$(a, b)=\{\{a\},\{a,b\}\}$. 
\end{defn}

\begin{lemma}
$(a,b)=(c,d) \dimplies (a=c) \y (b=d)$.
\end{lemma}

\begin{defn}[Producto cartesiano o directo][Producto\IS cartesiano]
Sean $X$ e $Y$ dos conjuntos. Entonces $X\x Y=\{(a,b\}\tq a\in X\; b\in B\}$.

Si $X$ e $Y$ son finitos, $\#(X\x Y) =\#X \cdot \#Y$
\end{defn}

\subsection{Sucesiones y límites}

Una sucesión es una colección ordenada de números. 

\begin{defn}[Convergencia][Convergencia!de sucesiones]
Una sucesión $x_n$ es convergente a $l$ (o tiene límite $l$) si $\forall \epsilon > 0 \;\exists n_0 \in \nat \tq \forall n > n_0 \;\abs{x_n -l} < \epsilon$.

$n_0$ suele depender del $\epsilon$ que tomemos.
\end{defn}

\begin{theorem}[Teorema del Sandwich o principio de comparación][Teorema!del sándwich]
Sean $a_n,\: b_n, \: c_n$ tres sucesiones, y $a_n\leq b_n \leq c_n \:\forall n$. Si $a_n$ y $c_n$ convergen al mismo límite $\alpha$, entonces $b_n$ tiene límite y es $\alpha$.
\end{theorem}

\begin{prop}[Cálculo de límites]
\[ \lim (a_n \pm b_n) = \lim a_n \pm \lim b_n \]
\[ \lim (a_n b_n) = \lim a_n \cdot \lim b_n \]
\[ \lim \frac{a_n}{b_n} = \frac{\lim a_n}{\lim b_n} \; ;\lim b_n \neq 0\]
\end{prop}

\begin{lemma}
Si $A\neq \emptyset$ entonces $\exists\: \{a_n\} \in A$ monótona creciente tal que $\exists \lim_{n\to\infty} a_n= sup(A)$.\end{lemma}

\begin{defn}[Sucesión de Cauchy][Cauchy!Sucesión de]
Una sucesión $\{a_n\}$ es de Cauchy si $\forall \epsilon > 0 \; \exists n_o \in \nat \tq |y_n-y_{n'}| < \epsilon \; \forall n,n' \geq n_o$.\end{defn}

\begin{prop}Toda sucesión de Cauchy tiene límite.\end{prop}

\begin{defn}[Subsucesión] Dada una sucesión $\{x_n\}$ se dice que $\{y_k\}$ es una subsucesión de $\{x_n\}$ si existen índices $n_1 < n_2 < \cdots < n_k < \cdots$ tales que $y_k=x_{n_k}$.\end{defn}

\begin{theorem}[Principio del palomar]
Sean $A$ y $B$ dos conjuntos tales que $\#(A) < \#(B)$. No existe una aplicación inyectiva entre $A$ y $B$.

Es decir, si tenemos $m$ huecos y tenemos que meter $n>m$ elementos, en algún hueco hay más de un elemento.
\end{theorem}

\begin{theorem}[Teorema\IS de Bolzano-Weierstrass]
Toda sucesión $\{x_n\}$ acotada posee una subsucesión convergente.
\end{theorem}

\begin{proof}
Supongamos que $a_0 ≤ x_n ≤ b_0\; \forall n$. Hay infinitos $\x_n$ distintos. Sea $I_0=[a_0, b_0]$: una de sus dos mitades, que llamaremos $I_1=[a_1,b_1]$, contiene infinitos elementos $x_n$. A su vez, una de sus dos mitades de $I_1$, a la que llamamos $I_2=[a_2, b_2]$, contiene infinitos elementos.

Por recurrencia, existen intervalos $I_0 \subset I_1 \subset \cdots \subset I_k=[a_k, b_k]$ cada uno de los cuales contiene infinitos elementos de la sucesión. Además, la longitud de cada uno es la mitad del anterior. Observamos que $a_0 \leq a_1 \leq \cdots \leq a_k \leq a_{k+a} \leq \cdots \leq b_{k+1} \leq b_k \leq \cdots \leq b_1 \leq b_0$. Luego $\exists \lim_{k\to\infty}a_k =\lim_{k\to\infty}b_k$.

Construimos la subsucesión de forma siguiente. $x_{n_1} \in I_1$, $x_{n_2} \in I_2$ pero con $n_1 < n_2$. Luego $\exists \lim_{k\to\infty} x_{n_k} = \lim_{k\to\infty}a_k =\lim_{k\to\infty}b_k$.
\end{proof}

\begin{corol}Toda sucesión de Cauchy es convergente en $\real$.\end{corol}

\begin{proof}Sea $\{x_n\}$ de Cauchy, luego es acotada. Por el teorema de Bolzano-Weierstrass existe una sucesión convergente $\{x_{n_k}\}$. Por lo tanto $\exists L = \lim_{k\to\infty}x_{n_k}$. Entonces, se tiene que $\exists \lim_{n\to\infty} x_n = L$.\end{proof}

\begin{lemma}La serie $\sum^{\infty}a_n$ converge si $\exists\lim_{n\to\infty}S_n$.\end{lemma}

\section{Funciones}

\begin{defn}[Función]
Una relación $f\subset A\x B$ es función si $\forall x \in A \; \uexists y \in B$. Se denota como $\appl{f}{A}{B}$.
\end{defn}

\begin{defn}[Antiimagen]
Sea \stdf. La antiimagen de un conjunto $B\subset Y$ es 
\[ f^{-1}(B)=\{ x\in X \tq f(x) \in B\}\].
\end{defn}

\begin{remark}No confundir la antiimagen con la función inversa. La antiimagen es sólo con conjuntos, la inversa con elementos. Por ejemplo, si $x$ es un elemento y $X$ es un conjunto, $f^{-1}(f(x))=x$, pero $f^{-1}(f(X))$ no tiene por qué ser igual a $X$. 

Por ejemplo, sea $X=[0,2]$ y $f(x)=x^2$. La imagen de $X$ es $[0,4]$. Sin embargo, la antiimagen de $[0,4]$ es $[-2,2]\neq X$.
\end{remark}

\begin{defn}[Función\IS inyectiva] Una función \stdf es inyectiva si elementos distintos tienen imágenes distintas: $f(x)=f(y) \implies x=y$.
\end{defn}

\begin{defn}[Función\IS sobreyectiva]
Una función \stdf es sobreyectiva si $f(X)=Y$, es decir: $\forall y \in Y \exists x \in X \tq f(x)=y$.
\end{defn}

\begin{defn}[Función\IS biyectiva]
Una funcion es biyectiva si es inyectiva y sobreyectiva.
\end{defn}

\begin{defn}[Función\IS inversa] Sea \stdf una función. La relación inversa es $\appl{f^{-1}}{Y}{X}$, y si es función, se dice que $f^{-1}$ es la inversa de $f$.
\end{defn}

\begin{prop} $f$ es invertible si y sólo si es inyectiva.

\begin{proof}
Para que \stdf sea invertible, $\appl{f^{-1}}{Y}{X}$ tiene que ser función. Es decir, que $\forall y\in Y \uexists x \in X$. Comprobamos primero la existencia de imagen para cualquier elemento de $Y$. Si $f$ es sobreyectiva, entonces tenemos que $Y=f(X)$. Por lo tanto, cualquier elemento de $Y$ tiene una imagen en $X$. Si no fuese sobreyectiva existiría algún elemento en $Y$ que no fuese imagen de un elemento de $X$, así que $f^{-1}$ no sería función.
 
Pasamos ahora a demostrar la unicidad de la imagen para cualquier elemento de $Y$. Si $f$ es inyectiva, tenemos que $\forall x,x' \in X \: f(x)=f(x') \dimplies x=x'$. Cada elemento de $X$ esta relacionado con un sólo un elemento de $Y$, por lo que cada elemento de $Y$ tiene una sola imagen. Si no fuera inyectiva, algún elemento de $Y$ tendría dos imágenes en $X$ y la relación inversa no sería función.
\end{proof}
\end{prop}

\begin{defn}[Composición][Función\IS composición de] Sean $\appl{f}{A}{B}$ y $\appl{g}{C}{D}$, y $f(A)\subset C$. Entonces se define la composición $f$ compuesto con $g$ como $\appl{g\circ f}{A}{D}$, tal que $(g \circ f)(x)=g(f(x)), x \in A$.

La composición de funciones cumple la propiedad asociativa ($(f\circ g)\circ h=f\circ (g\circ h)$).

Si $f$ y $g$ son sobreyectivas, entonces $g\circ f$ también lo es.
\end{defn}

\begin{defn}[Límite] Sea $\appl{f}{A}{\real}, A\subset\real$ se dice que $f$ tiene límte $L$ en el punto $a$ si $\forall \epsilon > 0 \; \exists \delta >0 \tq (x\in A \y |x-a|<\delta) \implies |f(x)-L|<\epsilon$.

Se escribe como \[\lim_{x\to a}f(x)=L\]
\end{defn}

\begin{remark}
No es necesario que $a\in A$.\end{remark}

\begin{defn}[Límite\IS lateral] Se define el límite lateral por la derecha de $\appl{f}{A}{\real}, A\subset\real$ (con valor $L_d$ como aquel que cumple que $\forall  \epsilon >0 \;\exists\delta >0 \tq( x\in A \y |x-a| <\delta \y x>a) \implies |f(x)-L_d|<\epsilon$. La definición de límite lateral por la izquierda es análoga, salvo que $x<a$. 

Los límites laterales por la derecha e izquierda se escriben, respectivamente, como
\[ \lim_{x\to a^{+}}f(x)=L_d\]
\[ \lim_{x\to a^{-}}f(x)=L_i\]
\end{defn}

\begin{defn}[Límite\IS en el infinito] Se dice que $\appl{f}{A}{\real}, A\subset\real$ tiene límite $L$ para $x\to +\infty$ si $\forall \epsilon > 0\; \exists M >0 \tq (x>M\y x\in A)\implies |f(x)-L|<\epsilon$. La definición es análoga cuando $x\to -\infty$, salvo que $x<-M$.

\end{defn}

\begin{theorem}
$f$ tiene límite $L$ en $a$ si y sólo si \underline{toda} sucesión $\{x_n\}\subset dom(f)$ con $\lim_{n\to\infty} x_n=a$ cumple que $\{f(x_n)\}$ forman una sucesión convergente a $L$ ($\lim_{n\to\infty}f(x_n)=L$).
\end{theorem}

\begin{defn}[Continuidad en un punto][Continuidad] Se dice que $\appl{f}{A}{\real}$ es continua en $a$ si cumple que $a\in A \y \exists \lim_{x\to a} f(x) \y \lim_{x\to a} f(x) = f(a)$.\end{defn}

\begin{defn}[Función\IS continua] Una función es continua si lo es en todos los puntos de su dominio.\end{defn}

\begin{theorem}[Lema del sándwich para funciones - Principio de comparación][Teorema\IS del sándwich]
\[(f(x) \leq g(x) \leq h(x) \; \forall x \neq c \y \exists \; \lim_{x\to c}f(x) =\lim_{x\to c}h(x)=L) \implies \exists \lim_{x\to c}g(x) = L\]
\end{theorem}

\begin{proof}
Sea $\{x_n\}$ una sucesión tal que $\neg c \in \{x_n\}$ y $\lim_{n\to\infty}x_n = c$. Entonces, tenemos que $\lim_{n\to\infty}f(x_n)=\lim_{n\to\infty}h(x_n)=L$. Por el lema del sandwich para las sucesiones, tenemos que $f(x_n)\leq g(x_n) \leq h(x_n) \implies \exists \lim_{n\to\infty}g(x_n)=L \implies \exists \lim_{x\to c}g(x) = L$.
\end{proof}

\begin{theorem}[Teorema de los valores intermedios - Teorema de Bolzano][Teorema\IS de Bolzano]
Si $\appl{f}{[a,b]}{\real}$ es continua y $f(a)<f(b)$, $\forall v \in (f(a),f(b)) \:\exists z \in [a,b] \tq f(z)=v$.
\end{theorem}

\begin{proof}
Sea $a_0=a$, $b_0=b$ y $I_0=[a_0, b_0]$. Sea $m_0$ el punto medio de $I_0$. Si $f(m_0)=v$, hemos terminado. Si no, cogemos $I_1$ como la parte izquierda de $I_0$ si $f(m_0) >v$ o la parte derecha si $f(m_0)<v$. 

Por recurrencia encontramos intervalos $I_n=[a_n, b_n]$ tal que $I_0\supset I_1 \supset \cdots \supset I_n$, de forma que $f(a_n)<v<f(b_n)$. Se tiene que $a_0 \leq a_1 \leq \cdots \leq a_n \leq \cdots \leq b_n \leq \cdots \leq b_1 \leq b_0$. $z$ es el límite de $a_n$, que coincide con el límite de $b_n$. Por ser $f$ continua, $f(z)=\lim_{n\to\infty}f(a_n) \leq v$ y $f(z)=\lim_{n\to\infty}f(b_n) \geq v$, por lo tanto $f(z)=v$.
\end{proof}

\begin{defn}[Acotación de funciones][Función!acotada]
Se dice que $\appl{f}{A}{\real}$ está acotada superiormente si $\exists M \tq f(x)\leq M \: \forall x\in A$. La definición es análoga para la cota inferior.
\end{defn}

\begin{theorem}[Teorema\IS de Weierstrass]
\label{thmWeierstrass}
Toda función continua en un intervalo cerrado está acotada y alcanza su máximo y mínimo.
\end{theorem}

\begin{theorem}
Sea $\appl{f}{[a,b]}{\real}$ inyectiva y continua. Entonces, $f$ es estrictamente creciente o decreciente y $\inv{f}$ es continua.
\end{theorem}

\begin{remark}
Esto también quiere decir que\[f([a,b])=[f(a),f(b)]\]
\end{remark}

\begin{proof}
Como $f$ es inyectiva, $\forall a\neq b \; f(a)\neq f(b)$, es decir que $f(a)<f(b)$ o $f(a)>f(b)$. Suponemos el primer caso $f(a)<f(b)$. 

\textit{Previo:} Sabemos que $a<x<b \implies f(a)<f(x)<f(b)$, ya que si $f(a)<f(b)<f(x)$ dado un $v\tq f(b)<v<f(x)$ por Bolzano $\exists x_1\in [a,x];\: x_2\in [x,b] \tq f(x_1)=f(x_2)=v$, contradicción con que la función es inyectiva.

Si la función no fuese estrictamente creciente, entonces $\exists x,y \in [a,b] \tq x<y \:\y\: f(x)>f(y)$. En ese caso, $a<x<y$ y $f(a)<f(y)<f(x)$, lo que es imposible según el argumento previo. 

Demostramos la segunda parte, la continuidad de la inversa. Sea $\epsilon >0, \:x_0\in dom \inv{f} \tq f(x_0)=y_0$, buscamos $\delta \tq |y-y_0|<\delta \implies |\inv{f}(y)-x_0|<\epsilon$. Suponemos que $a<x_0-\epsilon < x_0+\epsilon < b$. Sea $\delta=min(y_0-f(x_0-\epsilon), f(x_0+\epsilon)-y_0)$. Entonces $|y_0-y|<\delta \implies y\in (f(x_0-\epsilon, f(x_0+\epsilon))$ luego $|\inv{f}(y)-x_0|<\epsilon$.
\end{proof}

\subsection{Derivadas}

\begin{defn}[Derivada]
Sea $f$ una función continua. La derivada en un punto $a$ es
\[f'(a)=\frac{df}{dx}(a)=\lim_{x\to a} \frac{f(x)-f(a)}{x-a} \]

Se dice que una $f$ es derivable en $a$ si y sólo si $\exists \lim_{x\to a} \frac{f(x)-f(a)}{x-a}$. 

La derivada en un punto marca la pendiente de la recta tangente a la función en ese punto.
\end{defn}

\begin{prop}
Si $H(x)$ es una recta que pasa por el punto de la gráfica de $f$ $(a, f(a))$ y cumple que \[\lim_{x\to a} \frac{f(x)-H(x)}{x-a}=0\] entonces $f$ es derivable en $a$ y su derivada en ese punto es la pendiente de $H$.\end{prop}

\begin{proof}
Sea $H(x)= f(a)+m(x-a)$. Entonces \[ \frac{f(x)-H(x)}{x-a}=\frac{f(x)-f(a)-m(x-a)}{x-a}=\frac{f(x)-f(a)}{x-a}-m\] que tiende a 0 cuando $x\to a$. Por lo tanto, \[\exists \lim_{x\to a}\frac{f(x)-f(a)}{x-a}=m\].
\end{proof}

\begin{prop}[Cálculo operativo]
Sean $f, g$ derivables en $a$. Entonces 
\begin{itemize}
\item $(f\pm g)'(a)=f'(a)\pm g'(a)$.
\item $(fg)'(a)=f'(a)g(a)+f(a)g'(a)$.
\item Si $g(a)\neq 0 $, $\left(\frac{1}{g}\right)'(a)=\frac{-g'(a)}{(g(a))^2}$.
\item Si $g(a)\neq 0$, $\left(\frac{f}{g}\right)'(a)=\frac{f'(a)g(a)-f(a)g'(a)}{(g(a))^2}$.
\item $(g\circ f)'(a)= g'(f(a))f'(a)$.
\end{itemize}
\end{prop}

\begin{prop}La derivada de una función derivable en un extremo local (máximo o mínimo) vale cero.\end{prop}

\begin{theorem}[Teorema\IS de Rolle]
Sea $\appl{f}{[a,b]}{\real} \tq f(a)=f(b)$ continua en el cerrado y derivable en el abierto. Entonces $\exists c \in (a,b) \tq f'(c)=0$.
\end{theorem}

\begin{proof}
Sólo es necesario buscar un extremo local en $(a,b)$. Por el teorema de Weierstrass (\ref{thmWeierstrass}) $f$ alcanza el máximo y mínimo $x_1, x_2$ en el intervalo $[a,b]$. Si $x_1\in (a,b)$ o $x_2 \in (a,b)$, hemos terminado. Si no, el máximo y mínimo están en los extremos y como $f(a)=f(b)$ $f$ es constante y su derivada siempre vale 0.
\end{proof}

\begin{theorem}[Teorema\IS del valor medio de Lagrange]
Sea $\appl{f}{[a,b]}{\real}$ continua en el cerrado y derivable en el abierto. Entonces, $\exists t \in (a,b) \tq f'(t)=\frac{f(b)-f(a)}{b-a}$.
\end{theorem}

\begin{proof}
Sea \[h(x)=f(x) - f(a)-\frac{f(b)-f(a)}{b-a}(x-a)\]. Es claro que $h(a)=h(b)$, por lo tanto $\exists c \in (a,b) \tq h'(c)=0$. Derivamos $h(x)$:

\[ h'(x)=f'(x) - \frac{f(b)-f(a)}{b-a} \]

Si $h'(c)=0$ 
\begin{align*}
h'(c)&=f'(c)-\frac{f(b)-f(a)}{b-a} \\
0 &= f'(c)-\frac{f(b)-f(a)}{b-a} \\
f'(c)&=\frac{f(b)-f(a)}{b-a}
\end{align*}
\end{proof}

\begin{theorem}[Teorema\IS del valor medio de Cauchy]
Sean $f$ y $\appl{g}{[a,b]}{\real}$ continuas en el cerrado y derivables en el abierto. Entonces $\exists t \in (a,b)$ tal que 
\[ \left(f(b)-f(a)\right)g'(t)=\left(g(b)-g(a)\right)f'(t) \]

Si $g(b)\neq g(a)$ 

\[ \frac{f(b)-f(a)}{g(b)-g(a)}=\frac{f'(t)}{g'(t)} \]

\end{theorem}

\begin{proof}
Sea $h(x)=\left(f(b)-f(a)\right)g'(x)-\left(g(b)-g(a)\right)f'(x)$. Es claro $h(a)=h(b)$, así que $\exists t \in (a,b) \tq h'(t)=0$.
\end{proof}

\begin{lemma}
Sea $\appl{f}{(a,b)}{\real}$ derivable. Si $f'(x)\geq 0$ la función es creciente. 
\end{lemma}

\begin{theorem}[Regla de L'Hopital]
Sean $f$ y $g$ derivables definidas sobre un intervalo abierto $I$ salvo quizás en un punto $a\in I$. Supongamos \begin{enumerate}
\item $g'(t)\neq 0 \forall t \in I$.
\item $\lim_{x\to a}f(x)=\lim_{x\to a}g(x)=0$.
\item $\lim_{x\to a}\frac{f'(x)}{g'(x)}=L$
\end{enumerate}

Entonces \[ \lim_{x\to a}\frac{f(x)}{g(x)}=L \]
\end{theorem}

\begin{lemma}[Resolución indeterminaciones 0/0]
Sean $\appl{f,g}{(a,b)}{\real}$ derivables. Supongamos \begin{enumerate}
\item $\lim_{x}{a^+}{f}=\lim_{x\to a^+}g(x)=0$.
\item $g'(x)\neq 0 \; \forall x \in (a,b)$.
\item $\exists\lim_{x\to a^+}\frac{f'(x)}{g'(x)}=L$.
\end{enumerate}

Entonces, \[ \lim_{x\to a^+}\frac{f(x)}{g(x)}=L \]
\end{lemma}

\section{Polinomios y Teorema de Taylor}
\begin{defn}Se dice que $f(x)$ es $o$ de una función $\varphi(x)$ cuando $x\to a$ (notación: $f(x)=o(\varphi(x)),\; x\to a$) si \[ \lim_{x\to a} \frac{f(x)}{\varphi(x)}=0\]
\end{defn}

\begin{defn}Se dice que $f$ y $g$ tienen orden de contacto superior a $n$ cuando \[f(x)-g(x)=o(|x-a|^n); x\to a\], es decir \[ \lim_{x\to a}\frac{f(x)-g(x)}{(x-a)^n}\].
\end{defn}

En particular, $f$ y su recta tangente tienen orden de contacto superior a 1.

\begin{defn}[Derivada\IS superiore]
Si $f$ es una función derivable en un intervalo $I$ podemos considerar la función derivada $\appl{f'}{I}{\real}$. Si ésta es a su vez derivable, la segunda derivada es $f''(x)$, y así sucesivamente para la n-ésima derivada. \end{defn}

\begin{defn}[Polinomio de Taylor] Sea $f$ $n$ veces derivable en el entorno de un punto $a$. Se define el polinomio de Taylor de orden $n$ asociado a $f$ en el punto $x=a$ como \[ P_n(x)=P_{n,a}f(x)=f(a)+f'(a)(x-a)+\frac{f''(a)}{2!}(x-a)^2+\cdots + \frac{f^{(n)}}{n!}(x-a)^n = \sum_{k=0}^n \frac{d^nf}{dx^{n}} (a)\cdot \frac{(x-a)^n}{n!} \].
\end{defn}

Propiedades del polinomio de Taylor:

\begin{enumerate}
\item $P_n(a)=f(a)$, $P_n^{(k)}(a)=f^{(k)}(a),\; k=1,2,\cdots,n$.
\item $\frac{d}{dx}\left(P_n(f)\right)(x)=P_{n-1}f'(x)$.
\item $f$ y $P_n$ tienen orden de contacto superior a $n$ para $x\to a$.
\item $P_n$ es el único polinomio de grado menor o igual que $n$ con la propiedad anterior.
\end{enumerate}

\begin{proof}
Propiedad 2:
\[\frac{d}{dx}\left(P_n(f)\right)(x)=f'(a)+f''(a)(x-a)+\cdots +\frac{f^{n}(a)}{(n-1)!}(x-a)^{n-1} = P_{n-1,a}f'(x) \].

Propiedad 1: $P_n(a)=f(a)$ es evidente. $P_n^{(k)}=f^{(k)}(a)$ también lo es a partir de la propiedad 2.

\textbf{Propiedad 3}: Usando L'Hopital siempre que el límite exista:

\[ \lim_{x\to a} \frac{f(x)-P_n(x)}{(x-a)^n}=^{0/0}\lim_{x\to a} \frac{f'(x)-P_n'(x)}{n(x-a)^{n-1}}=\cdots=\lim_{x\to a} \frac{f^{(n-1)}(x)-P^{(n-1)}_n(x)}{n!(x-a)} \]

$P_n^{(n-1)}(x)$ es la ecuación de la recta tangente a $f^{(n-1)}(x)$ en $x=a$, así que \[\lim_{x\to a} \frac{f^{(n-1)}(x)-P^{(n-1)}_n(x)}{n!(x-a)}=0\]. 

\textbf{Propiedad 4}: Sea $Q$ un polinomio de grado menor o igual que $n$ que cumpla la propiedad 3. Entonce $P_n - Q$ tiene orden de aproximación superior a $n$ en $x\to a$ porque \[\lim_{x\to a} \frac{P_n(x)-Q(x)}{(x-a)^n}=\lim_{x\to a} \left(\frac{P_n(x)-f(x)}{(x-a)^n}+\frac{f(x)-Q(x)}{(x-a)^n}\right)=0-0=0 \]

Si $P_n(x) - Q(x)$ es un polinomio de grado menor o igual que $n$, entonces \[0=\lim_{x\to a}\frac{R(x)}{(x-a)^n}=\lim_{x\to a}\frac{A_0+A_1(x-a)+\cdots}{(x-a)^n}\], por lo que $A_0=0$. Como $A_0$ es 0, reducimos una potencia y \[\lim_{x\to a}\frac{A_1+A_2(x-a)+\cdots}{(x-a)^{n-1}}\], de forma que $A_1$ es 0 y así sucesivamente cualquier $A_n$ vale 0. Por lo tanto, $R=0$ y $P_n=Q$.
\end{proof}

\begin{theorem}[Teorema\IS de Taylor]
Sea $f$ derivable $(n+1)$ veces alrededor del punto $a$. Entonces, dado un $x\;\exists t \in (a,x)$ tal que 
\[ f(x)-P_n(x)=\frac{f^{(n+1)}(t)}{(n+1)!}(x-a)^{n+1} \].

\end{theorem}

\begin{defn}[Resto] $R_{n,a}f(x)=f(x)-P_{n,a}f(x)$ se denomina resto y el teorema nos da la forma de Lagrange de este resto.\end{defn}

\section{Geometría de gráficas de funciones}

\begin{defn}[Asíntota\IS vertical] Se dice que $f$ tiene una asíntota vertical por la derecha para $x=c$ si $\lim_{x\to c^+}f(x)=\pm \infty$. La definición es análoga para la asíntota vertical por la izquierda.\end{defn}

\begin{defn}[Asíntota\IS oblicua] Se dice que $f$ tiene una asíntota horizontal para $x\to \pm \infty$ si $\lim_{x\to \pm \infty}f(x)=m$.\end{defn}

\section{Integrales}

\subsection{Integral de Riemann}

\begin{defn}[Suma\IS superior e inferior]
La suma superior asignada a una partición $P=\{x_0=a, x_1,\cdots, x_n=b\}$ de un conjunto $[a, b]$ se define como 

\[ S_pf =\sum_{k=1}^{n}(\textit{long.}\; I_k)\sup_{I_k} f \]

De forma análoga, se define la suma inferior (notación $s_pf$).\end{defn}

\begin{defn}[Función\IS integrable]
Dada $\appl{f}{[a,b]}{\real}$ acotada, se dice que $f$ es integrable (Riemann) si
\[ \sup s_pf = inf S_pf \] y se denota por 
\[\int^b_a f\ \equiv \int^b_a f(x) \,\mathrm{d}x\]
\end{defn}

\begin{prop} \[ f\; \text{integrable} \dimplies \forall \epsilon >0, \exists P \;\mathrm{ particion} \tq S_Pf-s_Pf \leq \epsilon\]\end{prop}

\begin{prop} Si $\appl{f}{[a,b]}{\real}$ es continua, entonces es integrable.\end{prop}

\begin{remark}
Algunas funciones con una cantidad numerable de discontuinidades son integrables.
\end{remark}

Propiedades de la integral: Sean $f$ y $g$ dos funciones integrables y $\alpha \in \real$. Entonces se cumplen las siguientes propiedades: \[\sint (f+g) = \sint g + \sint g \]
 \[ \sint \alpha f = \alpha \sint f \]
 \[ f\leq g \implies \sint f \leq \sint g \]
 \[m\leq f \leq M \implies m \leq \frac{1}{b-a}\sint f \leq M \]
 \[ \left|\sint f\right | \leq \sint |f| \]
 \[ c \in (a,b) \implies \sint  f= \int_a^c f + \int_c^b f \]

\begin{prop} Si $f$ no es positiva, entonces llamamos $f_+ = max(f(x),0)$ y $f_- = - min(f(x),0)$. $f$ es integrable si y sólo si $f_+$ y $f_-$ lo son, y \[\sint  f =\sint f_+ -\sint  f_-\]\end{prop}

\begin{defn}[Función\IS Lipschitziana]
Una función es Lipschitziana si para cierta constante $k$ $|f(x) - f(y)| \leq k |x-y|$.\end{defn}

\begin{theorem}
Si $f$ es integrable y acotada, entonces la función $F(x)=\int_a^x f$ es continua y Lipschitziana.
\end{theorem}

\begin{theorem}[Teorema\IS Fundamental del Cálculo]
Si $F$ es continua en $[a,b]$, entonces $F(x)=\int{a}{b}{t}$ es derivable y $F'(x) = f(x)$.
\end{theorem}

\begin{proof}
Fijado $x_0\in (a,b)$ queremos ver que \[\lim_{h\to 0}\frac{F(x_0+h)-F(x_0)}{h}=f(x_0)\].

Usamos que $f$ es continua en $x_0$: dado $\epsilon>0, \; \exists \delta >0 \tq |x_0-t| < \delta \implies |f(x_0)-f(t)| < \epsilon$. Sea $|h| < \delta\; , h>0$. Entonces

\[ \frac{F(x_0+h)-F(x_0)}{h} = \frac{1}{h} \int_{x_0}^{x_0+h}f(t)\;dt \] y \[ f(x_0)-\epsilon \leq \frac{1}{h} \int_{x_0}^{x_0+h}f(t)\;dt \leq f(x_0) + \epsilon\] \[-\epsilon \leq \frac{1}{h} \int_{x_0}^{x_0+h}f(t)\;dt - f(x_0) \leq  \epsilon\]

Por lo tanto el límite existe y es $f(x_0)$.
\end{proof}

\begin{remark}$F(x)$ es una primitiva de $f$ si es continua. 

Si $G(x)$ es otra constante entonces $F(X) = G(X) + C$, donde $C$ es una constante.\end{remark}

\subsection{Integrales impropias}

Usamos los métodos de integración más general cuando $f$ no es acotada o cuando la región de integración no es acotada.

\[ \int_a^\infty f = \lim_{R\to\infty}\int_a^R f(t)\;dt \]

Sean $\varphi(x),\; \psi(x)$ derivables. Entonces 
\[H(x)=\int_{\varphi(x)}^{\psi(x)}f(t)\,dt \] es derivable y su derivable es fácil de hallar si nos damos cuenta de que, si llamamos $F(x)=\int_a^xf(t)\; dt$ entonces $H(x) = F(\psi(x))-F(\varphi(x))$.
\newpage
\printindex
\end{document}
