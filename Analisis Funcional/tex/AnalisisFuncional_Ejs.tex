% -*- root: ../AnalisisFuncional.tex -*-
\newcommand{\hard}{\hspace{-3pt}(\dag)\hspace{5pt}}

Los ejercicios marcados con (\dag) están marcados como de ``dificultad especial'' en las hojas.

\section{Hoja 1}


\begin{problem}
\ppart Probar, usando el \nref{thm:CategoriaBaire}, que $I = \set{x ∈ ℝ \tq x ∉ ℚ} ≠ ∅$ y que, de hecho, $I$ es un \nlref{def:ConjuntoGDelta}.

\ppart Probar que $ℝ$ no es numerable.

\ppart Sea $X = ℤ$ con $\dst(x,y) = \abs{x-y}$. Probar que \sdst es un espacio métrico completo y que, sin embargo, es numerable. ¿Por qué no contradice esto al Teorema de Baire?

\solution

\spart

Sabemos que $ℚ$ es numerable, así que podemos enumerar todos los racionales en una serie $q_1, q_2, \dotsc, q_n, \dotsc ∈ ℚ$. Definimos entonces $X_n = ℝ \setminus \set{q_n}$ como una serie de conjuntos abiertos y densos. La intersección de todos ellos son todos los $x ∈ ℝ$ no racionales, que es el conjunto $I$ que buscábamos. Además, por el \nref{thm:CategoriaBaire}, esa intersección es un $G_δ$ denso en $ℝ$, y por eso mismo es no vacío.

\spart

Si $ℝ$ fuese numerable, entonces podríamos enumerarlo: $ℝ \equiv\set{ x_1, x_2, \dotsc, x_n, \dotsc}$. Por otra parte, los conjuntos formados por un único punto son diseminados, por lo que podríamos definir que $ℝ = \bigcup_{n≥1} \set{x_n}$. Sin embargo, esto entraría en contradicción con el Teorema de Baire, que nos dice que no podemos escribir $X$ como una unión numerable de conjuntos diseminados.

\spart

Para que \sdst sea un espacio métrico completo, toda \nlref{def:SucesionCauchy} ha de converger en el espacio. Que una sucesión sea de Cauchy implica que $∀ε> 0$ existe un $N ∈ ℕ$ tal que si $m,n ≥ N$, entonces $\dst(x_m, x_n)$. La cuestión es que, como estamos en $ℤ$, si tomamos\footnote{Cosa que no sé si podemos hacer.} un $ε < 1$, entonces $\dst(x_m, x_n) = 0$ (no podemos tener distancias fraccionarias entre elementos de $ℤ$). Por lo tanto, por ser de Cauchy llega un momento en el que la sucesión se repite constantemente. El límite será entonces es elemento que se repite, que por ser parte de la misma sucesión está en $ℤ$.

% Triplazo.
Esto no contradice el Teorema de Baire porque en $ℤ$ no hay conjuntos densos, y lo vamos a demostrar. Sea $Y \subsetneq ℤ$ un conjunto cualquiera de $ℤ$, y sea $z ∈ ℤ \setminus Y$. La bola de radio $\sfrac{1}{2}$ centrada en $z$ tiene intersección vacía con $Y$ (no hay ningún entero a distancia $\sfrac{1}{2}$ de $z$), por lo que $Y$ no puede ser denso.

Como no hay conjuntos densos, no puede haber tampoco conjuntos diseminados y por lo tanto sigue cumpliéndose el Teorema de Baire: no podemos escribir $ℤ$ como unión numerable de conjuntos diseminados.
\end{problem}

\begin{problem} \hard Sean $\set{a_n}_n≥1$, $\set{b_n}_{n≥1}$ dos sucesiones de números reales y $a_n$ absolutamente convergente. Probar que:

\ppart La función $f$ dada por \[ f(x) = \sum_{n≥1} a_n φ(b_n) \], con $φ(x) ≝ [x]$ (la parte entera de $x$), es continua y $f ∈ C[0,1]$. Además, la serie que define a $f(x)$ es absolutamente convergente.

\ppart Sea $a_n = 2^{-n}$, $b_n = 2^n$, y $h_m = ε_n 2^{-m}$ con $ε_m = \pm 1$ para todo $m$. Probar que \[ \frac{f(x + h_m) - f(x)}{h_m} = ε_m \sum_{n=1}^{m-1} 2^{m-n} \left(φ(2^n(x+h_m)) - φ(2^nx)\right)\]

\ppart Si escribimos $x = [x] + \sum_{k>0} α_k 2^{-k}$ con $α_k ∈ \set{0,1}$, entonces \[ φ(2^nx) = φ\left(\sum_{l≥1} α_{n +l} · 2^{-l}\right)\] y además $\sum_{l≥1}α_{n +l} · 2^{-l} ∈ [0,1]$. Del mismo modo, \[ φ(2^n(x+h_m)) = φ(ε_m2^{2-m} + \sum_{l≥1} α_{n +l} · 2^{-l})\] y \[ ε_m2^{n-m} + \sum_{k≥1} α_{n +l} · 2^{-l} = \sum_{l≥1} α_{n +l}' · 2^{-l}\], siendo $α_{n+l}' = α_{n+l} + δ_{m-n, k} ε_m$, con $δ_{i,j}$ la delta de Kronecker\footnote{Esto es, $δ_{i,j} = 1$ si $i = j$, y $0$ si $i ≠ j$.}.

\ppart Tomamos $ε_m = (-1)^{α_m}$. Entonces $α_{n+l}' ∈ {0,1}\;∀l≥1$. Fijemos $m > 1$. Entonces $\sum_{l≥1} α_{n+l} 2^{-l}$ y $\sum_{l≥1}α_{n+l} 2^{-l}$ están ambos en la misma mitad del intervalo $[0,1]$. Usar esto para probar que \[ \frac{f(x+h_m) - f(x)}{h_m} = m-1\]

\ppart Del apartado anterior se sigue que $f(x)$ no es diferenciable en ningún $x ∈ ℝ$. Sin embargo, $f$ no está muy lejos de serlo en el sentido siguiente: si $\abs{h} ≤ 1$, entonces $∃ C ∈ (0,∞)$ independiente de $x$ y $h$ tal que \[ \abs{f(x+h) - f(x)} ≤ C\abs{h} \left(1 + \log \frac{1}{\abs{h}}\right) \]

\textbf{Indicación}: Dado $0 < \abs{h} ≤ 1$, existe un único $k ∈ ℕ$ con $2^{-k-1} < \abs{h} <≤ 2^{-k}$. Entonces estimar $f(x+h) - f(x)$ dividiendo la suma en los términos $n < k$ y $n ≥ k$ y estimando cada suma por separado.

\solution


\end{problem}

\begin{problem} Sea \sdst un espacio métrico compacto. Probar que es completo. ¿Es cierto el recíproco?
\solution

Sea $\set{x_n}$ una sucesión de Cauchy en $X$, y sea $\set{ε_n}$ otra sucesión que tiende a $0$. Por ser $\set{x_n}$ de Cauchy, para cada $ε_n$ existe un $M_n ∈ ℕ$ tal que si $m,n ≥ M_n$ entonces $\dst(x_m, x_n) < ε_n$. Equivalentemente, para todo $n ∈ N$ tendremos que $x_n ∈ \bola_{ε_n} (x_{M_n}) = B_n$. Entonces, por ser $X$ compacto existe un subrecubrimiento finito $B_{n_i}$ de $\bigcup B_n$.

Por ser un subrecubrimiento, tendremos que a partir de un cierto $n$ suficientemente grande, las bolas $\bola_{ε_n} (x_{M_n})$ que definíamos antes están estrictamente contenidas en él, por lo que el límite debe de estar ahí también. % Me convence esto más bien poco.

\end{problem}

\begin{problem} \hard Sea $\set{f_n}_{n∈ℕ}$ una familia uniformemente acotada de funciones diferenciables en $[a,b]$, un intervalo compacto de $ℝ$, y cuyas derivadas están uniformemente acotadas.

\ppart Probar que cierta subsucesión $\set{f_{n_j}}$ converge uniformemente a una función $f$ Lipschitz. ¿Es cierto que $f$ es necesariamente diferenciable en todo $[a,b]$?

\ppart Probar que si se omite la condición de que la familia sea uniformemente acotada, existe una sucesión de constantes $c_n$ tales que $f_n - c_n$ converge uniformemente a una función $f$ Lipschitz continua.

\solution

\begin{figure}[hbtp]
\centering
\inputtikz{FuncionLipschitz}
\caption{La idea de la función Lipschitz es que siempre hay un doble cono (el verde) que contiene a toda la función.}
\label{fig:FuncionLipschitz}
\end{figure}

Recordamos la definición de función continua Lipschitz (\fref{fig:FuncionLipschitz}):

\begin{defn}[Función\IS Lipschitz continua] Una función $\appl{f}{(X, \dst_X)}{(Y, \dst_Y)}$ entre dos espacios métricos se dice Lipschitz continua si existen una constante $C ∈ ℝ$, $C ≥ 0$ tal que para todos $x_1, x_2 ∈ X$ se tenga que \[ \dst_Y(f(x_1), f(x_2)) ≤ C \dst_X(x_1, x_2) \]
\end{defn}

\spart

Si la familia de funciones está uniformemente acotada, eso significa que tenemos una cota $0 ≤ C_0 < ∞$ tal que $C_0 > f_n\; ∀n∈ℕ$. Igualmente, si sus derivadas están uniformemente acotadas tenemos que $f_n' < C_1$.

El espacio $C_{[a,b]}$ con la norma del supremo, que es donde vive esta sucesión, es un espacio métrico completo, por lo que existe una subsucesión $\set{f_{n_j}}$ convergente uniformemente a $f ∈ C_{[a,b]}$. Vamos a demostrar ahora que esa $f$ es Lipschitz.

Por otra parte, como las $f_n$ tienen derivada acotada por $C_1$, podemos decir que son funciones Lipschitz con cota $C_1$. Vemos ahora qué ocurre con $\abs{f(x) - f(y)}$ para $x,y ∈ [a,b]$. Fijando un $ε>0$, podemos encontrar un $n ∈ ℕ$ tal que $\abs{f_n(x) - f(x)} < ε$ por ser las $f_{n_j}$ convergentes a $f$. Sumando y restando: \begin{align*}
\abs{f(x) - f(y)} &= \abs{f(x) - f_n(x) + f_n(x) - f(y) + f_n(y) - f_n(y)} \\
&≤ \abs{f(x) -f_n(x)} + \abs{f(y) - f_n(y)} + \abs{f_n(x) - f_n(y)} \\
&≤ ε + ε + C_1\abs{x-y}
\end{align*}, por lo que haciendo tender $ε \to 0$ tenemos que $f$ es Lipschitz con la misma cota $C_1$ de las funciones de la sucesión.

Sin embargo, $f$ no tiene por qué ser necesariamente diferenciable: $f$ sólo es Lipschitz pero Lipschitz no implica diferenciable en todo punto. Por ejemplo, $f(x) = \abs{x}$ es continua Lipschitz pero no es derivable en $x = 0$.


\spart

Suponemos que lo que perdemos es la acotación uniforme, no la acotación de las funciones por separado, más que nada porque si no creo que no se puede demostrar.

Consideramos $C_n$ la cota para la función $n$. Podemos tomar entonces un $K ∈ ℝ^+$ y definimos la sucesión de constantes $c_n = C_n - K$. Entonces $f_n - c_n$ está acotada por $K$ ($f_n < C_n$ y por lo tanto $f_n - c_n < C_n - c_n = K$), y estamos en las condiciones del apartado anterior.

\end{problem}

\begin{problem} Construir en $C_{[0,1]}$ un subconjunto acotado de funciones que no sea un \nlref{def:ConjTotalmenteAcotado}.

\solution


\end{problem}

\begin{problem} Sea \sdst un espacio métrico completo. Demuestra que:

\ppart Si $K ⊂ X$ es cerrado, entonces $K$ es completo.
\ppart Si $K$ es completo y totalmente acotado, entonces es compacto.

\solution

\spart

Fácil: una sucesión de Cauchy en $K$ es convergente en $X$ por ser $X$ completo. Como $K$ es cerrado, su límite ha de estar en $K$, así que $K$ es completo.

\spart


\end{problem}


\begin{problem} Sea $f ∈ C_c(ℝ)$ una función continua en $ℝ$ y de soporte compacto. Fijamos $η ∈ C_c^1 (ℝ)$ con $\int η = 1$, y sea $η_t(x) = tη(tx)$ para $t > 0$. Demuestra que:

\ppart Sea $f_t ≝ f * η_t$. Entonces $f_t \convs[][t] f$ uniformemente.
\ppart $\norm{f_t'}_∞ ≤ C(1+t)$ con $t > 0$ y $C$ finita e independiente de $t$.

\solution

Este ejercicio es una demostración de un teorema conocido sobre familias de aproximaciones de la identidad \citep[Def. III.11, Teorema III.20]{ApuntesVarReal} que viene bien demostrado en \citep[Teoremas 8.14, 8.15]{folland99}. Vamos a demostrarlo todo formalmente.

\begin{defn}[Familia\IS de aproximaciones de la identidad] \label{def:AproxIdentidad} Una familia de aproximaciones de la identidad es una sucesión $\set{ρ_n}_{n∈ℕ}$ de funciones $\appl{ρ_n}{ℝ^N}{ℝ}$ no negativas, infinitamente derivables, de soporte compacto, con $\sop ρ_n ∈ \bola_{\frac{1}{n}} (0)$ y con norma $\norm{ρ_n}_1 = \int_ℝ ρ_n = 1$.
\end{defn}

Esta definición nos vale igualmente para una familia no numerable. Es fácil ver que $η_t$ son una familia de aproximaciones de la identidad, aunque en este caso miramos el límite $t \to ∞$ en lugar de $t \to 0$. No es un cambio relevante.

Vamos ahora con la demostración.

\spart

Demostramos primero que las $η_t$ mantienen la misma integral sobre $ℝ$ que η: \[ \int_{ℝ} η_t(x) \dif x = \int_ℝ tη(tx) \dif x \eqreasonup{$y = tx$} \int_ℝ t · \frac{1}{t} · η(y) \dif y = \int_{ℝ} η(y) \dif y = 1\]

Una vez hecho esto, calculamos la convolución: \[ f_t(x) = \int_ℝ f(x-y) η_t(y) \dif y \]

Por ser $f$ continua podremos acotar su valor en entornos pequeños, esto es, que $∀ ε > 0$ existe un $δ > 0$ tal que $f(y) ∈ \bola_ε(f(x))$ si $x - y ∈ \bola_δ(0)$. Además, dado que las $η_t$ tienen un soporte cada vez más pequeño, esto es, $\sop η_t \convs[][t] \set{0}$, podemos encontrar un $t_ε$ suficientemente grande tal que $\sop η_t ⊆ \bola_δ(0)$ si $t > t_ε$. En este caso podemos acotar y ver que, si $t > t_ε$, entonces \begin{align*}
f_t(x) &= \int_ℝ f(x-y) η_t(y) \dif y \\
&= \int_{\bola_δ(0)} f(x-y) η_t(y) \dif y \\
&≤ \int_{\bola_δ(0)} (f(x) \pm ε) η_t(y) \dif y \\
&= (f(x) \pm ε) \int_{\bola_δ(0)} η_t (y) \dif y = f(x) \pm ε \end{align*}

Haciendo tender $ε \to 0$, $t$ se irá a infinito y tendremos la convergencia uniforme que buscábamos.

\spart

Vamos a usar una propiedad de la convolución, y es la siguiente: dadas $f,g$, entonces \[ \od{f*g}{x} = \od{f}{x} * g = f* \od{g}{x}\]

\end{problem}
