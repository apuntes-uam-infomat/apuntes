\documentclass[bibnumbers, palatino]{apuntes}

\title{Análisis Funcional}
\author{Guillermo Julián Moreno}
\date{15/16 C2}

% Paquetes adicionales
\usepackage{enumitem}
\usepackage{xfrac}
\usepackage{fancysprefs}
\usepackage{tikztools}

\setlist{itemsep=1pt, topsep=5pt}
\bibliographystyle{plainnat}
% --------------------

\begin{document}
\pagestyle{plain}
\maketitle

\tableofcontents
\newpage
% Contenido.

\chapter{Espacios métricos completos}

A lo largo de este curso, vamos a tratar de estudiar las funciones analíticamente, dando una estructura a espacios de funciones y manejándolas de forma abstracta. Una de esas formas en las que van a aparecer los espacios de funciones es la de espacios métricos. Por eso, como introducción a la asignatura veremos ciertos conceptos de topología sobre espacios métricos abstractos que nos servirán más adelante.

\begin{defn}[Métrica] Una métrica $\dst$ en un espacio $X$ es una función $\appl{\dst}{X×X}{ℝ^+}$ que cumple las siguientes propiedades: \begin{enumerate}
\item Simetría: $∀x,y ∈ x$ tenemos que $\dst (x,y) = \dst(y,x)$.
\item Positividad: $\dst(x,y) = 0$ si y sólo si $x = y$. En otros términos, $\dst(x,y) > 0$ siempre que $x ≠ y$.
\item Desigualdad triangular: $∀x,y,z ∈ X\; \dst(x,z) ≤ \dst(x,y) + \dst(y,z)$.
\end{enumerate}
\end{defn}

\begin{defn}[Espacio\IS métrico] Un espacio topológico \stopl es un espacio métrico si la topología \topl está dada por una métrica $\dst$. Es decir, que $U ⊂ X$ es abierto ($U ∈ \topl$) si y sólo si $∀x ∈ U\; ∃δ>0$ con $\bola_δ(x) ⊂ U$, siendo $\bola_δ(x)$ la bola abierta\footnote{Por recordar, $\bola_r(x_0) = \set{x ∈ X \tq \dst(x,x_0) < r}$.} de radio δ centrada en $x$.
\end{defn}

Sobre espacios métricos podemos definir sucesiones, y a su vez ver cuáles de estas convergen para encontrar el espacio métrico completo. Normalmente, la definición de convergencia requiere saber el límite y demostrar que la sucesión converge a él.

\begin{defn}[Sucesión\IS convergente] Sea $\set{x_n}_{n≥1}$ una sucesión en un espacio métrico \sdst. Entonces diremos que $x_n$ tiene límite $x$ (equivalentemente, $\lim_{n\to ∞} x_n = x$) si $∀ε > 0$ existe un $N > 0$ tal que si $n ≥ N$ entonces $\dst(x,x_n) < ε$ o, en otras palabras, que $x_n ∈ \bola_ε (x)$.
\end{defn}

\begin{prop} Dado \sdst un espacio métrico, se cumple que si $x_n \convs x,y$, entonces $x = y$ (es decir, el límite es único). De forma equivalente, se cumple que la topología \topl inducida por la métrica es Hausdorff\footnote{Recordando Topología \citep{ApuntesTopologia}: Si $x≠y$ hay entornos de $x$ e $y$ con intersección vacía. En este caso, se demuestra como consecuencia de la desigualdad triangular.}.
\end{prop}

Sin embargo, hay otra noción de convergencia que podemos usar y que es más fácil de manejar, basada en sucesiones de Cauchy.

\begin{defn}[Sucesión\IS de Cauchy] \label{def:SucesionCauchy} Sea $\set{x_n}_{n≥1}$ una sucesión en un espacio métrico \sdst. Diremos que es de Cauchy si $∀ε> 0$ existe un $N ∈ ℕ$ tal que dados $m,n ≥N$, entonces $\dst(x_m, x_n) < ε$.
\end{defn}

Lo interesante de esta definición es que es ``bastante'' equivalente a la definición de convergencia.

\begin{prop} Si una sucesión $\set{x_n}_{n≥1}$ tiene límite, entonces es de Cauchy.
\end{prop}

\begin{proof} Sea $x = \lim_{n \to ∞} x_n$. Entonces, $∀ε > 0$ existe un $N > 0$ tal que si $n≥N$ entonces $\dst(x_n, x) ≤ \sfrac{ε}{2}$. Si tomamos $m,n≥N$, entonces usando la desigualdad triangular tenemos que $\dst(x_m, x_n) ≤ \dst(x_m, x) + \dst(x, x_n) ≤ ε$.
\end{proof}

Lo de ser ``bastante'' equivalente viene porque según el espacio que consideremos, no siempre se cumple que las sucesiones de Cauchy tengan límite. Sí se cumple lo siguiente:

\begin{prop} Si \sdst es un espacio métrico y $x_n$ es una sucesión de Cauchy en $X$, entonces $x_n$ tiene a lo más un punto de acumulación en $X$.
\end{prop}

En cierto sentido, si tenemos sucesiones de Cauchy que no convergen en el espacio, es como si nos faltase algo: sabemos que esas sucesiones convergen a algo que se nos ha quedado fuera. En general, buscaremos trabajar con espacios en los que esto no ocurra.

\begin{defn}[Espacio\IS métrico completo] Un espacio métrico \sdst se dice completo si toda sucesión de Cauchy tiene exactamente un punto de acumulación. En otras palabras, si toda sucesión de Cauchy converge en el espacio.
\end{defn}

Por ejemplo, $ℝ$ con la distancia habitual es completo (toda sucesión de Cauchy en $ℝ$ tiene límite en $ℝ$). Sin embargo, si tomásemos los racionales con la misma métrica no sería completo (es trivial hacer una sucesión de racionales que converja a un número real).

También es importante ver que la noción de convergencia es métrica, no topológica. Por ejemplo, $(0,1)$ y $ℝ$ son homeomorfos pero $(0,1)$ no es un espacio completo.

Un ejemplo muy simple de espacio métrico $(ℝ^n, \dst(x,y) = \norm{x-y})$, que es completo. Una pequeña variante sería tomar $ℂ^n$, pero nada cambiaría esencialmente.

Podemos construir espacios algo menos triviales. Sea $[a,b] ⊂ ℝ$ un intervalo cerrado y acotado. Consideramos $(C_{[a,b]}, \dst(f,g) = \norm{f-g}_∞)$ el espacio de funciones continuas de $[a,b]$ a $ℂ$ con la norma del supremo (esto es, $\norm{f}_∞ = \sup_{x ∈ [a,b]} \abs{f}$). Este es un espacio métrico completo. Además, se daría que $f_n \convs f$ en este espacio si y sólo si $\norm{f-f_n}_∞ \convs 0$ o, en otras palabras, si $f_n \convs f$ uniformemente en $[a,b]$.

Un concepto relacionado con el de completitud es del de densidad.

\begin{defn}[Conjunto\IS denso] Dado un espacio métrico \sdst y sea $Y ⊂ X$. Se dice que $Y$ es denso si para cualquier $x∈X$ y $∀ε > 0$ se cumple que $\bola_ε(x) ∩ Y ≠ ∅$.
\end{defn}

Como ejemplo canónico, $ℚ$ es denso en $ℝ$. También podemos ver que con $x_0 ∈ X$, entonces $Y = \set{x_0}^c = ℝ \setminus \set{x_0}$ es un abierto denso en $ℝ$.

Vamos ahora con unas cuantas definiciones útiles para categorizar conjuntos en espacios topológicos.

\begin{defn}[Conjunto\IS $F_σ$] Dado un espacio topológico \stopl y un conjunto $Y ⊂ X$, se dice que $Y$ es $F_σ$ si es una unión numerable de cerrados.
\end{defn}

\begin{defn}[Conjunto\IS $G_δ$] \label{def:ConjuntoGDelta} Dado un espacio topológico \stopl y un conjunto $Y ⊂ X$, se dice que $Y$ es $G_δ$ si es una intersección numerable de abiertos.
\end{defn}

Como observación, es fácil ver\footnote{Consecuencia de las leyes de DeMorgan.} que $Y ⊂ X$ es un $F_σ$ si y sólo si $Y^c$ es $G_δ$.

\begin{defn}[Conjunto\IS diseminado] Dado \sdst un espacio métrico y $Y⊂ X$, se dice que es residual o diseminado si $\adh{X}^c$ es denso en $X$.
\end{defn}

\begin{defn}[Conjunto\IS de 1ª categoría de Baire] Dado \sdst un espacio métrico y $Y⊂ X$, se dice que $Y$ es de 1ª categoría de Baire si $Y$ es una unión numerable de conjuntos diseminados.
\end{defn}

\begin{defn}[Conjunto\IS de 2ª categoría de Baire] Dado \sdst un espacio métrico y $Y⊂ X$, se dice que $Y$ es de 2ª categoría de Baire si no es de 1ª categoría.
\end{defn}

Con esto, vamos a por el teorema más importante de este tema.

\begin{theorem}[Teorema\IS de categoría de Baire] \label{thm:CategoriaBaire} Sea \sdst un espacio métrico completo. Entonces:

\begin{enumerate}
\item Si $\set{X_n}_{n≥1}$ es una colección numerable de subconjuntos de $X$ abiertos y densos, entonces la intersección de todos ellos es un $G_δ$ denso en $X$.
\item $X$ es de segunda categoría. En particular, ningún espacio métrico completo se puede escribir como unión numerable de conjuntos diseminados.
\end{enumerate}
\end{theorem}

\begin{proof} Empezamos con la primera sentencia. Dados $x ∈ X$ y $ε > 0$, tenemos que probar\footnote{Complicándonos un poco la vida, porque no sabemos cuál es la intersección de todos los $X_n$ y por lo tanto no podemos ver directamente si es densa o no. Por ejemplo, podría ocurrir que la intersección de dos $X_n$ fuese vacía, así que no podemos decir simplemente que $\bola_ε(x) ∩ W$ es no vacía porque es no vacía con cada uno de los $X_n$.} que $\bola_ε(x) ∩ W ≠ ∅$, siendo $W = \bigcap X_n$; esto es, que $W$ es denso en $X$.

Como $X_1$ es abierto y denso, entonces su intersección con $\bola_ε(x)$ es un abierto (por ser ambos abiertos) y no vacío (por ser $X_1$) denso. En este caso, existe un $x_1 ∈ X_1 ∩ \bola_ε(x)$. Además, por ser esa intersección abierta, existe un $r_1 > 0$ tal que $\adh{\bola_{r_1}(x_1)} ⊂ X_1 ∩ \bola_ε(x)$. Podemos suponer además $r_1 < 1$ (si no lo fuera, tomamos $r_1' = 0.5 · \min\set{1,r_1}$).

De nuevo, como $X_2$ es abierto y denso, $X_2 ∩ \bola_{r_1}(x_1)$ es abierto y no vacío; y por lo tanto existen $x_2 ∈ X_2 ∩ \bola_{r_1}(x_1)$ y un $r_2 ∈ (0, \min\set{r_1, \sfrac{1}{2}})$ de modo que $\adh{\bola_{r_2}(x_2)} ⊂ X_2 ∩ \bola_{r_1}(x_1)$. Tras $n$ pasos análogos, elegimos puntos $x_1, \dotsc, x_n$ y radios $r_1, \dotsc, r_n$ que cumplen que $0 < r_i < \min\set{r_{i-1}, \sfrac{1}{i}}$ y con $\adh{\bola_{r_n}(x_n)} ⊂ X_n ∩ \bola_{r_{n-1}} (x_n)$.

Aquí entra en juego el axioma de elección: de momento hemos cogido $n$ puntos pero queremos asumir que podemos cogerlos para toda la sucesión infinita.

Si cogemos dos índices $i,j > n$, entonces sabemos que $x_i,x_j ∈ \bola_{r_n}(x_n)$, y por lo tanto que $\dst(x_i, x_j) < r_n$. Esto nos lleva a que la sucesión $\set{x_n}_{n≥1}$ es de Cauchy, y por ser \sdst completo el límite de la sucesión existe: $x_n \convs x'$.

Como $x_i ∈ \adh{\bola_{r_n}(x_n)}\;∀i>n$, entonces $x'$ ha de estar en la intersección de todas las $\adh{\bola_{r_n}(x_n)}$, que en particular están metidas dentro de $X_n$. Por lo tanto, $x' ∈ \bigcap X_n = W$ y $x'∈\bigcap \adh{\bola_{r_n}}(x_n)$.

Además, como $x' ∈ \adh{\bola_{r_1}(x_1)} ⊂ \bola_ε(x)$ lo que nos queda es que $\bola_ε(x) ∩ W ≠ ∅$ y por lo tanto la intersección de todos los $X_n$ es no vacía.
\end{proof}

\begin{corol} En un espacio métrico completo, la intersección de cualquier familia numerable de conjuntos $G_δ$ densos es otro $G_δ$ denso.
\end{corol}


\begin{proof} Sea $W ⊂ X$ un $G_δ$ y por lo tanto de la forma $W = \bigcap X_n$, con $X_n ⊂ X$ abiertos. Si $\set{W_n}_{n≥1}$ es una familia numerable de $G_δ$ en $X$ de la forma $W_m = \bigcap X_{m,n}$ abiertos, entonces simplemente vemos que \[\bigcap_{n≥1} W_n = \bigcap_{m≥1} \bigcap_{n≥1} X_{m,n} = \bigcap_{(m,n) ∈ ℕ×ℕ} X_{m,n} \], y como $ℕ×ℕ$ es numerable entonces el \nlref{thm:CategoriaBaire} nos dice que esa intersección es densa si lo es cada uno de esos conjuntos $W_n$.
\end{proof}

Una aplicación de esto es que nos permite probar la existencia de una función $f ∈ C_{[0,1]}$ no diferenciable en ningún punto $x ∈ [0,1]$. De hecho, hay un $G_δ$ denso en $C_{[0,1]}$ con esas características. Para ello, tomamos el espacio $C_{[0,1]}$ con la distancia del supremo.

En otras palabras, lo que podemos decir con eso es que las funciones diferenciables son un conjunto despreciable (en el sentido topológico) dentro de todas las funciones continuas. Sin embargo, necesitaremos ver algunos conceptos nuevos para poder demostrarlo.

\begin{defn}[Función\IS uniformemente continua] \label{def:FuncionUnifCont} Sea \sdst un espacio métrico y $\appl{f}{X}{ℂ}$ continua. $f$ se dice uniformemente continua si y sólo si $∀ε>0$ existe un $δ>0$ tal que $\dst(x,y) < δ \implies \abs{f(x) - f(y)} <ε$, con δ escogido independientemente de $x$ e $y$.
\end{defn}

\begin{defn}[Familia\IS uniformemente equicontinua] \label{def:FamiliaUnifEquicont} Sea \sdst métrico y $\mathcal{F} ⊂ C(X)$ una familia de funciones continuas en $X$. Entonces $\mathcal{F}$ es una familia equicontinua si $∀ε>0\;∃δ>0$ tal que si $\dst(x,y) < δ$, entonces $\abs{f(x) - f(y)} < ε$ para toda función $f ∈ \mathcal{F}$.
\end{defn}

Vamos a hacer ahora la demostración rigurosa de esa proposición.

\begin{prop} \label{prop:ConjDensoNoDifs} Hay un conjunto $G_δ$ denso de funciones $f ∈ C_{[0,1]}$ no diferenciables en ningún punto.
\end{prop}

Para la demostración, necesitamos un lema previo:

\begin{lemma}\label{lem:ConvUnifConDiferenciables} Sea $f ∈ C_{[0,1]}$. Entonces existe una sucesión $\set{f_j}_{j≥1} ⊂ C^1_{[0,1]}$ (funciones continuas y diferenciables) con $\norm{f_j'}_∞ ≤ Cj$, con $0 < C < ∞$ independiente de $j$, y además $f_j \to f$ uniformemente.
\end{lemma}

\begin{proof}[\Fref{lem:ConvUnifConDiferenciables}]
Fijamos $η ∈ C_c^1(ℝ)$ (continua, derivable y de soporte compacto) y con $\int η = 1$. Consideramos \[ η_j (x) = jη(jx) \], y entonces definimos $f_j = \bar{f} * η_j$, con $\bar{f}$ una extensión de $f$ a una función continua y de soporte compacto en $ℝ$.

Es fácil ver que $f_j$ cumple las propiedades pedidas: es derivable (la derivada la podemos ``cargar'' a las $η_j$) y converge a $f$ por ser $η_j$ una familia de aproximaciones de la identidad\footnote{Ver \citep[Def. III.11]{ApuntesVarReal}: se trata de una familia de funciones con soporte cada vez más comprimido que convergen a la delta de Dirac, y que por lo tanto $f * η_j \convs[][j] f$.}.
\end{proof}

\begin{proof} [\Fref{prop:ConjDensoNoDifs}] Para demostrar esta proposición, primero vamos a construir el conjunto de las funciones diferenciables en algún punto. Sobre este conjunto, fácil de manejar, demostraremos que es cerrado y que su complementario es denso, demostrando así que las funciones no diferenciales en ningún punto es un conjunto denso e intersección de abiertos.

\proofpart{$f$ derivable $∈ E_n$}

Para $n = 1,2,\dotsc$ podemos construir conjuntos de la forma \[ E_n = \set{f∈ C_{[0,1]} \tq ∃t ∈ [0,1]\,, \abs{f(t) - f(s)} ≤ n\abs{t-s}\; ∀t,s ∈ [0,1]} \]

Si $f ∈ C_{[0,1]}$ y es diferenciable en algún $s ∈ (0,1)$, podemos probar que $f ∈ E_n$ para algún $n$.

Como $f$ es derivable en $s$, existe un $δ>0$ con $\bola_δ(s) ⊂ [0,1]$ para el cual la derivada está definida. Así, si tomamos otro $t ∈ \bola_δ(s)\setminus\set{s}$, podemos acotar \[ \abs{\frac{f(t) - f(s)}{t - s}} ≤ M \implies \abs{f(t) - f(s)} ≤ M \abs{t-s} \]

Por otra parte, si $t ∉ \bola_δ(s)$, entonces $\abs{t-s} ≥ δ > 0$ y podemos acotar igualmente usando la norma del supremo (como las funciones son continuas en un compacto, la norma del supremo es finita) \[ \abs{\frac{f(t) - f(s)}{t-s}} ≤ \frac{2 \norm{f}_∞}{δ} \]

Juntando ambas cosas y tomando el máximo de las cotas, lo que hemos hecho ha sido demostrar que cualquier función que sea diferenciable en al menos un punto se puede acotar y por lo tanto que está en algún $E_n$ para un $n > \max \set{M, \frac{2\norm{f}_∞}{δ}}$.

Así, lo que tenemos es que el conjunto de funciones diferenciables en algún punto es un subconjunto de $\bigcup_{n≥1}E_n$.

Con esto, lo que vamos a ver es que los $E_n$ son cerrados y diseminados en $C_{[0,1]}$, y por lo tanto $E_n^c$, que es el conjunto de funciones no diferenciables en ningún punto, es un abierto denso.

\proofpart{$E_n$ es cerrado}

Para demostrar que $E_n$ es cerrado, tomamos $\set{f_j}_{j≥1}$ una sucesión en $E_n$ y $f_j \convs[][j] f$ en $C_{[0,1]}$. Queremos comprobar que $f ∈ E_n$, y para ello vemos primero que esa sucesión es una \nlref{def:FamiliaUnifEquicont}, esto es, que $∀ε > 0$ existe un $δ > 0$ tal que si $\abs{t-s} < δ$, entonces $\abs{f_j(t) -f_j(s)} < ε$ para cualquier $j$. Esto lo demostraremos más tarde.

Como $f_j ∈ E_n$, $∃t_j ∈ [0,1]$ tal que $\abs{f_j(x) -f_j(t_j)} ≤ n\abs{x-t_j}\;∀x ∈ [0,1]$. Como $[0,1]$ es compacto, existe una subsucesión $\set{t_{j_k}}$ convergente a un cierto $s ∈ [0,1]$. Consideramos entonces la subsucesión $g_k = f_{j_k}$, que tiene que converger a $f$ igual que lo hace $f_j$. Lo que hemos ganado es que en este caso los puntos $s_k = t_{j_k}$ convergen igualmente.

Con esto podemos tratar de evaluar la diferencia entre $f(x)$ y $f(t_0)$. Podemos reescribirlo simplemente sumando y restando cosas, y después aplicando la desigualdad triangular: \begin{align*} &\hspace{-20pt}\abs{f(x) -f(t_0)} = \\
&=\abs{f(x) - g_k(x) + g_k(x) - g_k(s_k) + g_k(s_k) - g_k(t_0) + g_k(t_0) - f(t_0)} \\
&≤
	\underbracket{\abs{f(x) - g_k(x)}}_{≤\norm{f-g_k}_∞}
+ 	\underbracket{\abs{g_k(x) - g_k(s_k)}}_{≤n\abs{x-s_k}}
+	\underbracket{\abs{g_k(s_k) -g_k(t_0)}}_{}
+ 	\underbracket{\abs{g_k(t_0) - f(t_0)}}_{≤\norm{f-g_k}_∞} \\
&≤
	\underbracket{2\norm{f-g_k}_∞}_{\to 0\; (g_k \to f\text{ unif.})}
+ 	\underbracket{\abs{g_k(s_k) - g_k(t_0)}}_{\to 0}
+ 	\underbracket{n\abs{x-s_k}}_{\to n\abs{x-t_0}} \\
& \convs[][k] n\abs{x - t_0}
\end{align*}, donde para decir que $\abs{g_k(s_k) - g_k(t_0)}$ usamos la equicontinuidad de la sucesión de funciones: sabemos que $∀ε > 0\;∃δ>0$ tal que si $\abs{x-t} < δ$ entonces $\abs{g_k(x) - g_k(t)} < ε$; por lo que si fijamos un $ε > 0$, como $s_k \to 0$ entonces $\abs{s_k - t_0} < δ$ para un $k$ lo suficientemente grande y finalmente $\abs{g_k (s_k) - g_k(t_0)} < ε$, por lo que haciendo tender ε a $0$ ya tenemos que esa resta se va a cero igualmente.

Resumiendo: hemos probado que $\abs{f(x) - f(t_0)} \to n\abs{x-t_0}$, por lo que ese límite $f$ estará en $E_n$ igualmente, así que los $E_n$ son cerrados y por lo tanto sus complementarios $E_n^c$ son abiertos.

\proofpart{$E_n^c$ es denso}

Ahora consideramos $φ(x)$ la función que nos da la distancia de $x$ al entero más próximo. Analíticamente, sería una función períodica de período uno que podemos definir en $[0,1]$ como \[ φ(x) = \begin{cases} x & 0 ≤ x ≤ \sfrac{1}{2} \\ \frac{1}{2} -x & \sfrac{1}{2} ≤ x ≤ 1 \end{cases} \]

Es fácil ver que si $x,y ∈ I_k = \left[\frac{1 + k}{2}, \frac{1 + k + 1}{2}\right]$ con $k ∈ℤ$, entonces $\abs{φ(x) - φ(y)} = \abs{x-y}$.

Podemos definir adicionalmente para $λ>0$ funciones $φ_λ (x) = \frac{1}{λ} φ(λ^2x)$, que cumple que $\norm{φ_λ}_∞ ≤ \frac{1}{2λ}\;∀λ>0$. Estas funciones lo que hacen es aumentar las oscilaciones (φ es una especie de diente de sierra) y reducir su magnitud. En estas funciones,se cumple que si $\abs{x-y} ≤ \frac{1}{2λ^2}$ con $λ^2x , λ^2y ∈ I_k$, entonces \[ \abs{φ_λ(x) - φ_λ(y)} = \frac{1}{λ} \abs{λ^2x - λ^2y} = λ\abs{x-y} \]

Con estas funciones, queremos ver que si $λ_j > C_{j+n}$ entonces $f_j + φ_{λ_j} ∉ E_n$. Si que si tenemos $\abs{x-y} ≤ \frac{1}{2λ^2}$ entonces \begin{align*}
\abs{(f_j + φ_{λ_j})(x) - (f_j + φ_{λ_j})(y)} &= \abs{(φ_{λ_j} (x) - φ_{λ_j}(y)) + (f_j(x) - f_j(y))} \\
&≥ \underbracket{\abs{φ_{λ_j} (x) - φ_{λ_j}(y)}}_{= λ_j\abs{x-y}} - \underbracket{\abs{f_j(x) - f_j(y))}}_{C_{j+n}\abs{x-y} \text{ TVM}} \\
&≥ (λ_j - C_j)\abs{x-y}
\end{align*}

Por lo tanto, cuando $j \to ∞$, $λ_j \to ∞$ y no podemos encontrar nunca un $n$ tal que $f_j + φ_{λ_j} ∈ E_n$.

Tenemos que $f_j \to f$ uniformemente en $[0,1]$, e igualmente $φ_{λ_j} \to 0$ uniformemente en $[0,1]$. Con esto, podemos definir $f_j + φ_{λ_j} ∈ E_n^c$, que converge uniformemente a $f$ en $[0,1]$ y por lo tanto hemos demostrado que $E_n^c$ es denso, y con esto acabamos la demostración.
\end{proof}

\section{Teorema de Ascoli-Arzelá y temas relacionados}

El teorema de Ascoli-Arzelá nos dará una caracterización de los conjuntos compactos en espacios de funciones. Para verlo, primero veremos ciertas caracterizaciones de funciones continuas.

\begin{lemma}[Lema\IS de Weierstrass] \label{lem:Weierstrass} Sea \sdst un espacio métrico compacto y $\appl{f}{X}{ℝ}$ continua. Entonces existe una cierta función $\appl{φ}{[0,∞)}{[0,∞)}$ no decreciente y con la propiedad de que $φ(t) \searrow 0$ cuando $t \searrow 0$ (esto es, $φ(t)$ va monótonamente a $0$ cuando $t$ va monótonamente a $0$), de modo que $∀x,y ∈ X$ tengamos que $\abs{f(x) - f(y)} ≤ φ(\dst(x,y))$.

En particular, $f$ es una \nlref{def:FuncionUnifCont}.
\end{lemma}

Con esto podemos ver una aprte del lema de Ascoli-Arzelá.

\begin{lemma}[Lema\IS de Ascoli-Arzelá] \label{lem:AscoliArzela} Sea \sdst un espacio métrico compacto y $\set{f_n}_{n≥1}$ una sucesión de funciones continuas que convergen uniformemente en $X$. Entonces la familia de todas esas funciones es una \nlref{def:FamiliaUnifEquicont} y equiacotada.

Es decir, que $∀ε>0$ existe un $δ>0$ tal que $∀n ∈ ℕ$ se cumple que si $\dst(x,y) ≤ δ$, entonces $\abs{f_n(x) - f_n(y)} ≤ ε$ (equicontinuidad).

Además, también existe una constante $C < ∞$ tal que $\norm{f_n}_∞ ≤ C\;∀n$ o, equivalentemente, que $\sup_{n≥1} \norm{f_n}_∞ < ∞$ (equiacotación).
\end{lemma}

\begin{proof}

\proofpart{Equiacotación}

Obvio: tenemos una sucesión convergente en un espacio métrico, luego ha de ser acotada.

\proofpart{Equicontinuidad}

Sea $f = \lim_{n\to ∞} f_n$. Por ser la convergencia uniforme y las $f_n$ continuas, tenemos que $f$ es continua en $X$. Por el \nref{lem:Weierstrass}, tenemos que además $f$ es uniformemente continua.

Sean $x,y ∈ X$ y $n ∈ ℕ$: vamos a ver que podemos controlar $\abs{f_n(x) - f_n(y)}$ en función de la distancia entre $x$ e $y$. Podemos reescribir y agrupar: \begin{align}
\abs{f_n(x) - f_n(y)} &= \abs{f_n(x) - f(x) + f(x) - f(y) + f(y) - f_n(y)} \nonumber \\
&≤
	\underbracket{\abs{f_n(x) - f(x)}}_{\norm{f - f_n}_∞}
+ 	\abs{f(x) - f(y)}
+	\underbracket{\abs{f(y) - f_n(y)}}_{\norm{f-f_n}_∞} \nonumber \\
&≤ 2\norm{f-f_n}_∞ + \abs{f(x) -f(y)} \label{eq:LemAscoliArzela:Cota1}
\end{align}

Vamos a acotar los dos sumandos. Para $\abs{f(x)-f(y)}$, dado $f$ es uniformemente continua, tenemos que $∀ε > 0$ existe un $δ_1>0$ tal que si $\dst(x,y) ≤ δ$, entonces $\abs{f(x) - f(y)} ≤ \sfrac{ε}{3}$.

Por el otro lado, como $f_n \to f$ uniformemente en $X$, tenemos que $\norm{f - f_n}_∞ \to 0$. Así, podremos hacer $\norm{f-f_n}_∞$ todo lo pequeño que queramos. Formalmente, para todo $ε> 0$ podremos tomar un $N$ suficientemente grande, tal que si $n ≥ N$ tengamos que $\norm{f - f_n}_∞ ≤ \sfrac{ε}{3}$.

Sólo nos queda juntar ambas cotas para acotar \eqref{eq:LemAscoliArzela:Cota1}. Es decir, hemos demostrado que $∀ε>0$, existen $δ_1 > 0$ y $N > 0$ tales que si $n≥N$ y $\dst(x,y) ≤ δ_1$ tenemos que \[2\norm{f-f_n}_∞ + \abs{f(x) -f(y)} ≤ 2 · \sfrac{ε}{3} + \sfrac{ε}{3} = ε \]

Hemos demostrado la equicontinuidad para un conjunto infinito de funciones, aunque nos hemos dejado unas cuantas por el camino: hemos dicho que se cumple para $n ≥ N$, nos hemos dejado una cantidad finita de funciones $\set{f_1, \dotsc, f_N}$ para las que no hemos demostrado la equicontinuidad.

La cuestión es que son una cantidad finita de funciones continuas en $X$, así por el \nref{lem:Weierstrass} son además uniformemente continuas. Esto será suficiente, ya que toda familia finita de funciones uniformemente continuas es equicontinua.

Para demostrarlo, vemos que  $∀ε>0$ y $∀n = 1, \dotsc, N$, la continuidad uniforme de cada función nos dice que existe un $δ(ε,n)$ tal que si $\dst(x,y) ≤ δ(ε,n)$, entonces $\abs{f_n(x) - f_n(y)} ≤ ε$. Lo que haremos será tomar el mínimo de esos $δ(ε,n)$ de cada función \[ δ_2 = δ(ε) = \min_{1≤n≤N} δ(ε,n) > 0 \], cosa que podemos hacer sin problemas por considerar sólo una cantidad finita.

Finalmente, sólo tenemos que tomar $δ = \min \set{δ_1, δ_2}$, y entonces cumpliremos la condición de equicontinuidad: si $\dst(x,y) ≤ δ$, hemos demostrado que $\abs{f_n(x) - f_n(y)} ≤ ε$.
\end{proof}

\begin{corol} Si $\set{f_n}_{n≥1} ⊂ C(X)$ es una familia de funciones continuas en un espacio métrico compacto \sdst, entonces si $f_n$ tiene algún punto de acumulación en $C(X)$ la familia es equiacotada y equicontinua.
\end{corol}

\begin{defn}[Punto\IS aislado] Dado \stopl un espacio topológico y $x_0 ∈ X$. Se dice que $x_0$ es aislado si existe un entorno $U$ de $x_0$ tal que $U = \set{x_0}$ o, en otras palabras, que $\set{x_0}$ es un abierto.
\end{defn}

\begin{theorem} Si \sdst es un espacio métrico completo y sin puntos aislados, entonces ningún conjunto denso y numerable puede ser un $G_δ$.
\end{theorem}

\begin{proof}
La demostración la haremos por reducción al absurdo.  Sea $E = \set{x_k}_{k∈ℕ}$ numerable y denso en $X$. Supongamos además que $E$ es un $G_δ$, por lo que tenemos que es una intersección numerable de abiertos: \[ E = \bigcap_{n∈ℕ} V_n \], con $V_n$ conjuntos abiertos y densos (han de ser densos porque si no su intersección no sería densa).

Sea $W_n = V_n \setminus \set{x_1, \dotsc, x_n}$. Como $X$ carece de puntos aislados, $\set{x_1, \dotsc, x_n}$ ha de ser cerrado, así que  entonces podemos escribir $W_n = V_n ∩ \set{x_1, \dotsc, x_n}^c$ con $\set{x_1, \dotsc, x_n}^c$ abierto para cualquier $n$ y además denso (el complementario de un único punto es abierto, y además denso por no tener $X$ puntos aislados, así que su unión finita también lo cumple).

Consideramos la intersección de todos los $W_n$: \begin{align*} \bigcap_{n≥1} W_n &= \bigcap_{n≥1} (V_n ∩ \set{x_1, \dotsc, x_n}^c) = \left(\bigcap_{n>1} V_n\right) ∩ \left(\bigcap_{n≥1} \set{x_1, \dotsc, x_n}^c \right) \\ &= E ∩ \left(\bigcup_{n≥1}  \set{x_1, \dotsc, x_n}\right)^c = E ∩ E^c = ∅\end{align*}, contradicción con el \nref{thm:CategoriaBaire}.
\end{proof}

\begin{corol} Si \sdst es un espacio métrico completo y sin puntos aislados, entonces $X$ es no numerable.
\end{corol}

\begin{proof} La primera observación que tenemos que hacer es que si $X$ es métrico y carece de puntos aislados, entonces $X$ no es finito. Si lo fuese, como todo singlete $\set{x} ⊂ X$ es un cerrado y todo abierto $U$ habría de ser unión finita de singletes, entonces cualquier conjunto sería abierto y cerrado, lo que nos llevaría a deducir que $X$ tiene la topología discreta, incompatible con un espacio métrico.

Podemos suponer entonces que $X$ es infinito. Si fuese numerable y por lo tanto pudiésemos escribirlo como $X = \set{x_k}_{k∈ℕ} = \bigcup_{k∈ℕ} \set{x_k}$, unión numerable de conjuntos cerrados y diseminados, que igual que antes contradice el Teorema de Baire.
\end{proof}

\begin{defn}[Espacio\IS separable] Sea \sdst un espacio métrico. Diremos que $X$ es separable si y sólo si existe un $E ⊂ X$ numerable y denso.
\end{defn}

Un ejemplo sencillo de espacio separable es $ℝ^n$, con $ℚ^n ⊂ ℝ^n$ como subconjunto denso y numerable. Pero también lo son las funciones continuas $C_{[a,b]}$ con la norma $\dst(f,g) = \norm{f-g}_∞$.

\begin{defn}[Aplicación\IS contractiva] \label{def:ApplContractiva} Una aplicación $\appl{F}{(X, \dst_X)}{(Y, \dst_y)}$ se dice contractiva si $∀x_1, x_2 ∈ X$ se tiene que $\dst_Y(F(x_1), F(x_2)) < \dst_X(x_1, x_2)$.
\end{defn}

\begin{defn}[Aplicación\IS estrictamente contractiva] \label{def:ApplEstrContractiva} Una aplicación $\appl{F}{(X, \dst_X)}{(Y, \dst_y)}$ se dice contractiva si existe una constante $ 0 ≤ λ ≤ 1$ tal que $∀x_1, x_2 ∈ X$ con $x_1 ≠ x_2$ se tiene que $\dst_Y(F(x_1), F(x_2)) < λ \dst_X(x_1, x_2)$.
\end{defn}

\begin{theorem}[Teorema\IS del punto fijo de Banach] Sea \sdst un espacio métrico completo y $\appl{F}{X}{X}$ una \nlref{def:ApplContractiva}. Entonces $F$ tiene a lo más un punto fijo $x_0$ para el cual $F(x_0) = x_0$.

Si además $F$ es estrictamente contractiva, entonces $F$ tiene exactamente un punto fijo.
\end{theorem}

\begin{proof} La existencia es sencilla de demostrar. Sean $x_0 ≠ x_1$ puntos fijos de $F$. En ese caso, $\dst(F(x_0), F(x_1)) < \dst(x_0, x_1)$ por ser $F$ contractiva, pero como ambos son puntos fijos nos queda que $\dst(x_0, x_1) < \dst(x_0, x_1)$, contradicción.

Para demostrar la existencia cuando la aplicación es estrictamente contractiva, primero fijamos un $x_0 ∈ X$ y definimos \[ x^k = F^{(k)} (x_0),\qquad F^{(k)} = \underbracket{F ○ \dotsb ○ F}_{k \text{ veces}} \]

Entonces, estudiamos la distancia entre dos puntos $x_{k+l}, x_k$. \begin{align}
\dst(x_{k+l}, x_k) & = \dst(F^{(k-l)}(x_0), F^{(k)}(x_0)) \nonumber \\
&≤ λ \dst (F^{(k+l-1)}(x_0), F^{(k-1)}(x_0)) ≤ \dotsb ≤ λ^k\dst (x_l, x_0) \label{eq:PtoFijoBanach:Cota1}
\end{align}

Usando la desigualdad podremos estimar esa distancia entre $x_l$ y $x_0$: \[ \dst(x_l, x_0) ≤ \dst(x_l, x_{l-1}) + \dst(x_{l-1}, x_0) ≤ \sum_{i = 0}^{l-1} \dst(x_{i+1}, x_{i})\], donde cada distancia se podrá estimar como $\dst(x_{i+1}, x_i) ≤ λ^{i} \dst(x_1, x_0)$, así que nos quedaría una suma infinita que podemos calcular por ser $λ ∈ [0,1)$ \[ \dst(x_l, x_0) ≤ \sum_{i = 0}^{l-1} \dst(x_{i+1}, x_{i}) ≤ \dst(x_1, x_0) \sum_{i=0}^{l-1} λ^i = \dst(x_1, x_0) \frac{1}{1-λ} \]

Con esta cota y la de \eqref{eq:PtoFijoBanach:Cota1}, podemos decir que \[ \dst(x_{k+l}, x_l) ≤  \frac{λ^k}{1-λ} \dst(x_1, x_0)\quad ∀k,l ∈ ℕ \]

Como $λ^k \convs[][k] 0$ por ser $λ ∈ [0,1)$, tenemos que la sucesión $\set{x_k}_{k≥1}$ es de Cauchy en $X$, y por ser este espacio completo existirá el límite $x = \lim x_k ∈ X$. Sólo nos falta ver que ese $x$ es un punto fijo.

Lo primero es ver que, por ser $F$ contractiva, ha de ser continua. Además, la distancia también es continua como consecuencia de la desigualdad triangular.

Con todo eso podemos escribir \[ \dst(F(x), x) = \lim_{k \to ∞} \dst(F(x_k), x_k) = \lim_{k\to ∞} \dst(x_{k+1}, x_k) \]

Operando, podemos llegar a $\dst(x_{k+1}, x_k) ≤ λ^k \dst(x_1, x_0)$. Lo malo es que los límites no se llevan bien con las desigualdades. Por suerte, como tanto $λ$ como $\dst$ son positivas, podemos considerar simplemente el límite superior y entonces \[ \dst(F(x), x) ≤ \lim_{k\to ∞} \dst(x_{k+1}, x_k) ≤ \limsup_{k\to ∞} λ^k \dst(x_1, x_0) = 0\], por lo que $\dst(F(x), x) = 0$ y nos queda que $F(x) = x$.
\end{proof}

\begin{defn}[Conjunto\IS relativamente compacto] \label{def:ConjRelCompacto} Sea \stopl un espacio topológico y sea $K ⊂ X$ un subconjunto de $K$. $K$ se dice relativamente compacto si $\adh{K}$ es compacto.
\end{defn}

Por ejemplo, $ℚ ∩ [0,1]$ es relativamente compacto: si lo cerramos, nos queda $[0,1]$ que es compacto en $ℝ$.

\begin{defn}[Conjunto\IS totalmente acotado] \label{def:ConjTotalmenteAcotado} Sea \sdst un espacio métrico y $K ⊂ X$. Se dice que $K$ está totalmente acotado si y sólo si $∀ε > 0$ existe una sucesión $x_1, \dotsc, x_N ∈ X$ tales que $K ⊆ \bigcup_{j=1}^N \bola_ε(x_j)$.
\end{defn}

Es fácil ver que si un conjunto es totalmente acotado, está también acotado. Además, en $ℝ^n$ con la métrica usual, un conjunto acotado es equivalente a ser totalmente acotado y a ser relativamente compacto.

No es difícil de demostrar: si $K ⊂ ℝ^n$ es acotado, entonces existe un $0 < R < ∞$ tal que $K ⊆ \bola_R (0) ⊆ \adh{\bola_R(0)}$. Como $\adh{\bola_R(0)}$ es compacta, para cualquier recubrimiento por bolas de radio $ε$ podremos encontrar un subrecubrimiento finito y por lo tanto estará totalmente acotado. Por otra parte, si ya está acotado, su cierre será cerrado y por lo tanto compacto en $ℝ^n$, luego $K$ es relativamente compacto.

La idea de que un conjunto en $ℝ^n$ es compacto si es cerrado y acotado tiene una generalización a espacios métricos genéricos.

\begin{theorem}[Teorema\IS de Heine-Borel] \label{thm:HeineBorel} Sea \sdst un espacio métrico completo y $K ⊂ X$. Entonces $K ⊂ X$ es compacto si y sólo si es cerrado y totalmente acotado.
\end{theorem}

\begin{proof}

\proofpart{Compacto $\implies$ cerrado y tot. acotado}

Si $K$ es compacto, entonces podemos construir un recubrimiento abierto $U = \set{\bola_ε(x_k)}_{x_k ∈ K}$ del que, por compacidad, podemos extraer un subrecubrimiento finito tal que $K ⊂ \bigcup_{k = 1}^N \bola_ε x_k$, luego $K$ es totalmente acotado.

Por otra parte, si $K$ es compacto entonces también es cerrado. Si no lo fuese, podríamos construir una sucesión de Cauchy $\set{x_k}_{k ∈ ℕ} ⊆ K$ con límite $x ∈ X$ ($X$ es completo) pero $x ∉ K$. En ese caso, sea $δ_k = \dst(x, x_k)$ y consideramos el conjunto $U = \set{\bola_{\sfrac{δ_k}{2}} (x_k)}$. Puede no ser un recubrimiento, pero siempre podremos completarlo a un recubrimiento trivialmente, cuidándonos de no coger conjuntos que ya hayamos cubierto.

La cuestión es que de este recubrimiento no podemos quitarnos nada, porque si lo hiciésemos nos dejaríamos elementos fuera del recubrimiento.


\proofpart{Compacto $\impliedby$ cerrado y tot. acotado}

Si $K$ es cerrado y totalmente acotado, consideramos $\set{x_n}_{n≥1}$ una sucesión $K$. Queremos probar que existe una subsucesión convergente $\set{x_{n_j}}_{n≥1}$ convergente a un $x ∈ K$.

Por ser $K$ totalmente acotado, entonces existe una serie de puntos $y_1^1, \dotsc, y_{N_1}^1 ∈ X$ tales que $K ⊂ \bigcup_{j=1}^{N_1} \bola_1 (y_j^1)$.

Podemos ver que existe alguna bola entre las anteriores que contiene infinitos términos de la sucesión $\set{x_n}$. Digamos que esa bola es $\bola_1(y_1^1)$.

Ahora, $K ∩ \bola_1(y_1^1)$ sigue siendo totalmente acotado, ya que $k$ lo es, así que podemos repetir el procedimiento con una serie de puntos $y_1^2, \dotsc, y_{N_2}^2 ∈ X$ con $K ∩ \bola_1(y_1^1)⊂ \bigcup_{j=1}^{N_2} \bola_{\sfrac{1}{2}} (y_j^2)$ y tal que $\bola_{\sfrac{1}{2}} (y_1^2)$ contiene infinitos términos de la sucesión.

Así, encontraremos tras $n$ pasos una sucesión de puntos $z_i = y_1^i$ con $i = 1, \dotsc, n$ tal que $K ∩ \bola_1(z_1) ∩ \dotsb ∩ \bola_{\sfrac{1}{n}} (z_n)$ contiene infinitos términos de la sucesión $\set{x_n}$.

Para cada $j ∈ ℕ$, escogemos $x_{n_j} ∈ K ∩ \bola_1(z_1) ∩ \dotsb ∩ \bola_{\sfrac{1}{j}} (z_j)$. Si $k, j ∈ℕ$ y $k > j$, entonces $x_{n_j}, x_{n_k} ∈ \bola_{\sfrac{1}{j}} (z_j)$ luego $\dst(x_{n_j}, x_{n_k}) < \sfrac{2}{j}$, que tiende a cero cuando $j\to ∞$. Por tanto, esta sucesión que hemos generado es de Cauchy en $X$, por lo tanto convergente a $x$ por ser $X$ completo.

Por otra parte, $x_{n_j} ∈ K$ y como $K$ lo suponemos cerrado, $x ∈ K$. Luego hemos generado una subsucesión convergente a un elemento de $K$, y entonces $K$ es compacto. Nota: en algún momento tendrá que explicar que esta es una caracterización de compactos en espacios métricos, que es que podemos extraer una subsucesión convergente en el compacto de toda sucesión en él.

\end{proof}

\begin{theorem}[Teorema\IS de Ascoli-Arzelá] \label{thm:AscoliArzela} Sea \sdst un espacio métrico compacto, y sea $C(X)$ el espacio de funciones continuas en $X$ con la norma del supremo: $\dst(f,g) = \norm{f -g}_∞ = \sup_{x∈X} \abs{f(x) - g(x)}$. Consideramos una familia $\mathcal{F} ⊂ C(X)$ de funciones. $\mathcal{F}$ será relativamente compacta (\fref{def:ConjRelCompacto}) si y sólo si es equiacotada y equicontinua (\fref{def:FamiliaUnifEquicont}).
\end{theorem}

\begin{proof}

\proofpart{Compactidad relativa $\implies$ equiacotación, equicontinuidad}

Si $\set{f_n}_{n≥1}$ es una sucesión en $\mathcal{F}$ y este conjunto es relativamente compacto, entonces existe una subsucesión $\set{f_{n_j}}_{j≥1}$ convergente en $C(X)$. Aplicando el \nref{lem:AscoliArzela}, deducimos que esa subsucesión es una familia equicontinua y equiacotada. Si $\mathcal{F}$ no fuera igualmente equiacotada y equicontinua, podríamos elegir a priori una sucesión $\set{f_n}$ de manera que se violara equiacotación y equicontinuidad.

\proofpart{Compactidad relativa $\impliedby$ equiacotación, equicontinuidad}

Sea $\mathcal{F}$ una familia semiacotada y equicontinua. Para ver que $\mathcal{F}$ es relativamente compacta, basta ver que es totalmente acotada usando que $C(X)$ es completo y aplicando el \nref{thm:HeineBorel}.

Fijamos $ε > 0$. Puesto que $\mathcal{F}$ es equicontinua, $∀x ∈ X$ existe un cierto $δ_x > 0$ tal que $\abs{f(x) -f(y)} < \frac{ε}{4}$ si $\dst(x,y) < δ_x$ para cualquier $f ∈ \mathcal{F}$.

Ahora, por compacidad de $X$, podemos dar puntos $x_1, \dotsc, x_n ∈ X$ tales que $X$ está contenido en la unión de bolas $\bola_{δ_j} (x_j)$, donde $δ_j = δ_{x_j}$. Si $y ∈ \bola_{δ_j} (x_j)$, entones inmediatamente $\abs{f(x) - f(x_j)} ≤ \sfrac{ε}{4}$.

Sea $F = \set{f(x_i) \tq 1 ≤ j ≤ N, \, f ∈ \mathcal{F}} ⊂ ℂ$. Dado que $\mathcal{F}$ es equiacotada, entonces $F ⊂ ℂ$ ha de ser acotado igualmente. Entonces, como en $ℂ$ acotado implica totalmente acotado, existen $z_1, \dotsc, z_k ∈ ℂ$ tales que $F ⊂ \bigcup^k \bola_{\sfrac{ε}{4}} (z_i)$.

Consideramos ahora el conjunto $Φ$ de todas las posibles aplicaciones \[ \appl{φ}{\set{x_1, \dotsc, x_N} ⊂ X}{\set{z_1, \dotsc, z_k} ⊂ ℂ} \] y, por pura combinatoria, tenemos que $\abs{Φ} ≤ k^N$, un número de combinaciones finito.

Fijada una aplicación φ, consideramos $\mathcal{F}_φ = \set{f ∈ \mathcal{F} \tq f(x_j) ∈ \bola_{\sfrac{ε}{4}} (φ(z_j))}$. Cada $f$ está en un $\mathcal{F}_φ$ y sólo en uno.

Ahora, si tenemos $f,g ∈ \mathcal{F}_φ$ y $x ∈ \bola_{δ_j} (x_j)$ para algún $j ∈ \set{1, \dotsc, N}$, entonces podemos acotar la diferencia de ambas funciones por \begin{align*}
\abs{f(x) - g(x)} &≤
	\abs{(f(x) - f(x_j)) + (f(x_j) - φ(x_j)) + (φ(x_j) - g(x_j)) + (g(x_j) - g(x))} \\
&≤ 	\underbrace{\abs{f(x) - f(x_j)}}_{≤ \sfrac{ε}{4}}
+	\underbrace{\abs{f(x_j) - φ(x_j)}}_{≤ \sfrac{ε}{4}}
+	\underbrace{\abs{φ(x_j) - g(x_j)}}_{≤ \sfrac{ε}{4}}
+	\underbrace{\abs{g(x_j) - g(x)}}_{≤ \sfrac{ε}{4}} \\
&≤ 	ε
\end{align*} y se ve que con esto ya está. % TODO: WTF.

\end{proof}

\chapter{Espacios de Banach}

\section{Introducción y motivación}

Ejemplo: $C^1([a,b])$ con norma supremo.

\begin{defn}[Norma] \label{def:Norma} Sea $V$ un espacio vectorial sobre un cuerpo \kbb (para nosotros, $\kbb = ℝ$ o $ℂ$). Una función $\appl{\norm{\cdot}}{V}{ℝ^+ = [0,∞)}$ es una norma si cumple las siguientes propiedades:

\begin{enumerate}
\item \textbf{Homogeneidad}: $∀x ∈ V$ y $∀λ∈\kbb$, $\norm{λx} = \abs{λ}\norm{x}$.
\item \concept{Desigualdad\IS triangular}: $∀x,y ∈ V$, $\norm{x+y} ≤ \norm{x} + \norm{y}$.
\item \textbf{Positividad}: $∀x ∈ V^* = V \setminus \set{0}$, $\norm{x} > 0$.
\end{enumerate}
\end{defn}

\begin{defn}[Espacio\IS vectorial normado] El par $(V, \norm{·})$ de un espacio vectorial con la norma es un espacio vectorial normado.
\end{defn}

La norma nos define automáticamente una distancia $\dst(u,v) = \norm{u - v}$, de tal forma que todo espacio vectorial normado es un espacio métrico y por lo tanto también topológico.

Si omitimos la condición de positividad en la definición de norma, lo que tenemos es una \concept{Seminorma}. En ese caso, el espacio dado por $W = \set{v ∈ V \tq \norm{v} = 0}$ es un subespacio vectorial\footnote{Prueba rápida: si $w ∈ W$ entonces $\norm{λw} = 0$ luego $λw ∈ W$; y si $u, v ∈ W$ entonces $0 ≤ \norm{u+v} ≤ \norm{u} + \norm{v} ≤ 0$, luego $\norm{u+v} = 0$ y $u+v ∈ W$.}).

¿Cómo podemos usar esto? Antes hemos visto que $C^1([a,b])$ se puede considerar como espacio vectorial, pero es quizás demasiado restrictivo porque sólo vemos funciones continuas y derivables. Lo que podemos hacer es construir un espacio de funciones más genérico y que además en el futuro nos resultará más flexible. Consideraremos \meds un espacio de medida, y estudiaremos las funciones medibles ahí. Para eso, primero damos una definición de la norma de una función:

\begin{defn}[Norma\IS $p$] Dado \meas un espacio de medida y $\appl{f}{X}{ℂ}$, entonces definimos su norma $p$ (o $p$-norma) para $1 ≤ p ≤ ∞$ como \[ \norm{f}_p =
\begin{cases}\displaystyle\left(\int_X \abs{f}^p \dif μ\right)^{\frac{1}{p}} & 1 ≤ p < ∞ \\ \\
\displaystyle\essup_{x ∈ X} \abs{f(x)} & p = ∞ \end{cases} \], donde $\essup$ es el supremo esencial.
\end{defn}

Por si acaso, definimos el supremo esencial:

\begin{defn}[Supremo\IS esencial] \citep[Def I.9]{ApuntesVarReal} Sea $\appl{f}{X}{ℝ}$ una función y \meas nuestro espacio de medida habitual. Definimos entonces el supremo esencial como \[ \essup_{x∈X} f(x) = \inf \set{a ∈ ℝ \tq μ\left(\inv{f}((a, ∞))\right) = 0} \]

En otras palabras, es el mayor valor de $f$ tal que por encima sólo hay un conjunto de valores de medida cero.
\end{defn}

Ahora pasamos a definir el espacio de funciones $p$-integrables, que es el espacio de las funciones medibles con $p$-norma finita.

\begin{defn}[Espacio\IS $\mathcal{L}^p(X)$] Dado \meas un espacio de medida, definimos el espacio de funciones $p$-integrables como \[ \mathcal{L}^p(X) = \set{\appl{f}{X}{ℂ} \tq \norm{f}_p < ∞} \]
\end{defn}

La cuestión es que sobre este espacio, la $p$-norma no es una norma sino una seminorma: una función que no es nula sólo en un conjunto de medida 0 tiene $p$-norma $0$, pero no es la función 0. Para salvar este problema, definimos una relación de equivalencia $\sim$ de la siguiente forma: \( f \sim g \iff \pnorm{f-g} = 0 \label{eq:RelEquivMedidacero}\)

En otras palabras, consideramos que dos funciones son la misma si son iguales salvo en un conjunto de medida 0. Ahora podemos tomar el cociente y definir el espacio $L^p$ con el que trabajaremos habitualmente.

\begin{defn}[Espacio\IS $L^p(X)$] Dado \meas un espacio de medida y $\sim$ la relación de equivalencia de \eqref{eq:RelEquivMedidacero}, definimos \[ L^p(X) = \quot{\mathcal{L}^p(X)}{\sim} \] o, en otras palabras, el espacio de clases de funciones que sólo difieren en un conjunto de medida 0.
\end{defn}

Ahora, la $p$-norma sí es una norma ($\norm{f}_p = 0$ si y sólo si $f(x) = 0$ en casi todo punto, que es un único elemento en $L^p$) y por lo tanto $L^p(X)$ es un espacio normado.

Con esto, podemos ir a definir lo que es un espacio de Banach:

\begin{defn}[Espacio\IS de Banach] Si $(V, \norm{\cdot})$ es un espacio normado y $V$ es completo en la métrica inducida por la norma, entonces se dice que es un espacio de Banach.
\end{defn}

Por ejemplo, $C^1([a,b])$ con norma $\norm{f}_V = \norm{f}_∞ + \norm{f'}_∞$ es un espacio de Banach (no lo es si $\norm{f}_V = \norm{f}_∞$, ya que el límite de funciones continuas no tiene por qué ser continua).

Como era de esperar, $L^p(X)$ es un espacio de Banach para cualquier $1 ≤ p ≤ ∞$, aunque lo demostraremos más tarde.

\begin{defn}[Morfismo\IS de espacios normados] Sean $(V, \norm{·}_V)$ y $(W, \norm{·}_W)$ dos espacios normados y sea $\appl{T}{V}{W}$ lineal, con $T ∈ \mathcal{L}_{\mathrm{alg}} (V, W)$. Si $T$ es continua, entonces $T$ es un morfismo de espacios normados. El espacio de todos estos morfismos es \( \mathcal{L}(V, W) = \set{T ∈ \mathcal{L}_{\mathrm{alg}} (V, W) \tq T \text{ continua}} \label{eq:EspApplLinealesConts} \)
\end{defn}

\begin{prop} Sean $(V, \norm{·}_V)$ y $(W, \norm{·}_W)$ dos espacios normados sobre un mismo cuerpo \kbb. Sea $A ∈  \mathcal{L}_{\mathrm{alg}} (V, W)$ aplicación lineal entre $V$ y $W$. Entonces son equivalentes:

\begin{enumerate}
\item $A ∈ \mathcal{L}(V,W)$.
\item $A$ es continua en $0 ∈ V$.
\item $A$ es continua en todo $V$.
\item \label{prp:LinealEspNormados:Cota} $∃ C < ∞$ independiente de $v ∈ V$ tal que $\norm{A(v)}_W ≤ C\norm{v}_V$.
\end{enumerate}
\end{prop}


\begin{proof}

Que $A ∈ \mathcal{L}(V,W)$ implica que sea continua en $0 ∈ V$ es obvio. Vamos con el resto.

\proofpart{$A$ continua en $0 ∈ V \implies A$ continua en todo $V$}

Como $A$ es continua en $0$, si $v \to 0$ entonces $A(v) \to 0$. Sea ahora $v_0 ∈ V$ arbitrario. Entonces vamos a demostrar que $A(v) \to A(v_0)$ si $v\to v_0$. Lo que vemos es que \[ \dst_W(A(v), A(v_0)) = \norm{A(v) - A(v_0)} \eqreasonup{Linealidad} \norm{A(v-v_0)}_W \] que tiende hacia cero cuando $v \to v_0$, y como $A$ es continua en $0$ ya lo tenemos.

\proofpart{$A$ continua en todo $V \implies A$ acotada}

Consideramos $U = \bola_1(0) ⊂ W$, un abierto de $W$ que, por ser $\appl{A}{V}{W}$ continua, su preimagen $\inv{A}(U)$ es abierto en $V$. A su vez, es un entorno de $0 ∈ V$, ya que $A(0) = 0$ por ser lineal.

Entonces, por ser entorno abierto de $0$, podemos encontrar un $ρ > 0$ tal que $\bola_ρ(0) ⊂ \inv{A}(U)$.  Por lo tanto, un vector $v ∈ \bola_ρ(0)$ deberá tener su imagen en $U$. En otras palabras, si $\norm{v}_V < ρ$ entonces $\norm{A(v)}_W < 1$.

Ya casi hemos probado lo que queríamos, pero sólo para $v ∈ \bola_ρ(0)$: necesitamos expandirlo más. Lo bueno es que por ser lineal vamos a poder hacerlo, pagando con una constante.

Sea $v ∈ V\setminus\set{0}$ y $v' = t\frac{v}{\norm{v}_V}$, con $0 < t < ρ$. Por homogeneidad de la norma \[ \norm{v'}_V = \norm{t \frac{v}{\norm{v}_V}}_V = \frac{t}{\norm{v}_V} \norm{v}_V = t < ρ\], es decir, $v' ∈ \bola_ρ(0)$.

En ese caso, podemos aplicar la cota de antes y tenemos que \[ 1 > \norm{A(v')}_W \eqexpl{$A$ lineal} \norm{\frac{t}{\norm{v}_V} A(v)}_W = \frac{t}{\norm{v}_V} \norm{A(v)}_W  \]

Lo que nos queda es que $\norm{A(v)}_W < \frac{1}{t} \norm{v}_V$ y, haciendo tender $t \to ρ_-$ por la izquierda, tendremos que \[ \norm{A(v)}_W ≤ C \norm{v}_V\] con $C = \inv{ρ}$. Esto se cumple incluso aunque $v = 0$, así que hemos probado esta implicación.

\proofpart{$A$ acotada $\implies A$ continua}

Una vez hemos demostrado que $A$ está acotada, entonces la continuidad sigue de manera sencilla: si $\norm{v - v'}_V < ε$, entonces \[ \norm{A(v) - A(v')}_W = \norm{A(v-v')}_W ≤ C\norm{v-v'}_V \] y nuestro $δ$ de la definición continuidad es $δ = Cε$.

\end{proof}

\begin{prop} \label{prop:NormaEspacioAppLineales} Sean $(V, \norm{·}_V)$ y $(W, \norm{·}_W)$ dos espacios normados sobre un mismo cuerpo \kbb. Entonces $\mathcal{L}(V,W)$\footnote{Aplicaciones lineales y continuas de $V$ en $W$, ver \eqref{eq:EspApplLinealesConts}.} es normado si definimos \( \norm{A} ≝ \sup_{v∈V \setminus \set{0}} \frac{\norm{A(v)}_W}{\norm{v}_V} \label{eq:NormaEspacioAppLineales} \)
\end{prop}

\begin{proof} La acotación de $A ∈ \mathcal{L}(V,W)$ (\fref{prp:LinealEspNormados:Cota}) nos da directamente que esa norma está bien definida, ya que \[ \norm{A(v)}_W ≤ C\norm{v}_V \implies \frac{\norm{A(v)}_W}{\norm{v}_V} ≤ C < ∞ \quad ∀v ≠ 0\]

Tenemos que comprobar ahora las propiedades de la norma (ver \fref{def:Norma}). El producto por un escalar es sencillo, viendo que $(λA)(v) = λ · A(v)$ y que sale fuera de la norma y del supremo como $\abs{λ}$.

La desigualdad triangular también sale, aunque yo no lo voy a copiar y lo dejo como ejercicio al lector, porque sale muy fácil. Y la positividad igual.
\end{proof}

\begin{prop} Sean $(V, \norm{·}_V)$ y $(W, \norm{·}_W)$ dos espacios normados sobre un mismo cuerpo \kbb. Entonces, si $W$ es Banach entonces $\mathcal{L}(V,W)$ también lo es con la norma definida en \eqref{eq:NormaEspacioAppLineales}.
\end{prop}

\begin{proof} Sea $\set{A_n}_{n≥1}$ una sucesión de Cauchy en $\mathcal{L}(V,W)$. Pretendemos definir el límite $A_n \to A$ como \[ A(v) = \lim_{n \to ∞} A_n(v) \]

Para ver que esta definición tiene sentido lo que juega un papel fundamental es ver que el espacio de llegada, $W$, es un espacio de Banach. Dado $v ∈ V$, entonces \[ \norm{A_n(v) - A_m(v)}_W = \norm{(A_n - A_m) (v)}_W \eqexpl[≤]{\eqref{eq:NormaEspacioAppLineales}} \norm{A_n - A_m} \norm{v}_V \]

Como $\set{A_n}_{n≥1}$ es de Cauchy en $\mathcal{L}(V,W)$, podemos hacer $\norm{A_n - A_m}$ tan pequeño como queramos (y $\norm{v}_V$ es constante, por lo que no afecta) así que tendremos que $\set{A_n(v)}_{n≥1}$ es de Cauchy igualmente. Por último, como $W$ es completo, $\set{A_n(v)}_{n≥1}$ converge a $A(v)$ para todo $v ∈ V$.

Nos falta, eso sí, ver que este $A$ que hemos definido es lineal y acotado, es decir, que $A ∈ \mathcal{L}(V,W)$. La linealidad es fácil de ver y se deja como ejercicio. Para la acotación, vamos a hacerlo ahora.

Queremos demostrar primero que $\sup_n \norm{A_n} < ∞$, es decir, que $∃C < ∞$ tal que $\norm{A_n} ≤ C$ para cualquier $n$.

Por ser $A_n$ de Cauchy, existe un $N$ tal que $\norm{A_n - A_m} ≤ 1$ si $m,n ≥ N$. Entonces por un lado tenemos que  \[ \norm{A_n} = \norm{(A_n - A_N) + A_N} ≤ \norm{A_N} + \norm{A_n - A_N} ≤ 1 + \norm{A_N} = C_1 \] si $n ≥ N$, y por el otro que si $1 ≤ n < N$ entonces \[ \norm{A_n} ≤ \max_{1 ≤ i < N} \norm{A_i} = C_2 \], así que juntando ambas cotas tenemos que en general \[ \norm{A_n} ≤ \max \set{C_1, C_2} = C \]

Con esto, podemos probar que $A$ está acotado. Sea $x ∈ V$, entonces \[ \norm{A(x)}_W = \norm{\lim_{n \to ∞} A_n(x)}_W = \lim_{n\to ∞} \norm{A(x)}_W \]

No hay problema en sacar el límite fuera de la norma porque la norma es Lipschitz continua (ver un ejercicio de las hojas).

Ahora podemos usar que $\norm{A(x)}_W ≤ \norm{A_n}_{\mathcal{L}(V,W)} · \norm{x}_V ≤ C \norm{x}_V$. Nos hemos quitado la dependencia de $n$ y nos queda \[ \norm{A(x)}_W ≤ C \norm{x}_V \implies \norm{A} ≤ C\], por lo que $A$ está acotado. La cota $C$ se podría afinar un poco, aunque no lo vamos a probar, con \[ \norm{A} ≤ \limsup_{n \to ∞} \norm{A_n} \]
\end{proof}

\begin{corol} Tanto si $\kbb = ℝ$ ó $ℂ$, el espacio $V^* = \mathcal{L}(V, \kbb)$ es un espacio de Banach.
\end{corol}

Ese $V^*$ es, tal y como la notación indica, el espacio dual topológico.

\begin{defn}[Espacio\IS dual topológico] Dado un espacio normado $V$ sobre $\kbb$, se define el espacio dual topológico como \[ V^* = \mathcal{L}(V, \kbb) = \set{\appl{T}{V}{\kbb} \tq T\text{ lineal, continua}} \]
\end{defn}

\begin{defn}[Producto\IS de dualidad] Sea $V$ un espacio normado sobre \kbb, y sean $v ∈ V$ y $v ∈ V^*$. Entonces se define el producto dualidad como \begin{align*}
\appl{\pesc{·,·}}{V^* × V&}{\kbb} \\
\pesc{v^*, v} &\longmapsto v^*(v)
\end{align*}, que es una aplicación bilineal.
\end{defn}

En particular, como $\pesc{·,v}$ es lineal en $V^*$ fijado un $v ∈ V$, esto define una inyección canónica entre $V$ y $(V^*)^* = V^{**}$, que no depende de la base que elijamos en estos espacios.

Otra observación, que nos vendrá bien para cuando estudiemos el Teorema de Hahn-Banach en la \fref{sec:TeoremaHahnBanach}, es que el producto de dualidad es una aplicación bilineal y acotada. La acotación se ve rápidamente: \[ \abs{\pesc{v^*, v}} = \abs{v^*(v)} ≤ \norm{v^*}_{\mathcal{L}(V, \kbb)} \norm{u}_V = \norm{v^*}_{V^*} \norm{v}_V \]

De ahí también se puede deducir que la norma del operador $\appl{i}{V}{V^{**}}$ de la inyección canónica que comentábamos antes es $\norm{i} ≤ 1$.

\begin{defn}[Norma\IS dominante] \label{def:NormaDominante} Consideremos $V$ un espacio vectorial sobre un cuerpo $\kbb$ y dos normas $\norm{·}_A$, $\norm{·}_B$ en $V$. Diremos que $\norm{·}_A$ domina a $\norm{·}_B$ si cuando $\norm{v}_A \to 0$, entonces $\norm{v}_B \to 0$.
\end{defn}

\begin{defn}[Norma\IS equivalente] Dos normas son equivalentes si una domina a la otra y viceversa, es decir, que $\norm{v}_A \to 0 \iff \norm{v}_B \to 0$.
\end{defn}

Esta noción cualitativa de equivalencia tiene un análogo cuantitativo:

\begin{prop} Sea $V$ normado y sean $\norm{·}_A$ y $\norm{·}_B$ dos normas en él. Son equivalentes
\begin{enumerate}
\item La norma $\norm{·}_A$ domina a $\norm{·}_B$.
\item Existe una constante $C < ∞$ tal que $∀x ∈ V$ se cumple que $\norm{x}_B ≤ C\norm{x}_A$
\end{enumerate}
\end{prop}

\begin{proof}

La implicación \textit{b $\implies$ a} es trivial, así que vamos a demostrarlo al otro lado. Definimos dos espacios $X = (V, \norm{·}_B)$, $Y = (V, \norm{·}_A)$ y una aplicación identidad $I$ de $X$ en $Y$. Entonces $\norm{·}_A$ domina a $\norm{·}_B$ si y sólo si $I$ es continua.

Usando la \fref{prp:LinealEspNormados:Cota}, esto equivale a que exista una $C < ∞$ tal que $\norm{I(v)}_B ≤ C \norm{v}_A$, y como $\norm{I(v)}_B = \norm{v}_B$ ya tenemos la demostración.
\end{proof}

Una observación rápida es que si $\norm{·}_A$ domina a $\norm{·}_B$, entonces la topología generada por la norma de $A$ es más fina, esto es, $\topl_B ⊂ \topl_A$.

\begin{example} Tomamos $V = C^1([a,b])$, funciones continuas y con derivada continua en $[a,b]$. Podemos definir dos normas \begin{align*}
\norm{f}_A &= \norm{f}_∞ + \norm{f'}_∞ \\
\norm{f}_B &= \norm{f}_∞
\end{align*}

Claramente la norma $A$ domina a la norma $B$, pero a la inversa no se cumple.
\end{example}

\begin{prop} \label{prop:CompatibilidadNormaEspVect} Sea $(V, \norm{·})$ un espacio normado, entonces la topología es compatible con la estructura de espacio vectorial de $V$ sobre \kbb:

\begin{enumerate}
\item La topología inducida por la norma es una topología Hausdorff\footnote{Esto es, podemos separar dos puntos distintos con abiertos disjuntos. Lo que viene siendo una topología razonable, vamos.}.
\item La aplicación suma $x+y$ para $x,y ∈ V$ es continua en $V × V$ con la topología producto.
\item La multiplicación por un escalar $λv$ con $λ ∈ \kbb$, $v ∈ V$ es continua en $\kbb × V$
\item Para $a ∈ V$, la traslación $T_a(u) = a+ v$ es un homeomorfismo en $V$.
\item Dado $λ ∈ \kbb \setminus \set{0}$, el escalado $M_λ(v) = λv$ es un homeomorfismo en $V$.
\end{enumerate}
\end{prop}

\begin{proof}

\proofpart{Continuidad de la suma}

En $V × V$ podemos dar una norma que induce la topología producto: \[ \norm{(u,v)}_{V×V} = \max \set{\norm{u}, \norm{v}}\]

Con esto, podemos ver cuánto vale la norma producto de la suma dados $(u,v)$ $(u', v')$ cuando esos elementos están cerca.

Si tomamos $ε > 0$ y $\norm{u-u'}_V, \norm{v-v'}_V < \sfrac{ε}{2}$, entonces según la definición de la norma nos queda que $\norm{(u,v) - (u',v')}_{V×V} < \sfrac{ε}{2}$. Por otra parte, acotamos en la imagen y vemos que
\[ \norm{(u+v)-(u'+v')}_V = \norm{(u-u') + (v-v')}_V ≤ \norm{u-u'}_V + \norm{v-v'}_V < ε \], por lo que la suma es continua.

\proofpart{Continuidad del producto por un escalar}

Haciendo cuentas con $(λ,v), (λ', v') ∈ \kbb × V$ tenemos que \begin{align*}
\norm{λv - λ'v'}_V &= \norm{(λv-λ'v) + (λ'v - λ'v')}_V \\
	&≤ \norm{λv - λ'v}_V + \norm{λ'v - λ'v'}_V \\
	&= \norm{(λ-λ')v}_V + \norm{λ'(v-v')}_V \\
	&= \abs{λ-λ'}\norm{v}_V + \abs{λ'}\norm{v-v'}_V
\end{align*}, que podemos hacer tan pequeño como queramos si $\abs{λ-λ'}$ y $\norm{v-v'}_V$ son suficientemente pequeños, luego el producto por escalar es continuo.

\end{proof}

Queremos dar un criterio que nos sirva para decidir cuándo un espacio normado es de Banach, que nos servirá para cuando veamos el espacio cociente.

\begin{prop} Sea $X = (V, \norm{·})$ un espacio normado. Entonces $X$ es de Banach si y sólo si, dada una sucesión $\set{x_n}_{n≥1} ⊂ V$ con suma finita ($\sum_{n≥1} \norm{x_n} < ∞$), se cumple que la sucesión dada por \[ v_N = \sum_{n=1}^N x_n \] converge en $V$.
\end{prop}

\begin{proof}

Vamos a tratar de ver que la sucesión es de Cauchy y por lo tanto converge si $X$ es completo. Dados $N, N'$ con $N ≤ N'$, vemos que \[ \norm{v_N - v_{N'}} = \norm{\sum_{n=1}^{N'}x_n - \sum_{n=1}^N x_n} = \norm{\sum_{N < n ≤N'} x_n} ≤ \sum_{N<n≤N'} \norm{x_n} ≤ \sum_{n> N} \norm{x_n} \], que tenderá a cero cuando $N \to ∞$ dado que suponemos que la suma de todos los $x_n$ es finita.

Por lo tanto, $v_N$ es efectivamente de Cauchy y si $X$ es completo, $v_N$ converge en $X$.

Por ser $\set{v_n}_{n≥1}$ de Cauchy, existe un $N_1$ tal que $∀n ≥ N_1$, se tiene que $\norm{v_n - v_{N_1}} < \sfrac{1}{2}$. Igualmente, existe un $N_2 > N_1$ tal que $∀n ≥ N_2$, entonces se cumple que $\norm{v_n - v_{N_2}} ≤ \left(\sfrac{1}{2}\right)^2$.

En general, si se han elegido $N_1 < N_2 < \dotsb < N_k$ y términos $v_{N_1}, v_{N_2}, \dotsc, v_{N_k}$ de la sucesión de los $v_N$, tomamos $v_{N_{k+1}}$ tal que $\norm{v_n - v_{N_{k+1}}} ≤ \left(\sfrac{1}{2}\right)^{k+1}$.

Sea ahora $x_k = v_{N_{k+1}} - v_{N_k}$ para $k = 1, 2, \dotsc$. Por construcción, las normas de esos elementos son $\norm{x_k} ≤ \sfrac{1}{2^k}$, y por lo tanto \[ S=  \sum_{k≥1} \frac{1}{2^k} = 1 < ∞\], luego $S_N = \sum_{k=1}^N x_k$ converge.

Lo cierto es que no tengo muy claro por dónde está llevando la demostración así que yo simplemente voy a copiar y espero que en algún momento esto sea salvable.

Pero \[ S_N = \sum_{k=1}^N (v_{N_{k+1}} - v_{N_k})\] es una serie telescópica, y entonces $S_k = v_{N_{k+1}} - V_{N_1}$, luego $V_{N_{k+1}} = S_k + v_{N_1}$, donde $S_k$ converge a $S$ y $v_{N_1}$ es un vector fijo, luego la subsucesión $\set{v_{N_k}}_{k≥1}$ es convergente en $X$.

\proofpart{Traslación y escalado son homeomorfismos}

Dado que ya hemos demostrado que ambas aplicaciones son continuas y la biyectividad es trivial, sólo falta ver que llevan abiertos en abiertos. La demostración está en el \fref{ej:Hoja2:1A}.

\end{proof}

\section{Teorema de la acotación uniforme}

\begin{theorem}[Teorema\IS de acotación uniforme de Banach-Stainhaus] Sea $\set{T_α}_{α∈A}$ un subconjunto de $\mathcal{L}(X,Y)$, donde $X$ es Banach e $Y$ es normado. Entonces, o bien las aplicaciones lineales $T_α$ están uniformemente acotadas (es decir, $∃C < ∞$ tal que $∀α ∈ A$ se tiene que $\norm{T_α} ≤ C$), o bien existe un cierto conjunto\footnote{Recordamos la definición de \nref{def:ConjuntoGDelta}: intersección numerable de abiertos.} $G_δ$ denso en $X$, que llamaremos $B$, tal que \[ \sup_{α ∈ A} \norm{T_α(x)}_Y = ∞ \quad ∀x ∈ B \]
\end{theorem}

\begin{proof}
Para $n = 1,2, \dotsc$ consideraremos un conjunto \[ V_n = \set{x ∈ X \tq  \sup_{α∈A} \norm{T_α(x)}_Y > n} \]

Cada uno de estos conjuntos será un abierto, y lo vamos a demostrar. Cojamos $x ∈ V_n$. Entonces $∃ α_0 ∈ A$ tal que $\norm{T_{α_0}(x)}_Y > n$. Como $T_{α_0}$ es acotado, entonces existe un cierto $δ > 0$ tal que si $x' ∈ \bola_δ(x)$ se tiene que $\norm{T_{α_0}(x')} > n$.

Justificamos la existencia de ese δ. Por una parte, podemos hacer una estimación superior: \[ \norm{T_{α_0} (x) - T_{α_0} (x')}_Y = \norm{T_{α_0}(x-x')}_Y ≤ \norm{T_{α_0}} \norm{x-x'}_X \]

Por otra, \[ \norm{T_{α_0}(x')}_Y = \norm{T_{α_0}(x) - T_{α_0}(x-x')}_Y ≥ \norm{T_{α_0} (x)}_Y - \norm{T_{α_0}(x-x')}_Y ≥ \norm{T_{α_0}(x)} - \norm{T_{α_0}}{x - x'}_X > n\] si $\norm{T_{α_0}(x)} - \norm{T_{α_0}}\norm{x-x'}_X > n$ lo que ocurre si y sólo si $\norm{T_{α_0}}{x-x'} < \norm{T_{α_0}(x)} - n > 0$ lo que ocurre si $\norm{T_{α_0}} ≠ 0$. O algo así.

Pero entonces o que tenemos es que $\sup_{α ∈ A} \norm{T_α(x')} > n$ luego $x' ∈ V_n$ y $V_n$ es abierto.

Con esto, vamos a ver que pasa en dos casos posibles: que haya un conjunto no denso o que todos sean densos.

Supongamos que $∃N$ tal que $V_N$ no es denso. Entonces $V_N$ evita una cierta bola cerrada $\adh{\bola_r}(x_0)$ con $\adh{\bola_r}(x_0) ⊂ V_N^c$ para algún $x_0 ∈ X$ y $r > 0$.  Si $x ∈ \adh{\bola_r}(x_0)$ y $α_0 ∈ A$, entonces $N ≥ \sup_{α∈A} \norm{T_α(x)}_Y ≥ \norm{T_{α_0}(x)}_Y$, que podemos escribir como \[ \norm{T_{α_0}(x)}_Y = \norm{T_{α_0}(x_0 + (x-x_0))}_Y = \norm{T_{α_0}(x_0) + T_{α_0}(x-x_0)} ≥ \norm{T_{α_0}(x_0)} - \norm{T_{α_0}(x-x_0)} \implies \norm{T_{α_0}(x-x_0)}_Y ≤ 2N\]

Hacemos el cambio de variables $x-x_0 = y$ y entonces $x ∈ \adh{\bola_r}(x_0) \implies y ∈ \adh{\bola_r}(0)$, y entonces $∀y ∈ \adh{\bola_r}(x_0)$ $\norm{T_{α_0}(y)}_Y ≤ 2N$.

Sea ahora $z ∈ X$ arbitrario, $z = \norm{z}_X · z'$ con $z' ∈ \adh{\bola_1}(0)$, y $z = \frac{1}{4} \norm{z}_X · z''$ con $z'' ∈ \adh{\bola_r}(0)$ de tal forma que $\frac{1}{r} z'' = z'$. Esto nos dice que \[ T_{α_0}(z) = T_{α_0} \left(\frac{1}{r} \norm{z}_X z''\right) = \frac{1}{r} \norm{z}_X T_{α_0}(z'') \] y tomando normas nos queda que \[ \norm{T_{α_0}(z)}_X = \frac{1}{r} \norm{z}_X \norm{T_{α_0} (z'')}_X ≤ \frac{2N}{r} \norm{z}_X \] lo que nos dice que $\norm{T_{α_0}} ≤ \frac{2N}{r}$  para cualquier $α_0 ∈ A$.

Si por otra parte todo $V_n$ es denso, entonces por el \nref{thm:CategoriaBaire} la intersección es un $G_δ$ denso en $X$, y aquí es donde usamos que $X$ es Banach.

\end{proof}

\begin{corol} Si $\set{T_α}_{α∈A} ⊂ \mathcal{L}(X,Y)$ con $X$ Banach e $Y$ normado, entonces la familia $\set{T_α}$ está uniformemente acotada si $\sup_{α ∈ A} \norm{T_α(x)}_Y < ∞ \;∀x ∈ X$.
\end{corol}

Lo interesante de este teorema es la posibilidad de extraer información global (acotación uniforme) a partir de información puntual.


\section{Teorema de la aplicación abierta}

\begin{theorem}[Teorema\IS de la aplicación abierta] Sean $X$ e $Y$ Banach y $T ∈ \mathcal{L}(X,Y)$ sobreyectiva. Entonces:

\begin{enumerate}
\item $∃δ >0 $ tal que $T(\bola_1(0)) ⊃ \bola_δ(0)$.
\item $T$ es una aplicación abierta, es decir, que si $U ⊂ X$ es abierto entonces $T(U) ⊂ Y$ lo es igualmente.
\end{enumerate}
\end{theorem}

\begin{proof}
% Aviso: basura de demostración.
Primero vamos a demostrar que si $T$ es sobreyectiva, existe una cierta constante $c > 0$ tal que $\adh{T(\bola_1(0))} ⊃ \bola_{2c}(0)$.

Sea $Y_n = n\adh{T(\bola_1(0))} = \adh{T(\bola_n(0))}$ por ser $T$ lineal\footnote{Hay que pensar bien cómo funciona el intercambiarlo con el cierre.}, con $Y_n ⊂ Y$ para $n ∈ ℕ$.

Y ahora, puesto que $T$ es sobreyectiva, dado $y ∈ Y$ existe un $x ∈ X$ con $T(x) = y$. Si $\norm{x}_X < n$, entonces $y ∈ T(\bola_n(0))$ por definición. Lo que esto nos dice es que la unión \[ \bigcup_{n≥1} T(\bola_n(0)) = Y \] de forma simplemente algebraica. Como $Y$ es completo, por el \nref{thm:CategoriaBaire} esto implica que existe un $N$ tal que $\mop{int} \adh{T(\bola_n(0))} ≠ ∅$. A su vez, esto implica que existe una cierta cantidad $c$ positiva $y_0 ∈ Y$ con $\bola_{4c} (y_0) ⊂ \adh{T(\bola_n(0))}$.

Dado que $T$ es lineal, $-y_0 ∈ -\adh{T(\bola_1(0))} = \adh{T(-\bola_1(0))} = \adh{T(\bola_1(0))}$ o, en otras palabras, que $\bola_1(0)$ es un dominio par. Así, $y_0, -y_0 ∈ \adh{T(\bola_1(0))}$.

Entonces \[ \bola_{4c}(0) = \bola_{4c}(y_0) - y_0 ∈ \adh{T(\bola_1(0))} + \adh{T(\bola_1(0))} = 2 \adh{T(\bola_1(0))}\] por ser $\adh{T(\bola_1(0))}$ convexo (ver \fref{ej:Hoja2:2}), y así \( \adh{T(\bola_1(0))} ⊃ \frac{1}{2}\bola_{4c}(0) = \bola_{2c}(0) \label{eq:ThmAppAbierta:eq1}\)

Vemos que si $T$ es continua y se cumple \eqref{eq:ThmAppAbierta:eq1} de hecho \( T(\bola_1(0)) ⊃ \bola_c(0) \label{eq:ThmAppAbierta:eq2} \). Para demostrarlo, tomamos $y ∈ Y$ con $\norm{y}_Y < c$, esto es, $y \bola_c(0)$. Queremos encontrar $x ∈ X$ con $\norm{x}_X < 1$ y $T(x) = y$.

Por \eqref{eq:ThmAppAbierta:eq1}, dado $y ∈ Y$ con $\norm{y}_Y < c$, $∀ε > 0$ existe un $z ∈ \bola_1(0) ⊂ X$ con $\norm{y-T(z)}_Y < 2ε$, ya que $y ∈ \adh{T(\bola_1(0))}$.


Partimos de $ε = {c} > 0$. Escogemos $z_1 ∈ \bola_1(0)$ con $\norm{y - T(z_1)}_Y < \sfrac{c}{2}$. Sea $y_1 = y - T(z_1)$. Entonces $\norm{y_1}_Y < \sfrac{c}{2} \implies y_1 ∈ \bola_{\sfrac{c}{2}} (0) ⊂ Y$. Como $\adh{T(\bola_1(0))} ⊃ \bola_{2c}(0)$ entonces $\adh{T(\bola_{\sfrac{1}{2}}(0))} ⊃ \bola_c(0)$ por ser $T$ lineal.

De aquí concluimos que $∃z_2 ∈ \bola_{\sfrac{1}{2}}(0)$ con
\(\norm{T(z_2) - y_1}_Y < \frac{c}{2^2} \label{eq:ThmAppAbierta:eq3} \)

Continuando este proceso indefinidamente tendremos una sucesión $\set{z_i}_{i=1}^n$ con $z_i ∈ \bola_{\sfrac{1}{2^i}}(0) ⊂ X$ y $\norm{y - (T(z_1) + \dotsb + T(z_n))} < c \frac{1}{2^n}$. Sean $x_n = z_1 + \dotsb z_n$ entonces \[ \sum_{n≥1} \norm{z_j}_X < \sum_{n≥1} \frac{1}{2^i} = 1 \] y como $X$ es completo, se sigue que $\set{x_n}_{n≥1}$ es convergente en $X$ por nosequé caracterización de espacios completos y secuencias sumables absolutamente, entonces $x_n \to x ∈ X$, y además podemos decir cosas de la norma \[ \norm{x}_X = \norm{\lim_{n\to ∞} x_n}_X = \lim_{n\to ∞} \norm{x_n}_X ≤  \lim_{n\to ∞} \norm{\sum_{j=1}^n z_j}_X ≤  \lim_{n\to ∞} \sum_{j=1}^n \norm{z_j}_X < 1 \], luego $x ∈ \bola_1(0) ⊂ X$ y por otra parte como $T$ es continua entonces \[ T(x) = \lim_{n\to ∞} T(x_n) = T\left(\lim_{n\to ∞} x_n\right) = y \] por la acotación de \eqref{eq:ThmAppAbierta:eq3}.

\proofpart{$T$ es abierta}

Sea $U ⊂ X$ abierto e $y ∈ T(U)$, entonces $y = T(x)$ para algún $x ∈ U$. Por ser $U$ abierto, $∃δ > 0$ tal que $x + \bola_δ(0) = \bola_δ(x) ⊂ U$. Luego $T(U) ⊃ T(\bola_δ(x)) = T(x) + T(\bola_δ(0)) = T(x) + δT(\bola_1(0)) ⊃ y + δ \bola_c(0) = \bola_{δc}(y)$, luego $T(U)$ es abierto.

Dibujitoñ.
\end{proof}

\begin{corol} Sean $X$ e $Y$ espacios de Banach y $T ∈ \mathcal{L}(X,Y)$ con $T$ biyectiva. Entonces $\inv{T} ∈ \mathcal{L}(Y,X)$.
\end{corol}

Ver hoja 2 de ejercicios, esto es un problema.

\begin{corol} \label{crl:AppAbiertaAcotacionNormas} Sea $X$ un espacio vectorial con dos normas $\norm{·}_1,\, \norm{·}_2$ tales que $(X, \norm{·}_1)$ y $(X, \norm{·}_2)$ son ambos espacios de Banach. Si $∃C < ∞$ tal que $\norm{x}_2 ≤ C\norm{x}_1\;∀x ∈ X$ (también llamado \nref{def:NormaDominante}) entonces $∃C' > 0$ tal que $\norm{x}_1 ≤ C'\norm{x_2}\;∀x ∈ X$.
\end{corol}

Ver hoja 2 de nuevo, esto es otro problema.

\section{Teorema de la gráfica cerrada}

\begin{theorem} Sean $X$ e $Y$ espacios de Banach y $\appl{T}{X}{Y}$ lineal. Supongamos que el gráfico de $T$, dado por \[ G(T) ≝ \set{(x,T(x)) \tq x ∈ X } ⊂ X × Y \] es cerrado con la topología producto\footnote{Hay otro ejercicio para ver que $(X×Y, \norm{·,·}_{X×Y})$ con $\norm{u,v}_{X×Y} = \norm{u}_X + \norm{v}_Y$ es Banach igualmente.}. Entonces $T ∈ \mathcal{L}(X,Y)$.
\end{theorem}

\begin{proof}
Si $G(T)$ es cerrado en $X×Y$, entonces será un espacio de Banach con la norma producto restringida a $G(T)$\footnote{Otro ejercicio más.}. SI tomamos un $(x,y) ∈ G(T)$, entonces $y = T(x)$ para $x ∈ X$. La norma de ese vector será \[ \norm{(x,y)}_{X×Y} = \norm{x}_X + \norm{T(x)}_Y \]

Consideramos ahora \begin{align*} \appl{I}{X&}{G(T)} \\
x &\longmapsto (x,T(x)) \end{align*} que es una isometría entre $X$ con la norma $\norm{x}_2 = \norm{x}_X + \norm{T(x)}_Y$ y $G(T)$ con la norma del espacio producto.

Como el espacio de llegada de $I$ es Banach e $I$ es una isometría, entonces $(X, \norm{·}_2)$ es también un espacio de Banach\footnote{Adivina adivinanza: otro ejercicio de la hoja 2, chimpún.}.

Claramente, $\norm{x}_2 ≥ \norm{x}_X$ luego esta segunda norma domina en $X$ a su norma inicial. Usando el \fref{crl:AppAbiertaAcotacionNormas}, existe una constante $C$ finita tal que $\norm{x}_2 ≤ C \norm{X}_X\; ∀x ∈ X$. Esto lo que nos dice es que $∀x ∈ X$ entonces $\norm{T(x)}_Y ≤ \norm{x}_V + \norm{T(x)}_Y = \norm{x}_2 ≤ C\norm{x}_X$ luego $T ∈ \mathcal{L}(V,W)$ con norma $≤ C$.
\end{proof}

\section{Teorema de Hahn-Banach}
\label{sec:TeoremaHahnBanach}

Problema que queremos resolver: extensión de un operador lineal dado un subespacio. Daremos ciertas restricciones.

\begin{prop} Sea $\appl{T}{V⊂X}{Y}$ lineal sobre $V$ con $X$ normado e $Y$ Banach
\begin{enumerate}
\item $V$ es un subsespacio denso de $X$.
\item $T$ es acotado en $V$.
\end{enumerate}

Entonces existe una única extensión $\appl{T}{X}{Y}$ con $T$ lineal y $\norm{T}_{xy}= \norm{T}{VY}$.
\end{prop}

\begin{proof} Sea $x ∈ X$. Como $V$ es denso hay una sucesión en $V$ con límite $x$. La aplicación extendida se define como el límite de $T$ de los elementos de la sucesión. Se demuestra que está bien definido demostrando que otra sucesión se acercará igualmente a $X$ y haciendo cosas con las normas saldrá que $T(x_n) - T(x_n') \to 0$.

Hay que demostrar además que el límite existe, y para eso usamos que $Y$ es Banach, que la sucesión de las imágenes de Cauchy por estar el operador acotado y listos.

Vamos a ver ahora que es lineal. Sea $x$ límite de $x_n ∈ V$ y sea $λ ∈ \kbb$. Como las operaciones del espacio vectorial son compatibles con la topología, entonces $λx = \lim λx_n$. Así podemos tomar $T$ en ambos lados y ver que es lineal.

Luego sean $x,y ∈ X$ con sus respectivos límites definidos, y haciendo cuentas sale que es lineal de nuevo, usando que $T$ es lineal en $V$ y etc etc.

Nos falta ver que es acotada y que preserva la norma. Podemos sacar el líite fuera de la norma, por acotació o algo así podemos tomar el limsup y entonces acotar por $\norm{T}_V \norm{x_n}$ u la constante sale fuera y el límite es la norma de $X$ y entonces acotamos en $X$ con la misma norma.

Para la desigualdad al otro lado, como $T$ es una extensión del operador pues algo.
\end{proof}

Sea $X = (V, \norm{·}_∞)$ un espacio normado sobre \kbb, $E ⊂ V$ un subespacio y $\appl{λ}{E}{\kbb}$ un funcional acotado (esto es, $λ ∈ E^*$). Queremos encontrar extensiones de λ a todo $V$ no triviales y que conserven la norma.

Buscaremos $E' \subsetneq E$ y $\appl{λ'}{E'}{\kbb}$ lineal, de tal forma que $\restr{λ'}{E} = λ$ y además $\abs{λ'(x)} ≤ \norm{λ}_{E^*} \norm{x}_X$ cuando $x ∈ E'$.

\begin{lemma} Si $E \subsetneq V$ y $x_0 ∉ E$, entonces $λ$ admite una extensión con las propiedades anteriores al subespacio \[ E' = E + \spn \set{x_0} = \set{x ∈ V \tq x = x_1 + μ x_0,\,\,x_1 ∈ E, μ ∈ \kbb} \]
\end{lemma}

\begin{proof}
Observamos que, dado $x_0 ∉ E$, $x_0$ es linealmente independiente de $E$ y por lo tanto $E' ≠ E$ y además la descomposición $x = x_1 + μx_0$ es única.

La extensión estará dada por $λ(x) = λ(x_1) + μλ(x_0)$. El problema está en ver cuánto vale $λ(x_0)$, ya que $x_0$ no está en el dominio de $λ$.

\proofpart{$\kbb = ℝ$}

Supongamos primero que $\kbb = ℝ$, y sin pérdida de generalidad que $\norm{λ}_{E^*} = 1$. Queremos probar que $\abs{λ(x_1 + μx_0)} ≤ \norm{x_1 + μx_0}$ para todos $x_1 ∈ E$, $μ ∈ ℝ$. Tras una serie de manipulaciones, un cambio $y = x_1$, una división entre $μ$ cuando $μ ≠ 0$, otro cambio $z = \frac{y}{μ}$ y al final llegamos a que tenemos que demostrar que \[ \sup_{z ∈ E} -λ(z) - \norm{z+x_0} ≤ a ≤ \inf_{z ∈ E} -λ(z) + \norm{z + x_0}\]

Si $z, z' ∈ E$, entonces de nuevo hacemos manipulaciones con las normas de $λ$ y por lo tanto $A ≤ B$ y podemos encontrar ese $λ(x_0)$.

\proofpart{$\kbb = ℂ$}

Si $u = \Re λ$, entonces $u$ es un funcional lineal sobre $E$ y \[ λ(x) = u(x) - iu(ix) \;∀x∈E\]

Si en cambio $u$ es un funcional lineal real, $λ$ lo definimos en $E$ por la fórmula anterior, de tal forma que es un funcional lineal complejo sobre $E$. Además se cumple que $\norm{λ}_{E^*} = \norm{u}_{E^*}$. Y si λ está dado por lo que decíamos antes, entonces es $ℝ$-lineal y $ℂ$-lineal. Para verlo basta ver que $λ(ix) = iλ(x)$.

Como $u(x) = \Re λ(x)$, entonces $\norm{u(x)} ≤ \norm{λ(x)} \implies \norm{u}_{E^*} ≤ \norm{λ}_{E^*}$ y por otra parte si $x ∈ E$, entonces $∃α ∈ ℂ$ con $\abs{α} = 1$ y $αλ(x) = \abs{λ(x)}$, con $α = \frac{λ(x)}{\abs{λ(x)}}$ cuando $λ(x) ≠ 0$ (si $λ(x) = 0$ cualquier α nos vale); y entonces \[ \abs{λ(x)} = αλ(x) = λ(αx) = u(αx) ≤ \norm{u}_{E^*} · \abs{α}\norm{x} \] y por lo tanto $\norm{λ}_{E^*} ≤ \norm{u}_{E^*}$ y finalmente $\norm{λ}_{E^*} = \norm{u}_{E^*}$.
\end{proof}


\begin{theorem}[Teorema\IS de Hahn-Banach]
\end{theorem}

\chapter{Dualidad en espacios de Banach}

\section{Dual y bidual de un espacio de Banach}

\section{Reflexividad}

\chapter{Topologías débiles en espacios de Banach}

\section{Teorema de Banach-Alaouglu}

\chapter{Espacios de Hilbert}

\section{Ortogonalidad y método Gram-Schmidt}

\section{Teorema de la proyección ortogonal}

\section{Aproximación óptima en convexos}

\section{Dualidad en espacios de Hilbert}

\subsection{Teoremas de representación}

\section{Bases ortonormales y series de Fourier}

\chapter{Teoría espectral de operadores en espacios de Hilbert}

\section{Operadores autoadjuntos}

\section{Operadores compactos}

\section{Teorema espectral para operadores autoadjuntos y compactos}

\subsection{Alternativa de Fredholm}

%% Apéndices (ejercicios, exámenes)
\appendix

\chapter{Ejercicios}
\input{tex/AnalisisFuncional_Ejs.tex}

\nocite{brezis2010functional,reed1980methods,rudin1991functional,ApuntesVarReal}
\bibliography{../Apuntes}{}

\printindex
\end{document}
