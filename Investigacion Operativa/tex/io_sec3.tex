\section{Condiciones KTT}


\paragraph{Motivación:} Puede ser que los problemas a los que nos enfrentemos no cumplan las condiciones de convexidad estudiadas en el tema anterior. En ese caso, necesitaremos nuevas herramientas, como las condiciones KTT.
Vamos a intentar relajar las condiciones de convexidad para los problemas que vamos a resolver, encontrando otras condiciones (definidas por Karoush, Kuhn y Tucker) que permiten la identificación de los mínimos de un problema. 

En este tema vamos a estudiar tanto problemas generales como problemas convexos en un dominio del problema abierto que incluye todos los puntos que satisfacen las restricciones.

Consideremos el problema:

\begin{ioprob}
\goal{$\min f(x)$}
\restrictions{$f_i(x)≤0\;i=1,...,m$}{}{}{}{}{}
\end{ioprob}


\begin{defn}[Condiciones\IS KTT]
Sean $u_i ≥0$ y el Lagrangiano:

\[
	L(x) = f(x) + \sum_i u_i f_i(x)
\] 

\obs Estos $u_i$ utilizados los denominaremos \concept{ultiplicadores} por el \href{https://en.wikipedia.org/wiki/Lagrange_multiplier}{teorema de los multiplicadores de Lagrange}.

Se dice que el punto $\vx$ y el vector de multiplicadores $\vu \in ℝ^m$ verifica las condiciones KTT para un problema $(P)$ si

\begin{align*}
KKT(\vx) \dimplies \grad L(\vx) = 0 \dimplies \grad f(\vx) + \sum_i u_i\grad f_i(\vx) &=0\\
f_i(\vx)  &≤ 0 \;\; i=1,...,m\\
u_i&≥0\;\; i=1,...,m\\
u_if_i(\vx) &= 0  \;\; i=1,...,m
\end{align*}
\end{defn}
\paragraph{Notación:} $KKT(\vx)$ significa que para $\vx$ existe un vector de multiplicadores tales que verifican las condiciones KTT. De la misma manera, $KTT(\vx,\vu)$ significa que el punto $\vx$ y el vector de multiplicadores satisfacen las condiciones KKT.

Cualquier mínimo local de un problema $(P)$, que también cumpla las cualificación de las restricciones (que definimos a continuación) tiene que cumplir las condiciones KTT. 
Esto nos puede dar una pista para encontrar mínimos locales en un problema.


\begin{defn}[Cualificación\IS de las restricciones]
Dado un punto fatible $\vx$, sea $I_{\vx} = \{i : f_i(\vx) = 0\}$ el conjunto de restricciones \textbf{activas} en $\vx$.

$\vx$ verifica la cualificación de las restricciones si los vectores $\grad f_i(\vx)$ son linealmente independientes.
\end{defn}

Vamos a ver el resultado importante que relaciona estos conceptos:

\begin{itheorem}
\label{thm:cualificacionYKKT}
\[
\left.
	\begin{array}{c}
		\vx \text{ mínimo local de } (P)\\
		\vx \text{ verifica la cualificación de las restricciones}
	\end{array}
\right\} \implies KKT(\vx)
\]
\end{itheorem}

\begin{proof}
Si $\vx$ es un mínimo local de $(P)$ entonces no existe ninguna dirección $d∈ℝ^n$ tal que sin salir del conjunto factible mejoremos el valor objetivo de $\vx$ en esa dirección, es decir:

\[
	\pesc{\grad f(\vx),d}< 0 \wedge \pesc{\grad f_i(\vx) < 0} ∀ i \in I
\]

Siendo $I$ el conjunto de las restricciones activas en $\vx$.

Por el teorema Gordan, existen $u_0≥0, u_i≥0, i\in I$ no todos nulos tales que $\pesc{(u_0,\vu),(\grad f, \grad f_i}$

$u_0 >0$ por la cualificación de las restricciones, ya que 
\[
	u_0 = 0 \implies \sum u_i\grad f_i (\vx) = 0 
\]
con lo que habríamos encontrado una combinación lineal y podríamos concluir que $\grad f_i$ son linealmente dependientes y por hipótesis no puede serlo.

Definimos $\gor{u_i} = \frac{u_i}{u_0}$ si $i\in I$y $\gor{u_i} = 0$ si $i\notin I$. De esta manera tenemos:

\[
	\gor{u_i} f_i = 0 \impliedby
	\left\{ 
		\begin{array}{cc} 
			i\in I &\implies f_i(\vx) = 0 \\
			i\notin I &\implies \gor{u_i} = 0
		\end{array}
	\right.
\]

Ahora sólo queda comprobar $KKT(\vx,\gor{\vu})$.

\end{proof}

Con este teorema, clasificamos todos los mínimos que puede tener un problema en 2 clases disjuntas. \textbf{O cumple la cualificación de las restricciones o KKT}, pero no puede no cumplir ninguna (ni las 2 a la vez).

\begin{example}
Determina los puntos que verifican KKT y resuelve el problema:

\begin{ioprob}
\goal{$\min x_1^2+x_2^2 + 2x_3^2$}
\restrictions{$2x_1+3x_2+x_3 ≥ 6 \to -2x_1 - 3x_2 - x_3 + 6 ≤0$}{}{}{}{}{}
\end{ioprob}

Tenemos $\grad f(\vx) = (2x_1,2x_2,4x_3)$, con $f_i = (-2,-3,-1)$

Construimos el "sistema":

\[
\grad f(\vx) + \sum u_i f_i(\vx) \to 
\left\{
	\begin{array}{cc}
		2x_1-2u = 0&\\
		-2x_2 - 3u = 0&\\
		6x_3 - u = 0&\\
		u≥0, 2x_1+3x_2+x_3≥6 &(Factibilidad)\\
		u[-2x_1 - 3x_2 - x_3 + 6] = 0 &(Holgura Complementaria)
	\end{array}\right.
\]

Y ahora resolvemos el sistema\footnote{No hay ningún algoritmo mejor que ir razonando.}.

\begin{equation}
\label{KTT:ejemplo1}
2x_1+3x_2+x_3 > 6 \overset{H.C.}{\to} u=0 \to x_i = 0 \to \neg F
\end{equation}
De \ref{KTT:ejemplo1} obtenemos que $2x_1+3x_2 + x_3 = 6$ y nos hemos quitado la desigualdad.

Ahora tenemos un sistema de 4 incógnitas $(x_1,x_2,x_3,u)$ y 4 ecuaciones. Resolviendo el sistema obtenemos:

\[
	sol. \to (x_1,x_2,x_3,u) = \left( \rfrac{8}{9}, x_1^0,x_2^0,x_3^0\right)
\]

Llamamos $\gor{\vx} = (x_1^0,x_2^0,x_3^0)$. Hemos encontrado un punto que $KKT(\gor{\vx})$.

Por otro lado: como $\grad f_i(\vx) = (-2,-3,1) ∀\vx$, todos los $\grad f_i$ son linealmente independientes para todos los $\vx$, con lo que todos los puntos cumplen la cualificación de las restricciones.

$\gor{\vx}$ es un punto que cumple la cualificación de las restricciones y es KKT, con lo que es el único mínimo que hay. Como sólo hay un mínimo, éste tiene que ser el mínimo global.

\end{example}

\begin{example}

Resolver gráficamente y determinar los puntos que verifican KKY en el siguiente problema:

\begin{ioprob}
\goal{$\max 3x_1+x_2$}
\restrictions{$x_2-(1-x_1)^3≤0$}{$x_1≥0$}{$x_2≥0$}{}{}{}
\end{ioprob}

Lo primero es escribirlo como problema de minimización para poder utilizar lo visto hasta ahora:

\begin{ioprob}
\goal{$\min -3x_1-x_2$}
\restrictions{$x_2-(1-x_1)^3≤0$}{$-x_1≤0$}{$-x_2≤0$}{}{}{}
\end{ioprob}

Para comprobar KKT, calculamos el Lagrangiano:

\[
	L(\vx,\vu) = -3x_1 - x_2 + u_0[x_2-(1-x_1)^3] + u_1(-x_1) + u_2(x_2)
\]

Y construimos el sistema:

\[
	\left\{
	\begin{array}{lc}
		\dpa{L}{x_1} = -3 + 3u_0(1-x_1)^2 - u_1 = 0&(I)\\
		\dpa{L}{x_2} = -1 * u_0 - u_2 = 0 & (II)\\
		\left. 
			\begin{array}{c}
				u_0[x_2-(1-x_1)^3] = 0\\
				u_1(x_i) = 0\\
				u_2(x_2) = 0
			\end{array}
			\right\} &(HC)
	\end{array}
	\right.
\]

Y se resuelve.

\end{example}


\subsection{KTT con igualdad}

Podemos extender la noción de condición KKT a un problema en el que haya restricciones con igualdad, esto es:

\marginpar{\textcolor{yellow}{Completar de .tex del profesor}}



También hay una condición de cualificación de las restricciones y un teorema con el resultado análogo al anterior para problemas con restricciones con igualdad.


\section{Problema dual}

Podemos definir un problema a partir de uno dado que siempre es convexo y tiene otras propiedades interesantes. En ocasiones es más fácil de resolver y en otras aporta información muy claramente que en el problema inicial no están definidas. 

Vamos a comenzar definiendo la función que da lugar al problema dual:

\begin{defn}[Función\IS lagrangiana]
Para un problema general (no necesariamente convexo) con $m$ restricciones con desigualdad y $p$ restricciones con igualdad, definimos:

\[
	L(\vx,\vu,\vv) = f(\vx) + \sum_i^m u_if_i(\vx) + \sum_i^p v_if_i(\vx)
\]
\end{defn}

\paragraph{Interpretación:} Vamos a interpretar las restricciones como penalizaciones. Ahora el conjunto factible será todo $\real^n$, pero los puntos que no cumplan una restricción van a ser "penalizados". Definimos la función objetivo:

\[
	f(\vx) + \sum I_{-}(f_i(\vx)) + \sum I_{0}(f_i(\vx)) \to \left\{ 
		\begin{array}{c}
		I_{-} = \left\{
			\begin{array}{ccc}
				0 & si & x≤0\\
				∞ & si & x> 0\\
			\end{array}\right.\\
		I_{0} = \left\{
			\begin{array}{ccc}
				0 & si & x = 0\\
				∞ & si & x ≠ 0\\
			\end{array}\right.
		\end{array}
		\right.
\]

De esta manera hemos agrandado el conjunto factible y tenemos un problema equivalente, pero sin restricciones. Tomando valores interesantes en vez de $I_{-}$ e $I_{0}$, llegaríamos la función lagrangiana.


\begin{defn}[Función\IS dual]
	\[
		g(\vu,\vv) = \inf_{x\in D} L(\vx,\vu,\vv)
	\]
\end{defn}

Tomando la función dual, tenemos:

\[
	g(\vu,\vv) = \inf_{\vx\in D} L(\vx,\vu,\vv) ≤ L(\vx,\vu\vv) = f(x) + \sum u_if_i(\vx) + \sum v_if_i(\vx) \overset{(1)}{≤} f(\vx)
\]

$(1)$ si $\vx$ es un problema factible.

\begin{prop}
La función dual es una función cóncava (aunque el problema inicial $(PI)$ no sea convexo).
\end{prop}

\begin{proof}
\[
	g(λu_1 + (1-λ)u_2, λu_1 + (1-λ)v_2) = \min \{L(\vx,\vu,\vv)\} = \min \{λL(\vx,u_1,v_1) + (1-λ)L(\vx,u_2,v_2)\} \]
\[≥ λ\underbrace{\min\{L(\vx,u_1,v_1)\}}_{g(u_1,v_1)} + (1-λ) \underbrace{\min\{L(\vx,u_2,v_2)\}}_{g(u_2,v_2)}
\]
\end{proof}

La función dual es una cota inferior del valor óptimo del problema inicial. Podríamos considerar resolver el problema inicial buscando la mejor cota inferior de la función dual. De esta manera, igual llegamos a resolver el mismo problema. 
Los siguientes resultados nos ayudarán a resolver estas cuestiones:

Por si no nos creemos que sea una cota inferior, vamos a verlo formalmente como teorema (aunque no lo demostremos):

\begin{itheorem}
Sea $\bar{p}$ el valor óptimo de un problema de optimización cuya función dual es $g(\vu,\vv)$. \textbf{Entonces:} $∀ \vu≥0,∀v, g(\vu,\vv) = \bar{p}$
\end{itheorem}
\begin{proof}
Aunque no lo vamos a demostrar.
\end{proof}


\begin{defn}[Problema\IS dual]
Sea $g(\vu,\vv)$ la función dual asociada a un problema $(PI)$.

\begin{ioprob}
\goal{$\max g(\vu,\vv)$}
\restrictions{$u≥0$}{}{}{}{}{}
\end{ioprob}
\end{defn}

\begin{itemize}
	\item Llamaremos \concept{problema\IS primal} al problema inicial.
	\item El problema dual es \textbf{siempre convexo}, independientemente de que lo sea o no el problema primal al que corresponde.
	\item Un punto $(\vu,\vv)$ con $\vu≥0$ y $g(u,v) < -∞$ se llama \concept{solución\IS factible dual}.
	\item Llamamos \concept{solución\IS factible dual óptima} al punto $(\vu,\vv)$ que resuelve el problema dual.
	\item El problema dual tiene conjunto factible convexo, función cóncava y es un problema convexo\footnote{No tengo muy claro cómo puede ser todo esto al mismo tiempo}. 
	El problema es que la función dual puede ser muy complicada.
\end{itemize}


\subsection{Problemas duales}

\paragraph{El problema dual de un problema lineal en forma estándar}

...

\paragraph{El dual de un problema lineal en forma canónica}

...

\paragraph{Ejemplos}

...


\begin{example} Escribe el dual de:

...

\begin{ioprob}
\goal{$\min -u_1 - u_2$}
\restrictions{$-u_2≥1$}{$u_2 ≤ 1-$}{$u_1-u_2≥-1$}{$u_1 ≥$}{$u_2≥0$}{}
\end{ioprob}

Aquí no tienen solución ni el factible ni el primal.
\end{example}

\subsubsection{Resumen}

A continuación, una tabla que resume el cálculo de problemas duales a partir de primales.
\begin{table}[hbtp]
\centering
\begin{tabular}{c|c|c}
Primal $\equiv$ (P) & $\begin{array}{c} \min c'x\\Ax = b\\x≥ 0\end{array}$ & $\begin{array}{c} \max c'x\\Ax ≤ b\\x≥ 0\end{array}$\\
\hline
Dual $\equiv$ (D) & $\begin{array}{c} \max b'u\\A'u ≥ c\end{array}$ & $\begin{array}{c} \min b'u\\A^\top u ≤ c\\u≥ 0\end{array}$\\
\end{tabular}
\caption{Resumen de pasar del problema primal al dual.}
\end{table}



\subsection{Dualidad fuerte y débil}


\begin{defn}[Dualidad\IS débil]
Sean $\bar{p},\bar{d}$ sendos valores óptimos del problema primal y su dual.

Entonces:\[\bar{p} ≤ \bar{d}\]
\end{defn}

De aquí podemos sacar 2 conclusiones:

\begin{itemize}
	\item Si el primal no es acotado ($\bar{p} = -∞$), entonces el dual no es factible.
	\item Si el dual no es acotado ($\bar{d} = ∞$), entonces el primal no es factible.
\end{itemize}


\begin{defn}[Dualidad\IS fuerte]
$\bar{p} = \bar{d}$
\end{defn}


\begin{theorem}[Dualidad fuerte para problemas lineales]

Consideremos un problema lineal en forma estándar $(P)$ y el correspondiente problema dual $(D)$. 

Si $(P)$ tiene solución factible óptima finita, también la tiene $(D)$ y los correspondientes valores óptimos son iguales.
\end{theorem}

\begin{proof}
\label{proof:dualidadFuerte}
\[u' \equiv c_B'B^{-1}\]

\[
\begin{array}{c}
u'b = c'_BB^{-1}b
c'x = c'_BB^{-1}n]c_N'0
\end{array}
\]


$u$ es factible para $(D)$ $\dimplies$ 

\[u'A ≤ c' = c'_BB^{-1}\left(B | N \right) ≤ (c'_B,c'_N)\dimplies \underbrace{c_B'B^{-1}N}_{z_j} ≤ c'_N\]

Demostrar que $u$ es factible es lo mismo que demostrar que $z_j ≤ c_j$ en la tabla del simplex. Como $\bar{x}$ es el óptimo, en la última fila de simplex tenemos todos $≤0$, con lo que $z_j ≤ c_j$

\paragraph{Conclusión: } Encontrar un óptimo para el primal es encontrar un factible para el dual.

\end{proof}

\obs
\[
\dpa{\bar{z}}{b_i} = u_i
\]

Es decir, el resultado de incrementar uno de los coeficientes del problema primal, corresponde al valor del multiplicador.

\paragraph{Dualidad fuerte para problemas lineas}
\begin{itemize}
	\item La condición de factibilidad de $\bar{u}$ equivale a la de optimalidad de $\gx$.
	\item Resolver el primal y el dual es equivalente a partir de la relación obtenida en la demostración \ref{proof:dualidadFuerte}:
	\[
		\bar{u}^\top =  c_B^\top B^{-1}
	\]
\end{itemize}

\subsection{Interpretación económica del problema dual}

La solución del problema dual del pastelero es $u = \left(\rfrac{1}{3},0,10\right)$, que son los valores que aparecían en el problema \ref{ejer:pastelero}. Además, vemos también que $\bar{p} = \bar{d} = 775$. Es decir, la dualidad es fuerte. 


En la solución de este problema (\ref{ejer:pastelero}), se preguntaba la modificación del valor objetivo al aumentar en 1 cada una de las cantidades y la solución obtenida se corresponde con la solución del problema dual,
como nos indicaba la observación anterior.


\subsection{Algoritmo simplex-dual}

\paragraph{Motivación:} 
Tenemos un problema de programación lineal que resolvemos con simplex normal. 
Llegamos a una solución óptima que es factible del dual. Ahora, imaginemos que cambiamos $b$, con lo que las restricciones dejan de cumplirse. El estado de la tabla del simplex se mantiene, salvo la columna de la izquierda. 
Este es un punto de partida para este algoritmo. Otro caso ventajoso de este algoritmo se da al tener ¿coeficientes negativos?





\begin{example} Resolver el problema:

...

Lo primero es pasarlo a forma estándar:


\begin{ioprob}
\goal{$\min{3x_1 + 2x_2}$}
\restrictions{$3x_1-x_2+x_3 = -3$}{...}{...}{...}{...}{...}
\end{ioprob}


En este caso, no podemos empezar con el algoritmo del simplex, porque hay $b_i< 0$. Pero tendríamos una solución óptima si fuera factible. Al ser óptima en el primal, es factible en el dual y podemos aplicar el algoritmo del simplex-dual.
Vamos a ver la evolución de las tablas.


\textbf{Vamos a verlo gráficamente paso a paso}

\begin{figure}[hbtp]
\centering
\begin{tikzpicture}[scale=1.5]
\draw[thick,->] (0,0) -- (3.5,0);
\draw[thick,->] (0,0) -- (0,3.5);
\draw[thick,-] (3,0) -- (0,3);
\draw[thick,-] (1,0) -- (0,3);
\draw[thick,-] (1.5,0) -- (0,2);
\filldraw[fill=blue, opacity = 0.4] (3/5,6/5) -- (1.5,0) -- (3,0) -- (0,3) -- cycle;
\node [label={below:$(1)$},nodepoint, inner sep=2pt,color=red] at (0,0) {};
\node [label={left:$(2)$},nodepoint, inner sep=2pt,color=blue] at (0,2) {};
\node [label={below left:$(3)$},nodepoint, inner sep=2pt,color=green] at (3/5,6/5) {};
\end{tikzpicture}
\caption{Evolución del algoritmo del simplex-dual.}
\end{figure}

\end{example}


\begin{prop}
Tras el pivoteo se mantiene la factibilidad dual (optimilidad primal)
\end{prop}
\begin{proof}

\[
	\underbrace{(z_j-c_j)}_{≤0} - \frac{y_{rj}}{y_{rk}}\underbrace{(z_k-c_k)}_{≤0}
\]

También sabemos que $y_{rk}<0$.  Distingamos 2 casos:

\[
	y_{rj} ≥ 0 \implies \hat{z_j}-\hat{c_j} ≤ z_j-c-j ≤ 0
\]

\[
	y_{rj} ≤ 0 \implies \hat{z_j}-\hat{c_j} ≤ 0 \dimplies \frac{z_j-c_j}{y_{rj}}≥\frac{z_l-c_l}{y_{rk}}
\]
Esta segunda condición se cumple por el criterio de entrada a la base (selección de $k$).

Hemos visto que para cualquier valor de $y_{rj}$, se mantiene la condición de optimalidad ($z_j-c_j <0$)
\end{proof}

\begin{prop}
Tras el pivoteo se mejora el objetivo del dual, es decir:

\[
	\sum_{i\in \hat{B}} c_i\gor{b_i} > \sum_{i\in B} c_i\gor{b_i}
\]

\end{prop}
\begin{proof}
%% Completar de las traspas
\end{proof}

\begin{prop}

Si $y_{tj} ≥ 0 ∀j$, el tproblema primal no es factible
\end{prop}

\begin{proof}
Si existiera $\vx≥0$ con $A\vx = \vb$ tendríamos:

\[
	A\vx = \vb \dimplies B^{-1}A\vx = \gor{b} \dimplies \sum_{j=1}^n y_jx_j = \gor{b}
\]

En particular, $\gor{b_r} = \sum_j y_{rj}x_j ≥ 0$, lo que no puede ser ¿por el criterio de elección de $r$? porque $\gor{b_r} < 0$.
\end{proof} 


\section{KTT y dualidad}

Hasta ahora hemos visto las condiciones $KKT$ por un lado y el problema dual por el otro. Ahora vamos a ver qué relación tiene un concepto con el otro.

\paragraph{HOlgura complementaria en problemas lineales}

Sean $\vx$ y $\vu$ las soluciones de $(P) \equiv \max c^\top x \;\;s.a.\;\; A\vx ≤ b$ y de $(D)$ su dual.

En el caso de dualidad fuerte, tenemos:

\[
	\pesc{\vc,\vx} ≤ \vu^\top A \vx ≤ \pesc{\vu,\vb} = \pesc{\vc,\vx}
\]

\begin{prop}
Si una restricción no se activa en el primal, la variable correspondiente en el dual es 0. 
También se cumple intercambiando el papel del dual y del primal.

Si una variable del dual es positiva, la restricción correspondiente del primal está activa (por la holgura complementaria).

\end{prop}
\begin{proof}

\end{proof}

Estas condiciones caracterizan las soluciones de $(P)$ y de $(D)$ porque ... 




\begin{example}

Vamos a ver un ejemplo para entender los resultados anteriores.


\begin{ioprob}
\goal{$\max 3x_1 + 4x_2 + 6x_3$}
\restrictions{$3x_1+x_2+x_3≤2$}{$x_1+2x_2+6x_3≤1$}{$x_i≥0$}{}{}{}
\end{ioprob}

\textbf{Escribe el problema dual:}

\begin{ioprob}
\goal{$\min 2u_1 + u_2$}
\restrictions{$3u_1 + 1u_2 ≥ 3$}{$1u_1 + 2u_2 ≥ 4$}{$1u_1 + 6u_2 ≥ 6$}{$u_i ≥ 0$}{}{}
\end{ioprob}


\textbf{Resuelve el dual gráficamente:}

Gracias a pasar al dual podemos representar gráficamente un problema que inicialmente tenía 3 variables y no podríamos dibujar con tanta facilidad.



\begin{figure}[hbtp]
\centering
\begin{tikzpicture}[scale=1.5]
\draw[thick,->] (0,0) -- (8,0);
\draw[thick,->] (0,0) -- (0,4.2);
\draw[thick,-] (1,0) -- (0,3);
\draw[thick,-] (4,0) -- (0,2);
\draw[thick,-] (6,0) -- (0,1);
\filldraw[fill=blue, opacity = 0.2] (0,3) -- (2/5,9/5) -- (3,0.5) -- (6,0) -- (8,0) -- (8,4) -- (0,4) -- cycle;
\node [label={above right:$(Optm.)$},nodepoint, inner sep=2pt,color=red] at (2/5,9/5) {};
%\node [label={left:$(2)$},nodepoint, inner sep=2pt,color=blue] at (0,2) {};
%\node [label={below left:$(3)$},nodepoint, inner sep=2pt,color=green] at (3/5,6/5) {};
\end{tikzpicture}
\caption{Resolución gráfica del ejemplo.}
\end{figure}


Resolviéndolo, obtenemos: 

\[
	(\gor{u_1},\gor{u_2},\gor{d}) = \left(\rfrac{2}{5},\rfrac{9}{5},\rfrac{13}{5}\right)
\]



En el óptimo dual, la 3 restricción no está activa, con lo que $x_3 = 0$. Además, como los $\gor{u_1} ≠ 0$ implica que la restricción correspondiente se verifica con igualdad. Lo mismo con $\gor{u_2}≠0$.Recapitulando, tenemos:

\[
\left.\begin{array}{c}
	3x_1+x_2+x_3 = 2\\
	x_1+2x_2+6x_3 = 1
\end{array}\right\} \implies (x_3 = 0) + \text{ con igualdad } \implies \left\{\begin{array}{c}3x_1 + x_2 = 2\\x_1 + 2x_2 = 1\end{array}\right.
\]

\obs Si no supiéramos que $x_3 = 0$, por la dualidad fuerte tenemos otra ecuación que sería:

\[
	3x_1 + 4x_2 + 6x_3 = \gor{d}
\]
\end{example}


\subsubsection{Holgura complementaria en problemas no lineales}.


\begin{itheorem}[convexidad y KKT]

\label{thm:convKKT}

Completar
\end{itheorem}